{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sequential Data Modeling\n",
        "\n",
        "Sequential Data: 데이터의 순서가 중요한 데이터\n",
        "\n",
        "MLP의 경우는 순서를 고려하지 않고 **모든 데이터 간의 관계**를 파악하는 데 집중 <br>\n",
        "CNN의 경우 순서를 고려하지 않고 **특정 범위 내의 관계**를 파악하는 데 집중 <br>\n",
        "따라서, **순서 정보가 중요한 데이터를 모델링하기 위한 구조의 필요성**이 대두됨 <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RNN (Recurrent Nueral Network)\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*iP_ahgzkiMNu2hPYhkjlXw.png\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<img src=\"https://wikidocs.net/images/page/160068/7_Backpropagation-in-RNNs.jpg\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> Equation </font> <br>\n",
        "$ a_t = \\textbf{W}_x\\textbf{x}_t + \\textbf{W}_h\\textbf{h}_{t-1} + \\textbf{b} $ <br>\n",
        "$ h_t = tanh(a_t) $\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 구조 </font> <br>\n",
        "이전 셀의 hidden state 정보를 받아 현재 cell의 input으로 입력 <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; 이전 셀의 hidden state는 이전 셀 까지의 정보를 나타내는 vector <br>\n",
        "위의 두 정보를 결합(add)하여 현재 cell의 input으로 입력 <br>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 장점 </font> <br>\n",
        "\n",
        "1. RNN은 순차적 데이터를 처리\n",
        "2. 과거 데이터의 패턴을 식별\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 단점 </font> <br>\n",
        "\n",
        "1. 기울기 소실(Gradient Vanishing)\n",
        "2. 위의 문제로 장기 메모리를 저장하기에는 부적합\n",
        "3. 기울기 폭주(Gradient Exploding)\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "1. 기울기 소실\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcJa1Yt%2FbtrO2pbrnzZ%2FJB0yolOkMyzjT5l2KEMT8K%2Fimg.png\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "위의 빨간 선(Back Propagation)에서 tanh와 MatMul 연산을 통해 기울기 업데이트 진행 <br>\n",
        "여기서 tanh함수의 미분은 아래와 같음\n",
        "\n",
        "y = tanh(x) = $ \\frac{e^x - e^{-x}}{e^x + e^{-x}} $\n",
        "\n",
        "$ \\frac{dy}{dx} = \\frac{\\partial \\tanh(x)}{\\partial x} = \\frac{(e^x + e^{-x})*(e^x + e^{-x}) - (e^x - e^{-x})(e^x - e^{-x})}{(e^x - e^{-x})^2} $\n",
        "\n",
        "$ = 1 - \\frac{(e^x - e^{-x})(e^x - e^{-x})}{(e^x + e^{-x})^2} $\n",
        "\n",
        "$ = 1 - \\{\\frac{(e^x - e^{-x})^2}{(e^x + e^{-x})^2}\\}^2 $\n",
        "\n",
        "$ = 1 - tanh^2(x) $\n",
        "\n",
        "이를 그림으로 나타내면 아래와 같음\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcaZOSF%2FbtrOYv530Pr%2FnUpvCwWZ4bTVZ8TnIw4zjk%2Fimg.png\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "여기서 $\\frac{dy}{dx}$의 그래프 값은 0~1이고, x가 0에서 멀어질수록 작아짐 <br>\n",
        "이는 역전파에서 기울기가 tanh 노드를 지날 때마다 계속 작아지는 것을 의미 (0보다 작은 값이 계속 곱해짐) <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "2. 기울기 폭주\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzZ16q%2FbtrO00b8Tv2%2F1oNKWoDxDRGkeZvKqDd3SK%2Fimg.png\" width=\"600\" height=\"200\"/>\n",
        "\n",
        "\n",
        "기울기 폭주는 MatMul에 의해 발생 <br>\n",
        "dh라고 하는 기울기가 들어올 때 MatMul에서 dh와 $\\textbf{W}_h^T$의 행렬 곱으로 연산 <br>\n",
        "위의 연산을 길이 만큼 반복하는데 ($ (dh \\textbf{W}_h^T)^t $), 이 때 행렬 곱에서 매번 똑같은 가중치가 사용되고, 가중치의 값에 따라 기울기가 **지수적으로 증가 혹은 감소**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "\n",
        "<img src=\"https://media.springernature.com/full/springer-static/image/chp%3A10.1007%2F978-3-030-82184-5_7/MediaObjects/469466_1_En_7_Fig2_HTML.png?as=webp\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "입력과 출력의 조합에 따라 다양한 task 수행 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bidirectional\n",
        "\n",
        "\n",
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20230302163012/Bidirectional-Recurrent-Neural-Network-2.png\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "일반적인 RNN 계열은 순방향에서의 정보만을 전달 <br>\n",
        "이 경우 역방향에서의 정보를 받을 수 없음 <br>\n",
        "Black is a lawyer이라는 문장이 있을 시 black이 색상인지 사람인지 구분하려고 함 <br>\n",
        "이 경우 순방향에서의 정보만을 이용해서는 black이 어느 것을 지칭하는지 알기 어려움 <br>\n",
        "하지만 역방향으로부터 정보를 받으면 lawyer라는 단어를 통하여 사람이라는 것을 유추 가능 <br>\n",
        "이러한 sequential 데이터의 특성을 반영하기 위해 고안된 것이 bidirectional 기능 <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 방법 </font> <br>\n",
        "\n",
        "RNN계열의 셀에서 bidirectional 옵션 사용 <br>\n",
        "옵션 사용 시 hidden_state가 두 배가 됨 (forward, backward 각각의 뉴런의 합) <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 사용 방법\n",
        "\n",
        "> ```python\n",
        "> import torch.nn as nn\n",
        "> \n",
        "> rnn = nn.RNN(\n",
        ">    input_size,\n",
        ">    hidden_size,\n",
        ">    num_layers=,\n",
        ">    bidirectional=False,\n",
        ">    batch_first=True,\n",
        "> )\n",
        "> output, h_n = rnn(x)\n",
        "> output, h_n = rnn(x, h_0) # (초기 hidden state를 줄 때)\n",
        "> \n",
        "> # x: 입력 텐서 (batch, seq_len, n_feature)\n",
        "> # output: 매 t에 대한 output layer\n",
        "> # h_n: final hidden state\n",
        "> ```\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:16px\"> 주요 parameter </font> <br>\n",
        "- input_size (int): 입력 tensor의 크기 (feature의 수)\n",
        "- hidden_size (int): hidden state의 neuron의 수\n",
        "- num_layers (int): stack의 수\n",
        "- bidirectional (bool): bidirectional RNN 유무\n",
        "- batch_first (bool): shape에서 batch를 제일 처음으로 둘 건지 결정\n",
        "    - True: (batch, seq_len, n_feature)\n",
        "    - False: (seq_len, batch, n_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "input.size(-1) must be equal to input_size. Expected 10, got 64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m rnn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mRNN(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m64\u001b[39m)  \u001b[38;5;66;03m# (batch, seq_len, n_feature)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\rnn.py:588\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    585\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 588\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_RELU\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\rnn.py:280\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\rnn.py:246\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 10, got 64"
          ]
        }
      ],
      "source": [
        "rnn = nn.RNN(input_size=10, hidden_size=20)\n",
        "x = torch.rand(32, 128, 64)  # (batch, seq_len, n_feature)\n",
        "rnn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 20])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn = nn.RNN(input_size=10, hidden_size=20, batch_first=True)\n",
        "x = torch.rand(32, 128, 10)  # (batch, seq_len, n_feature)\n",
        "output, h_n = rnn(x)         # output: 모든 시점의 hidden state, h_n: 마지막 step에 대한 hidden_state\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 256, 100])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn = nn.RNN(input_size=48, hidden_size=100, batch_first=True)\n",
        "x = torch.rand(32, 256, 48)  # (batch, seq_len, n_feature)\n",
        "output, h_n = rnn(x)         # output: 모든 시점의 hidden state, h_n: 마지막 step에 대한 hidden_state\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 256, 200])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn = nn.RNN(\n",
        "    input_size=48,\n",
        "    hidden_size=100,\n",
        "    batch_first=True,\n",
        "    bidirectional=True,\n",
        ")\n",
        "x = torch.rand(32, 256, 48)  # (batch, seq_len, n_feature)\n",
        "output, h_n = rnn(x)         # output: 모든 시점의 hidden state, h_n: 마지막 step에 대한 hidden_state\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('./data/samsung_2023.csv', encoding='cp949', usecols=['일자', '종가', '거래량'])\n",
        "data = data.sort_values(by=['일자'])\n",
        "data.일자 = pd.to_datetime(data.일자)\n",
        "data = data.set_index('일자')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([240, 5, 20])"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# batch, seq_len, n_feature\n",
        "x = np.lib.stride_tricks.sliding_window_view(data, 5, axis=0)[:-1].transpose(0, 2, 1)\n",
        "y = data.종가.iloc[5:]\n",
        "x = torch.from_numpy(x).float()\n",
        "rnn = nn.RNN(\n",
        "    input_size=2,\n",
        "    hidden_size=10,\n",
        "    batch_first=True,\n",
        "    bidirectional=True,\n",
        ")\n",
        "output, h_n = rnn(x)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([241, 1])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = output.flatten(start_dim=1) # 241 x 100\n",
        "output_layer = nn.Linear(100, 1)\n",
        "output_layer(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([241, 1])"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = h_n.permute(1, 0, 2).flatten(start_dim=1)\n",
        "output_layer = nn.Linear(20, 1)\n",
        "output_layer(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>종가</th>\n",
              "      <th>거래량</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>일자</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-02</th>\n",
              "      <td>55500</td>\n",
              "      <td>10031448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>55400</td>\n",
              "      <td>13547030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>57800</td>\n",
              "      <td>20188071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>58200</td>\n",
              "      <td>15682826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>59000</td>\n",
              "      <td>17334989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>60700</td>\n",
              "      <td>18640107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-10</th>\n",
              "      <td>60400</td>\n",
              "      <td>14859797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-11</th>\n",
              "      <td>60500</td>\n",
              "      <td>12310751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-12</th>\n",
              "      <td>60500</td>\n",
              "      <td>16102561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-13</th>\n",
              "      <td>60800</td>\n",
              "      <td>12510328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               종가       거래량\n",
              "일자                         \n",
              "2023-01-02  55500  10031448\n",
              "2023-01-03  55400  13547030\n",
              "2023-01-04  57800  20188071\n",
              "2023-01-05  58200  15682826\n",
              "2023-01-06  59000  17334989\n",
              "2023-01-09  60700  18640107\n",
              "2023-01-10  60400  14859797\n",
              "2023-01-11  60500  12310751\n",
              "2023-01-12  60500  16102561\n",
              "2023-01-13  60800  12510328"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[55500, 55400, 57800, 58200, 59000],\n",
              "       [55400, 57800, 58200, 59000, 60700],\n",
              "       [57800, 58200, 59000, 60700, 60400]])"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.lib.stride_tricks.sliding_window_view(data.iloc[:-3], 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[60700, 60400, 60500],\n",
              "       [60400, 60500, 60500],\n",
              "       [60500, 60500, 60800]])"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.lib.stride_tricks.sliding_window_view(data.종가[:10].iloc[5:], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 미세먼지 데이터에서 구분이 평균인 row만 선택\n",
        "fine_dust = pd.read_csv(\n",
        "    './data/서울시 대기질 자료 제공_2022.csv',\n",
        "    encoding='cp949',\n",
        ")\n",
        "fine_dust = fine_dust.query('구분==\"평균\"')\n",
        "fine_dust = fine_dust.drop(columns=['구분'])\n",
        "fine_dust.일시 = pd.to_datetime(fine_dust.일시)\n",
        "fine_dust = fine_dust.sort_values(by=['일시'])\n",
        "fine_dust = fine_dust.set_index(['일시'])\n",
        "\n",
        "# 미세먼지와 초미세먼지의 평균을 target으로 설정\n",
        "fine_dust['target'] = fine_dust.mean(axis=1)\n",
        "\n",
        "# rnn을 통하여 이전 10시간의 미세먼지 데이터를 통하여 \n",
        "#   미래 5시간의 미세먼지 평균을 예측하는 모델 구성\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['미세먼지(PM10)', '초미세먼지(PM2.5)', 'target'], dtype='object')"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fine_dust.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([241, 1])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = h_n.permute(1, 0, 2).flatten(start_dim=1)\n",
        "output_layer = nn.Linear(20, 1)\n",
        "output_layer(x).shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "e4af6128c7e0808fede432f38729c473c5b0d80882e83c469acdb54455c56396"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
