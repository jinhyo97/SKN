{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sequential Data Modeling\n",
        "\n",
        "Sequential Data: 데이터의 순서가 중요한 데이터\n",
        "\n",
        "MLP의 경우는 순서를 고려하지 않고 **모든 데이터 간의 관계**를 파악하는 데 집중 <br>\n",
        "CNN의 경우 순서를 고려하지 않고 **특정 범위 내의 관계**를 파악하는 데 집중 <br>\n",
        "따라서, **순서 정보가 중요한 데이터를 모델링하기 위한 구조의 필요성**이 대두됨 <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSTM (Long Short Term Memory)\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*tEN1Ziu4VvRAaH9zagN3EQ.png\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "RNN의 문제점을 해결하기 위해 등장한 Cell <br>\n",
        "Input gate, forget gate, output gate의 gate를 사용하여 정보 업데이트 <br>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 구조 </font> <br>\n",
        "<font style=\"font-size:16px\"> Forget Gate </font> <br>\n",
        "<img src=\"https://wikidocs.net/images/page/160053/10_LSTM3-focus-f.png\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "셀 상태에서 버릴 정보 결정 <br>\n",
        "Sigmoid를 통해 0이면 제거, 1이면 유지, 그 사이면 그 비율 만큼을 유지 <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:16px\"> Input Gate </font> <br>\n",
        "<img src=\"https://wikidocs.net/images/page/160053/11_LSTM3-focus-i.png\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "이젠 셀 상태($C_{t-1}$)을 새 셀 상태($C_t$)로 업데이트 <br>\n",
        "$i_t*\\tilde{C_t}$의 정보량을 추가 <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; $i_t$: $x_t$에서 어느 정도 비율을 업데이트 할 지 결정 <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; $\\tilde{C_t}$: $x_t$에서 입력된 값을 -1 ~ 1로 스케일링 <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:16px\"> Output Gate </font> <br>\n",
        "셀 상태($C_t$)에서 어느 정도를 출력할지 결정 <br>\n",
        "<img src=\"https://wikidocs.net/images/page/160053/13_LSTM3-focus-o.png\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "$o_t$: 입력된 값을 통해 $C_t$에서 어느 정도의 양을 출력할 지 결정 <br>\n",
        "$tanh(C_t)$: $C_t$를 -1 ~ 1로 스케일링 <br>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 장점 </font> <br>\n",
        "\n",
        "1. RNN의 학습 불안정(기울기 소실, 폭발) 문제 일부 극복\n",
        "2. 장기 정보를 RNN보다 더욱 잘 캡처\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 단점 </font> <br>\n",
        "\n",
        "1. 완벽하게 해결하지는 못 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 사용 방법\n",
        "\n",
        "> ```python\n",
        "> import torch.nn as nn\n",
        "> \n",
        "> lstm = nn.LSTM(\n",
        ">    input_size,\n",
        ">    hidden_size,\n",
        ">    num_layers=,\n",
        ">    bidirectional=False,\n",
        ">    batch_first=True,\n",
        "> )\n",
        "> output, (h_n, c_n) = lstm(x)      # (초기 hidden state를 주지 않을 때)\n",
        "> output, (h_n, c_n) = lstm(x, h_0) # (초기 hidden state를 줄 때)\n",
        "> \n",
        "> # x: 입력 텐서 (batch, seq_len, n_feature)\n",
        "> # output: 매 t에 대한 output layer\n",
        "> # h_n: final hidden state\n",
        "> # c_n: final cell state\n",
        "> ```\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:16px\"> 주요 parameter </font> <br>\n",
        "- input_size (int): 입력 tensor의 크기 (feature의 수)\n",
        "- hidden_size (int): hidden state의 neuron의 수\n",
        "- num_layers (int): stack의 수\n",
        "- bidirectional (bool): bidirectional LSTM 유무\n",
        "- batch_first (bool): shape에서 batch를 제일 처음으로 둘 건지 결정\n",
        "    - True: (batch, seq_len, n_feature)\n",
        "    - False: (seq_len, batch, n_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variants\n",
        "\n",
        "LSTM 구조의 다양한 변형 <br>\n",
        "외에도 수많은 종류가 있으며 퍼포먼스는 비슷하나 일부 특정 task에 적합한 구조가 있는 것으로 발혀짐 <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Peephole\n",
        "\n",
        "<img src=\"https://wikidocs.net/images/page/160053/14_LSTM3-var-peepholes.png\" width=\"600\" height=\"300\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combined forget and input gate\n",
        "\n",
        "<img src=\"https://wikidocs.net/images/page/160053/15_LSTM3-var-tied.png\" width=\"600\" height=\"300\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GRU (Gated Recurrent Unit)\n",
        "\n",
        "RNN Variant의 하나로 LSTM에서 세 개의 gate를 보다 간소화 <br>\n",
        "Update gate와 reset gate를 활용하여 정보 업데이트 <br>\n",
        "LSTM의 cell state와 hidden state가 hidden state로 통합 <br>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 구조 </font> <br>\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*-ldMy6GqBy8D25uNKQl2gA.png\" width=\"600\" height=\"300\"/>\n",
        "\n",
        "\n",
        "<font style=\"font-size:16px\"> Reset Gate (a) </font> <br>\n",
        "\n",
        "잊을 정보량 결정\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:16px\"> Update Gate (b) </font> <br>\n",
        "\n",
        "\n",
        "이전 step의 hidden state의 정보를 현재 상태에 얼마나 반영할 것인지 결정 <br>\n",
        "0에 가까울 수록 이전 hidden state의 정보는 잊혀지고 1에 가까우면 현재의 hidden state 정보 유지 <br>\n",
        "그림의 -는 정보를 1에서 뺀다는 의미로 제거량 의미\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 장점 </font> <br>\n",
        "\n",
        "1. LSTM 대비 적은 parameter로 보다 빠른 학습 속도\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 단점 </font> <br>\n",
        "\n",
        "1. 일부 task에서 긴 시퀀스 데이터에서 LSTM대비 장기 의존성 유지 어려움 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 사용 방법\n",
        "\n",
        "> ```python\n",
        "> import torch.nn as nn\n",
        "> \n",
        "> gru = nn.GRU(\n",
        ">    input_size,\n",
        ">    hidden_size,\n",
        ">    num_layers=,\n",
        ">    bidirectional=False,\n",
        ">    batch_first=True,\n",
        "> )\n",
        "> output, h_n = gru(x)      # (초기 hidden state를 주지 않을 때)\n",
        "> output, h_n = gru(x, h_0) # (초기 hidden state를 줄 때)\n",
        "> \n",
        "> # x: 입력 텐서 (batch, seq_len, n_feature)\n",
        "> # output: 매 t에 대한 output layer\n",
        "> # h_n: final hidden state\n",
        "> ```\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:16px\"> 주요 parameter </font> <br>\n",
        "- input_size (int): 입력 tensor의 크기 (feature의 수)\n",
        "- hidden_size (int): hidden state의 neuron의 수\n",
        "- num_layers (int): stack의 수\n",
        "- bidirectional (bool): bidirectional LSTM 유무\n",
        "- batch_first (bool): shape에서 batch를 제일 처음으로 둘 건지 결정\n",
        "    - True: (batch, seq_len, n_feature)\n",
        "    - False: (seq_len, batch, n_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary\n",
        "\n",
        "|Cell|Structure|\n",
        "|---|----|\n",
        "|RNN|<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*iP_ahgzkiMNu2hPYhkjlXw.png\" width=\"600\" height=\"300\"/>|\n",
        "|LSTM|<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*tEN1Ziu4VvRAaH9zagN3EQ.png\" width=\"600\" height=\"300\"/>|\n",
        "|GRU|<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*-ldMy6GqBy8D25uNKQl2gA.png\" width=\"600\" height=\"300\"/>|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Practice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 20, 64])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(32, 20, 64)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 20, 200])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn = nn.RNN(64, 200, batch_first=True)\n",
        "output, h_n = rnn(x)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 200])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h_n.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 20, 200])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm = nn.LSTM(64, 200, batch_first=True)\n",
        "output, h_n = lstm(x)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(h_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 200])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h_n[0].shape    # 제일 마지막 hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 200])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h_n[1].shape    # 제일 마지막 cell_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lstm = nn.LSTM(64, 200, batch_first=True)\n",
        "output, (h_n, c_n) = lstm(x)    # h_n, c_n을 사용할 때\n",
        "output, _ = lstm(x)             # h_n, c_n을 사용하지 않을 때"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.randn(32, 20, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 20, 200])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 200])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gru = nn.GRU(64, 200, batch_first=True)\n",
        "output, h_n = gru(x)\n",
        "\n",
        "display(output.shape)\n",
        "display(h_n.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 삼성 주식데이터 2023의 데이터 활용\n",
        "# 시가, 고가, 종가, 저가, 거래량 다섯 개의 컬럼을 활용\n",
        "samsung = pd.read_csv(\n",
        "    './data/samsung_2023.csv',\n",
        "    encoding='cp949',\n",
        "    usecols=['일자', '시가', '고가', '종가', '저가', '거래량'],\n",
        ")\n",
        "samsung.일자 = pd.to_datetime(samsung.일자)\n",
        "samsung = samsung.sort_values(by=['일자'])\n",
        "samsung = samsung.set_index('일자')\n",
        "# 전일 10일의 데이터를 통하여 다음 5일의 종가 예측\n",
        "# 1. 데이터 전처리  (X, y) 생성, train, valid, test\n",
        "train, temp = train_test_split(samsung, test_size=0.4, shuffle=False, random_state=0)\n",
        "valid, test = train_test_split(temp, test_size=0.5, shuffle=False, random_state=0)\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "train.loc[:] = standard_scaler.fit_transform(train)\n",
        "valid.loc[:] = standard_scaler.transform(valid)\n",
        "test.loc[:] = standard_scaler.transform(test)\n",
        "\n",
        "window_size = 10\n",
        "output_dim = 5\n",
        "\n",
        "# X.shape -> (batch_size, seq_len, dim)\n",
        "x_train = np.lib.stride_tricks.sliding_window_view(\n",
        "    train.iloc[:-output_dim], window_size, axis=0).transpose(0, 2, 1)\n",
        "y_train = np.lib.stride_tricks.sliding_window_view(\n",
        "    train.종가.iloc[window_size:], output_dim\n",
        ")\n",
        "x_valid = np.lib.stride_tricks.sliding_window_view(\n",
        "    valid.iloc[:-output_dim], window_size, axis=0).transpose(0, 2, 1)\n",
        "y_valid = np.lib.stride_tricks.sliding_window_view(\n",
        "    valid.종가.iloc[window_size:], output_dim, axis=0\n",
        ")  \n",
        "x_test = np.lib.stride_tricks.sliding_window_view(\n",
        "    test.iloc[:-output_dim], window_size, axis=0).transpose(0, 2, 1)\n",
        "y_test = np.lib.stride_tricks.sliding_window_view(\n",
        "    test.종가.iloc[window_size:], output_dim, axis=0\n",
        ")\n",
        "\n",
        "# 2. LSTM cell 정의\n",
        "lstm = nn.LSTM(\n",
        "    5,\n",
        "    32,\n",
        "    batch_first=True,\n",
        ")\n",
        "\n",
        "x_train = torch.Tensor(x_train)\n",
        "x, _ = lstm(x_train)\n",
        "\n",
        "# 3. 다음 5일의 종가를 맞추기 위한 전처리 및 셀 구성\n",
        "x = x.flatten(start_dim=1)\n",
        "linear = nn.Linear(320, 5)\n",
        "output = linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([133, 5])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2494"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# x_train이 가지고 있는 전체 문장: 25000\n",
        "# 25000개의 문장 중에서 길이가 가장 긴 문장의 단어 수가 몇 개인지 찾는 코드 작성\n",
        "max([len(sentence) for sentence in x_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 길이 분포 확인 -> 문장의 최대 길이 정의\n",
        "sns.histplot([len(sentence) for sentence in x_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 200보다 길이가 긴 문장은 200개로 잘라서 사용\n",
        "max_len = 200\n",
        "x_train = [torch.Tensor(sequence[:max_len]).long() for sequence in x_train]\n",
        "x_test = [torch.Tensor(sequence[:max_len]).long() for sequence in x_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# max_len보다 작은 문장을 max_len으로 맞춤\n",
        "x_train = pad_sequence(x_train, batch_first=True)\n",
        "x_test = pad_sequence(x_test, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding = nn.Embedding(10000, 128)\n",
        "x = embedding(x_train[:32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 200, 128])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 200, 256])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# embedding 된 데이터를 lstm을 통해 학습\n",
        "lstm = nn.LSTM(128, 128, batch_first=True, bidirectional=True)\n",
        "x, _ = lstm(x)\n",
        "# batch normalization 사용하지 않음\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 51200])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# flatten\n",
        "x = x.flatten(start_dim=1)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 2])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# flatten 데이터를 linear를 통해 학습\n",
        "linear1 = nn.Linear(51200, 128)\n",
        "x = linear1(x)\n",
        "# 여기에는 dropout 사용 가능\n",
        "linear2 = nn.Linear(128, 2)\n",
        "x = linear2(x)\n",
        "# 여기에는 dropout 사용 불가능\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.7002, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "F.cross_entropy(x, torch.Tensor(y_train[:32]).long())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 위의 코드를 바탕으로 module 코드 수정\n",
        "# 1. imdb dataset 전처리\n",
        "#    max_len: 200, padding, validation set 생성\n",
        "# 2. dataset, lightningdatamodule 구성\n",
        "# 3. model (lstm)\n",
        "    # dropout 사용 (p=0.3)\n",
        "    # Embedding\n",
        "        # input: 10000, dim: 128\n",
        "    # LSTM 2개\n",
        "        # bidirectional\n",
        "        # layer1: 128 -> 256\n",
        "        # layer2: ?   -> 64\n",
        "    # Linear 3개\n",
        "        # layer1: ? -> 512\n",
        "        # layer2: 512 -> 128\n",
        "        # layer3: 128 -> 2\n",
        "# 4. lightningmodule\n",
        "    # classification task에 맞게 수정\n",
        "    # self.log를 통해서 정확도 산출"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "e4af6128c7e0808fede432f38729c473c5b0d80882e83c469acdb54455c56396"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
