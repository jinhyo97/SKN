{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UhoL6nMoWa0"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "whwymZ3zVzH2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn                               # layers\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim                         # optimizer\n",
        "import torchvision.datasets as ds                   # mnist daataset\n",
        "import torchvision.transforms as transforms         # image -> tensor\n",
        "from torch.utils.data import DataLoader, Dataset    # torch dataset\n",
        "\n",
        "import matplotlib.pyplot as plt                     # 시각화\n",
        "import seaborn as sns\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlGXlBEze4XI"
      },
      "source": [
        "# Multi-Layer Pereceptron (MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFUsOXCiVzkP"
      },
      "source": [
        "## MLP란?\n",
        "퍼셉트론으로 이루어진 층(layer) 여러 개를 순차적으로 붙여놓은 형태\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 등장 배경 </font> <p>\n",
        "<font style=\"font-size:16px\"> XOR 게이트 문제 </font> <p>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;and나 or의 경우 직선 하나로 경계를 확정할 수 있으나 xor에서는 불가 <br>\n",
        "\n",
        "  ![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNalwG%2FbtqxdrzsQAV%2FUY3iSEDRakKDjoWEpRHRWk%2Fimg.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 구조 </font> <p>\n",
        "\n",
        "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0925231223004502-gr1.jpg\" width=\"700\" height=\"300\"/>\n",
        "\n",
        "단순 matrix 연산의 반복 <br>\n",
        "> A1 = $\\textbf{W}_1X + \\textbf{b}_1$ <br>\n",
        "> h1 = $\\phi_1$(A1) <br>\n",
        "> A2 = $\\textbf{W}_2\\text{h1} + \\textbf{b}_2 = \\textbf{W}_2\\phi_1(\\textbf{W}_1X + \\textbf{b}_1) + \\textbf{b}_2$ <br>\n",
        "> h2 = $\\phi_2$(A2) = $ \\phi(\\textbf{W}_2\\phi_1(\\textbf{W}_1X + \\textbf{b}_1) + \\textbf{b}_2) $\n",
        "> ...\n",
        "\n",
        "<br>\n",
        "\n",
        "Hidden Layer의 $\\phi$는 activation 함수는 비선형을 목적으로 사용 <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRPTi61Df5IV"
      },
      "source": [
        "## 사용 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPU 사용 확인\n",
        "\n",
        "시스템에서 gpu를 사용할 수 있는지 확인\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 예제 </font> <p>\n",
        "\n",
        "> ```python\n",
        "> device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Seed 고정\n",
        "\n",
        "실험 재현을 위한 난수 고정\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 예제 </font> <p>\n",
        "\n",
        "> ```python\n",
        "> seed = 0\n",
        "> np.random.seed(seed)\n",
        "> torch.manual_seed(seed)\n",
        "> if device == 'cuda':\n",
        ">     torch.cuda.manual_seed(seed)\n",
        ">     torch.cuda.manual_seed_all(seed)\n",
        ">     torch.backends.cudnn.deterministic = False\n",
        ">     torch.backends.cudnn.benchmark = True\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 하이퍼파라미터 설정\n",
        "\n",
        "하이퍼파라미터: 모델에서 학습되지 않는 사용자가 직접 설정해야하는 파라미터 <br>\n",
        "대표적으로는 아래의 파라미터 존재 <br>\n",
        "- batch_size: 전체 데이터 중 데이터를 묶음으로 분할할 건데 몇 개의 묶음으로 분할할지 설정\n",
        "- epoch: 몇 번의 학습을 진행할 것인가\n",
        "- learning_rate: 얼마 만큼의 보폭으로 학습을 진행할 것인가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "learning_rate = 1e-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_planar_dataset():\n",
        "    np.random.seed(1)\n",
        "    m = 400 # number of examples\n",
        "    N = int(m/2) # number of points per class\n",
        "    D = 2 # dimensionality\n",
        "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
        "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
        "    a = 4 # maximum ray of the flower\n",
        "\n",
        "    for j in range(2):\n",
        "        ix = range(N*j,N*(j+1))\n",
        "        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n",
        "        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius\n",
        "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
        "        Y[ix] = j\n",
        "\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = load_planar_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 결측치 중복 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of na: x1    0\n",
            "x2    0\n",
            "y     0\n",
            "dtype: int64\n",
            "num of duplicated: 0\n"
          ]
        }
      ],
      "source": [
        "data = pd.DataFrame(X, columns=['x1', 'x2'])\n",
        "data['y'] = y\n",
        "print(f'num of na: {data.isna().sum()}')\n",
        "print(f'num of duplicated: {data.duplicated().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### train, valid, test split\n",
        "\n",
        "<img src=\"https://camo.githubusercontent.com/109b64cb7b6e1b6d912b84a1b6afefa53300033be1df4ed8c4433910f8c328bf/68747470733a2f2f76656c6f672e76656c63646e2e636f6d2f696d616765732f696775762f706f73742f38616538343265332d663262362d343463352d623762662d6131663734623361393132342f696d6167652e706e67\" width=\"500\" height=\"300\"/>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 예제 </font> <p>\n",
        "\n",
        "> ```python\n",
        "> X_train, X_temp, y_train, y_temp = train_test_split(\n",
        ">     X, y, test_size=0.6, random_state=seed, shuffle=True)\n",
        "> X_valid, X_test, y_valid, y_test = train_test_split(\n",
        ">     X, y, test_size=0.5, random_state=seed, shuffle=True)\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=seed\n",
        ")\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(240, 80, 80)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train), len(X_valid), len(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### scaler 적용\n",
        "\n",
        "일반화 성능을 위해 scaler 적용\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 예제 </font> <p>\n",
        "\n",
        "> ```python\n",
        "> standard_scaler = StandardScaler()\n",
        "> X_train = standard_scaler.fit_transform(X_train)\n",
        "> X_valid = standard_scaler.fit(X_valid)\n",
        "> X_test = standard_scaler.fit(X_test)\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "standard_scaler_x = StandardScaler()\n",
        "X_train = standard_scaler_x.fit_transform(X_train)\n",
        "X_valid = standard_scaler_x.transform(X_valid)\n",
        "X_test = standard_scaler_x.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset\n",
        "\n",
        "DataLoader에서 불러올 데이터의 형식을 지정하는 클래스. <br>\n",
        "\\_\\_getitem\\_\\_의 idx는 전체 데이터의 인덱스를 임의로 추출. <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;-> def \\_\\_len\\_\\_(self)에서 정의된 데이터의 크기를 사용하기에 **반드시 정의**하여야 함. <br>\n",
        "**Dataset class를 상속**받아 구현\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 예제 </font> <p>\n",
        "\n",
        "> ```python\n",
        "> class CustomDataset(Dataset):\n",
        ">     def __init__(self, x, y, ...):\n",
        ">         super().__init__()\n",
        ">         self.x = x\n",
        ">         self.y = y\n",
        "> \n",
        ">     def __len__(self):\n",
        ">         return len(self.x)\n",
        "> \n",
        ">     def __getitem__(self, idx):\n",
        ">         x = self.x[idx]\n",
        ">         y = self.y[idx]\n",
        "> \n",
        ">         x = torch.Tensor(x)\n",
        ">         y = torch.Tensor(y)\n",
        ">         \n",
        ">         return x, y\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PlanarDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super().__init__()\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.from_numpy(self.X[idx]).float()\n",
        "        y = torch.from_numpy(self.y[idx]).float()\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = PlanarDataset(X_train, y_train)\n",
        "valid_dataset = PlanarDataset(X_valid, y_valid)\n",
        "test_dataset = PlanarDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1.5398, 0.8657], dtype=torch.float64), tensor([1], dtype=torch.uint8))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataLoader\n",
        "\n",
        "데이터셋을 순회(iterate)할 때 사용. <br>\n",
        "각 순회(iteration)는 batch_size의 특징(feature)과 정답(label)의 묶음(batch)을 반환. <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 예제 </font> <p>\n",
        "\n",
        "> ```python\n",
        "> train_dataloader = DataLoader(\n",
        ">     dataset=train_dataset,\n",
        ">     batch_size=batch_size,\n",
        ">     shuffle=False,\n",
        ">     drop_last=True,\n",
        "> )\n",
        "> \n",
        "> valid_dataloader = DataLoader(\n",
        ">     dataset=valid_dataset,\n",
        ">     batch_size=batch_size,\n",
        ">     shuffle=False,\n",
        ">     drop_last=True,\n",
        "> )\n",
        "> \n",
        "> test_dataloader = DataLoader(\n",
        ">     dataset=test_dataset,\n",
        ">     batch_size=batch_size,\n",
        ">     shuffle=False,\n",
        ">     drop_last=True,\n",
        "> )\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = list(train_dataloader)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 2])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 1])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 모델 구조 정의\n",
        "\n",
        "학습 시 사용할 모델 아키텍처 정의. <br>\n",
        "- 모형 복잡도에 비해 데이터 수가 적으면 오버피팅 발생 가능성 높음\n",
        "- 모형 복잡도에 비해 데이터 수가 많으면 언더피팅 발생 가능성 높음 <br>\n",
        "\n",
        "**nn.Module을 상속받아 구현.** <br>\n",
        "생성자에서는 사용할 layer 정의 <br>\n",
        "forward 함수는 순전파 구현 <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 예제 </font> <p>\n",
        "\n",
        "> ```python\n",
        "> class MLP(nn.Module):\n",
        ">     def __init__(self, input_dim, hidden_dim, output_dim):\n",
        ">       super(MLP, self).__init__()\n",
        ">       self.fc1 = nn.Linear(input_dim, hidden_dim)   # input_dim: feature 수, hidden_dim: 중간에 사용될 뉴런의 수\n",
        ">       self.relu = nn.ReLU()                         # ReLU: activation function\n",
        ">       self.fc2 = nn.Linear(hidden_dim, output_dim)  # output_dim: target의 수\n",
        "> \n",
        ">     def forward(self, x):\n",
        ">       x = self.fc1(x)       # input layer -> hidden layer\n",
        ">       x = self.relu(x)      # hidden layer -> activation fuction\n",
        ">       x = self.fc2(x)       # activation function -> output layer\n",
        "> \n",
        ">       return x\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.tanh(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 모델 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp = MLP(2, 4, 1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5482],\n",
              "        [0.5851],\n",
              "        [0.5564],\n",
              "        [0.5521],\n",
              "        [0.5553],\n",
              "        [0.5512],\n",
              "        [0.5865],\n",
              "        [0.5318],\n",
              "        [0.5566],\n",
              "        [0.5548],\n",
              "        [0.5591],\n",
              "        [0.5360],\n",
              "        [0.5530],\n",
              "        [0.5376],\n",
              "        [0.5497],\n",
              "        [0.5481],\n",
              "        [0.5536],\n",
              "        [0.5625],\n",
              "        [0.5371],\n",
              "        [0.5444],\n",
              "        [0.5578],\n",
              "        [0.5507],\n",
              "        [0.5316],\n",
              "        [0.5483],\n",
              "        [0.5568],\n",
              "        [0.5349],\n",
              "        [0.5477],\n",
              "        [0.5849],\n",
              "        [0.5539],\n",
              "        [0.5478],\n",
              "        [0.5481],\n",
              "        [0.5534]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss, Optimizer 정의\n",
        "\n",
        "학습 시 사용할 loss와 optimizer 명시\n",
        "- loss: 정답과 모델 예측 값의 차이 계산\n",
        "- optimizer: parameter를 update할 로직 설정\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 예제 </font> <p>\n",
        "\n",
        "> ```python\n",
        "> criterion = nn.CrossEntropyLoss().to(device)\n",
        "> optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss().to(device)\n",
        "optimizer = optim.Adam(mlp.parameters(), learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X13XBcb7sNJ1"
      },
      "source": [
        "### Train & Validation\n",
        "\n",
        "<font style=\"font-size:20px\"> Train </font> <p>\n",
        "정의된 loss와 optimizer를 통해 학습 진행. <br>\n",
        "모델이 주어진 데이터에서만 잘 동작하는 것(overfitting)을 주의해야 함. <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> Validation </font> <p>\n",
        "학습 중인 모델의 성능을 평가하기 위한 데이터. <br>\n",
        "학습 데이터에 포함되어 있지 않기에 학습 시 validation data의 패턴을 학습하지는 않으나 <br>\n",
        "학습되지 않는 데이터를 통해 현재 학습되는 모델의 성능을 평가 <br>\n",
        "오버피팅을 확인하는 목적으로 주로 사용 <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "**오버피팅** <br>\n",
        "\n",
        "<img src=\"https://camo.githubusercontent.com/32695ae0709af770e85679280d75b1d377a43eac73cece31c1b03290ed8cd911/68747470733a2f2f696d67312e6461756d63646e2e6e65742f7468756d622f523132383078302f3f73636f64653d6d746973746f72793226666e616d653d6874747073253341253246253246626c6f672e6b616b616f63646e2e6e6574253246646e2532466f73304535253246627471456d6f5168385a36253246745532756e6636426e464e6d776234597873736f696b253246696d672e706e67\" width=\"500\" height=\"300\"/>\n",
        "\n",
        "주어진 데이터에 모델이 높은 결과를 내도록 적합되는 것 <br>\n",
        "이 경우 일반화 성능이 떨어지기에 오버피팅은 딥러닝 학습에서 중요한 이슈 <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 예제 </font> <p>\n",
        "\n",
        "> ```python\n",
        "> train_losses = []\n",
        "> train_accs = []\n",
        "> valid_losses = []\n",
        "> valid_accs = []\n",
        "> for epoch in tqdm(range(1, epochs+1)):      # 학습 횟수 설정\n",
        ">     total_train_loss = 0\n",
        ">     total_train_acc = 0\n",
        "> \n",
        ">     model.train()                           # dropout, batch norm 등 train과 train이 아닌 경우의 동작이 다를 때 학습 시 적용\n",
        ">     for X, y in train_loader:\n",
        ">         X = X.reshape(batch_size, -1).to(device)\n",
        ">         y = y.to(device)\n",
        "> \n",
        ">         optimizer.zero_grad()               # optimizer의 parameter에 대한 gradient 초기화\n",
        ">         y_pred = model(X)                   # model 예측값 계산 (순전파)\n",
        ">         train_loss = criterion(y_pred, y)   # model 예측값과 실제 값과의 loss 계산\n",
        ">         train_loss.backward()               # 계산된 loss를 바탕으로 각 parameter에 대한 기울기 계산\n",
        ">         optimizer.step()                    # 계산한 기울기를 바탕으로 parameter update\n",
        ">\n",
        ">         total_train_loss += train_loss\n",
        ">         total_train_acc += (y == result.argmax(axis=-1)).sum()\n",
        ">     \n",
        ">     mean_test_loss = total_test_loss / len(test_loader)\n",
        ">     mean_test_acc = total_test_acc / len(test_loader)\n",
        ">     train_losses.append(total_train_loss)\n",
        ">     train_accs.append(total_train_acc)\n",
        "> \n",
        ">     model.eval()                            # dropout, batch norm 등 train과 train이 아닌 경우의 동작이 다를 때 학습이 아닐 시 적용\n",
        ">     with torch.no_grad:                     # 가중치 업데이트를 진행하지 않기에 gradient 제거\n",
        ">         for X, y in valid_loader:\n",
        ">             X = X.reshape(batch_size, -1).to(device)\n",
        ">             y = y.to(device)\n",
        "> \n",
        ">             y_pred = model(X)                \n",
        ">             valid_loss = criterion(y_pred, y)\n",
        "> \n",
        ">             total_valid_loss += valid_loss\n",
        ">             total_valid_acc += (y == result.argmax(axis=-1)).sum()\n",
        "> \n",
        ">         mean_valid_loss = total_valid_loss / len(valid_loader)\n",
        ">         mean_valid_acc = total_valid_acc / len(valid_loader)\n",
        ">         valid_losses.append(mean_valid_loss)\n",
        ">         valid_accs.append(mean_valid_acc)\n",
        ">         \n",
        ">     print(f'Epoch: {epoch: 3d} | train_loss: {mean_train_loss: .6f} | train_acc = {mean_train_acc: .2f}% | valid_loss: {mean_valid_loss: .6f} | valid_acc = {mean_valid_acc: .2f}%')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[ 0.1235, -0.7493],\n",
              "         [ 2.0218, -0.7239],\n",
              "         [ 0.6409, -1.7714],\n",
              "         [ 0.9353, -1.5894],\n",
              "         [ 1.5733, -0.8141],\n",
              "         [ 0.7955, -1.7908],\n",
              "         [-0.5037, -0.6293],\n",
              "         [ 0.1177,  0.8696],\n",
              "         [-1.0359, -0.7096],\n",
              "         [ 0.4149,  0.4259],\n",
              "         [-0.5617,  0.4611],\n",
              "         [-0.0413, -0.0738],\n",
              "         [-0.0224, -0.0596],\n",
              "         [-1.6016, -0.4001],\n",
              "         [ 1.0667,  0.6860],\n",
              "         [ 0.0057,  0.0217],\n",
              "         [ 1.8929,  0.8730],\n",
              "         [ 0.3786,  1.4905],\n",
              "         [-1.8570, -0.7972],\n",
              "         [-0.6047,  0.7642],\n",
              "         [ 0.0230, -0.3342],\n",
              "         [ 1.2649,  0.2188],\n",
              "         [-1.9218,  0.6822],\n",
              "         [ 0.5966, -1.6951],\n",
              "         [-1.6789,  0.8298],\n",
              "         [-0.7206,  1.0694],\n",
              "         [ 0.0527,  0.4252],\n",
              "         [ 0.0451, -0.2418],\n",
              "         [-1.1847, -0.1921],\n",
              "         [-0.6141,  1.7307],\n",
              "         [ 1.1914,  0.1648],\n",
              "         [-0.4492, -0.0330]]),\n",
              " tensor([[1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.]])]"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(list(train_dataloader)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss:  0.5807 | train_acc:  66.07% | valid_loss:  0.6257 | valid_acc:  57.81%\n",
            "Epoch: 2 | train_loss:  0.5920 | train_acc:  65.62% | valid_loss:  0.6241 | valid_acc:  57.81%\n",
            "Epoch: 3 | train_loss:  0.5940 | train_acc:  66.52% | valid_loss:  0.6242 | valid_acc:  57.81%\n",
            "Epoch: 4 | train_loss:  0.5873 | train_acc:  66.96% | valid_loss:  0.6208 | valid_acc:  57.81%\n",
            "Epoch: 5 | train_loss:  0.5821 | train_acc:  66.96% | valid_loss:  0.6182 | valid_acc:  57.81%\n",
            "Epoch: 6 | train_loss:  0.5871 | train_acc:  66.07% | valid_loss:  0.6173 | valid_acc:  57.81%\n",
            "Epoch: 7 | train_loss:  0.5801 | train_acc:  66.96% | valid_loss:  0.6171 | valid_acc:  57.81%\n",
            "Epoch: 8 | train_loss:  0.5751 | train_acc:  66.96% | valid_loss:  0.6144 | valid_acc:  57.81%\n",
            "Epoch: 9 | train_loss:  0.5654 | train_acc:  67.86% | valid_loss:  0.6137 | valid_acc:  57.81%\n",
            "Epoch: 10 | train_loss:  0.5827 | train_acc:  67.86% | valid_loss:  0.6132 | valid_acc:  57.81%\n",
            "Epoch: 11 | train_loss:  0.5706 | train_acc:  67.86% | valid_loss:  0.6113 | valid_acc:  56.25%\n",
            "Epoch: 12 | train_loss:  0.5577 | train_acc:  68.30% | valid_loss:  0.6090 | valid_acc:  56.25%\n",
            "Epoch: 13 | train_loss:  0.5766 | train_acc:  68.30% | valid_loss:  0.6099 | valid_acc:  57.81%\n",
            "Epoch: 14 | train_loss:  0.5558 | train_acc:  69.20% | valid_loss:  0.6085 | valid_acc:  54.69%\n",
            "Epoch: 15 | train_loss:  0.5792 | train_acc:  68.30% | valid_loss:  0.6067 | valid_acc:  54.69%\n",
            "Epoch: 16 | train_loss:  0.5562 | train_acc:  70.09% | valid_loss:  0.6076 | valid_acc:  57.81%\n",
            "Epoch: 17 | train_loss:  0.5684 | train_acc:  69.20% | valid_loss:  0.6067 | valid_acc:  57.81%\n",
            "Epoch: 18 | train_loss:  0.5610 | train_acc:  68.75% | valid_loss:  0.6032 | valid_acc:  56.25%\n",
            "Epoch: 19 | train_loss:  0.5531 | train_acc:  69.64% | valid_loss:  0.6035 | valid_acc:  56.25%\n",
            "Epoch: 20 | train_loss:  0.5651 | train_acc:  68.30% | valid_loss:  0.6027 | valid_acc:  56.25%\n",
            "Epoch: 21 | train_loss:  0.5685 | train_acc:  68.30% | valid_loss:  0.6031 | valid_acc:  57.81%\n",
            "Epoch: 22 | train_loss:  0.5698 | train_acc:  69.20% | valid_loss:  0.6021 | valid_acc:  59.38%\n",
            "Epoch: 23 | train_loss:  0.5637 | train_acc:  69.20% | valid_loss:  0.6004 | valid_acc:  60.94%\n",
            "Epoch: 24 | train_loss:  0.5484 | train_acc:  71.88% | valid_loss:  0.5989 | valid_acc:  59.38%\n",
            "Epoch: 25 | train_loss:  0.5555 | train_acc:  70.98% | valid_loss:  0.5983 | valid_acc:  59.38%\n",
            "Epoch: 26 | train_loss:  0.5621 | train_acc:  69.64% | valid_loss:  0.5959 | valid_acc:  59.38%\n",
            "Epoch: 27 | train_loss:  0.5430 | train_acc:  71.88% | valid_loss:  0.5902 | valid_acc:  57.81%\n",
            "Epoch: 28 | train_loss:  0.5492 | train_acc:  70.54% | valid_loss:  0.5847 | valid_acc:  57.81%\n",
            "Epoch: 29 | train_loss:  0.5440 | train_acc:  72.32% | valid_loss:  0.5764 | valid_acc:  62.50%\n",
            "Epoch: 30 | train_loss:  0.5300 | train_acc:  76.34% | valid_loss:  0.5679 | valid_acc:  65.62%\n",
            "Epoch: 31 | train_loss:  0.5136 | train_acc:  81.25% | valid_loss:  0.5570 | valid_acc:  70.31%\n",
            "Epoch: 32 | train_loss:  0.5106 | train_acc:  81.70% | valid_loss:  0.5461 | valid_acc:  75.00%\n",
            "Epoch: 33 | train_loss:  0.4968 | train_acc:  83.04% | valid_loss:  0.5346 | valid_acc:  76.56%\n",
            "Epoch: 34 | train_loss:  0.5078 | train_acc:  83.93% | valid_loss:  0.5230 | valid_acc:  78.12%\n",
            "Epoch: 35 | train_loss:  0.4931 | train_acc:  84.82% | valid_loss:  0.5119 | valid_acc:  79.69%\n",
            "Epoch: 36 | train_loss:  0.4773 | train_acc:  85.71% | valid_loss:  0.5021 | valid_acc:  79.69%\n",
            "Epoch: 37 | train_loss:  0.4743 | train_acc:  86.16% | valid_loss:  0.4945 | valid_acc:  79.69%\n",
            "Epoch: 38 | train_loss:  0.4706 | train_acc:  85.71% | valid_loss:  0.4855 | valid_acc:  79.69%\n",
            "Epoch: 39 | train_loss:  0.4589 | train_acc:  86.16% | valid_loss:  0.4778 | valid_acc:  79.69%\n",
            "Epoch: 40 | train_loss:  0.4518 | train_acc:  86.16% | valid_loss:  0.4693 | valid_acc:  82.81%\n",
            "Epoch: 41 | train_loss:  0.4526 | train_acc:  86.61% | valid_loss:  0.4610 | valid_acc:  84.38%\n",
            "Epoch: 42 | train_loss:  0.4395 | train_acc:  87.95% | valid_loss:  0.4544 | valid_acc:  84.38%\n",
            "Epoch: 43 | train_loss:  0.4407 | train_acc:  87.05% | valid_loss:  0.4494 | valid_acc:  82.81%\n",
            "Epoch: 44 | train_loss:  0.4353 | train_acc:  87.05% | valid_loss:  0.4429 | valid_acc:  81.25%\n",
            "Epoch: 45 | train_loss:  0.4134 | train_acc:  87.95% | valid_loss:  0.4373 | valid_acc:  82.81%\n",
            "Epoch: 46 | train_loss:  0.4087 | train_acc:  87.95% | valid_loss:  0.4309 | valid_acc:  82.81%\n",
            "Epoch: 47 | train_loss:  0.4010 | train_acc:  87.50% | valid_loss:  0.4249 | valid_acc:  84.38%\n",
            "Epoch: 48 | train_loss:  0.3986 | train_acc:  88.84% | valid_loss:  0.4198 | valid_acc:  85.94%\n",
            "Epoch: 49 | train_loss:  0.4054 | train_acc:  87.95% | valid_loss:  0.4150 | valid_acc:  82.81%\n",
            "Epoch: 50 | train_loss:  0.4006 | train_acc:  88.84% | valid_loss:  0.4103 | valid_acc:  84.38%\n",
            "Epoch: 51 | train_loss:  0.3991 | train_acc:  87.50% | valid_loss:  0.4071 | valid_acc:  82.81%\n",
            "Epoch: 52 | train_loss:  0.3880 | train_acc:  88.84% | valid_loss:  0.4033 | valid_acc:  82.81%\n",
            "Epoch: 53 | train_loss:  0.3771 | train_acc:  88.39% | valid_loss:  0.3995 | valid_acc:  82.81%\n",
            "Epoch: 54 | train_loss:  0.3727 | train_acc:  87.95% | valid_loss:  0.3965 | valid_acc:  82.81%\n",
            "Epoch: 55 | train_loss:  0.3780 | train_acc:  87.50% | valid_loss:  0.3924 | valid_acc:  84.38%\n",
            "Epoch: 56 | train_loss:  0.3739 | train_acc:  87.95% | valid_loss:  0.3890 | valid_acc:  84.38%\n",
            "Epoch: 57 | train_loss:  0.3741 | train_acc:  88.39% | valid_loss:  0.3861 | valid_acc:  84.38%\n",
            "Epoch: 58 | train_loss:  0.3844 | train_acc:  87.05% | valid_loss:  0.3835 | valid_acc:  84.38%\n",
            "Epoch: 59 | train_loss:  0.3735 | train_acc:  87.95% | valid_loss:  0.3806 | valid_acc:  84.38%\n",
            "Epoch: 60 | train_loss:  0.3521 | train_acc:  90.18% | valid_loss:  0.3782 | valid_acc:  84.38%\n",
            "Epoch: 61 | train_loss:  0.3636 | train_acc:  89.73% | valid_loss:  0.3752 | valid_acc:  84.38%\n",
            "Epoch: 62 | train_loss:  0.3642 | train_acc:  87.95% | valid_loss:  0.3717 | valid_acc:  85.94%\n",
            "Epoch: 63 | train_loss:  0.3476 | train_acc:  90.18% | valid_loss:  0.3693 | valid_acc:  87.50%\n",
            "Epoch: 64 | train_loss:  0.3529 | train_acc:  88.84% | valid_loss:  0.3678 | valid_acc:  85.94%\n",
            "Epoch: 65 | train_loss:  0.3528 | train_acc:  88.84% | valid_loss:  0.3664 | valid_acc:  84.38%\n",
            "Epoch: 66 | train_loss:  0.3667 | train_acc:  87.95% | valid_loss:  0.3637 | valid_acc:  85.94%\n",
            "Epoch: 67 | train_loss:  0.3559 | train_acc:  88.84% | valid_loss:  0.3614 | valid_acc:  84.38%\n",
            "Epoch: 68 | train_loss:  0.3551 | train_acc:  88.39% | valid_loss:  0.3596 | valid_acc:  84.38%\n",
            "Epoch: 69 | train_loss:  0.3536 | train_acc:  89.29% | valid_loss:  0.3582 | valid_acc:  84.38%\n",
            "Epoch: 70 | train_loss:  0.3527 | train_acc:  88.84% | valid_loss:  0.3565 | valid_acc:  84.38%\n",
            "Epoch: 71 | train_loss:  0.3544 | train_acc:  88.39% | valid_loss:  0.3546 | valid_acc:  84.38%\n",
            "Epoch: 72 | train_loss:  0.3397 | train_acc:  90.62% | valid_loss:  0.3523 | valid_acc:  87.50%\n",
            "Epoch: 73 | train_loss:  0.3555 | train_acc:  89.29% | valid_loss:  0.3502 | valid_acc:  87.50%\n",
            "Epoch: 74 | train_loss:  0.3456 | train_acc:  88.84% | valid_loss:  0.3493 | valid_acc:  87.50%\n",
            "Epoch: 75 | train_loss:  0.3499 | train_acc:  89.29% | valid_loss:  0.3488 | valid_acc:  84.38%\n",
            "Epoch: 76 | train_loss:  0.3415 | train_acc:  87.95% | valid_loss:  0.3468 | valid_acc:  84.38%\n",
            "Epoch: 77 | train_loss:  0.3479 | train_acc:  89.73% | valid_loss:  0.3453 | valid_acc:  85.94%\n",
            "Epoch: 78 | train_loss:  0.3437 | train_acc:  89.29% | valid_loss:  0.3445 | valid_acc:  84.38%\n",
            "Epoch: 79 | train_loss:  0.3485 | train_acc:  89.29% | valid_loss:  0.3429 | valid_acc:  85.94%\n",
            "Epoch: 80 | train_loss:  0.3182 | train_acc:  91.96% | valid_loss:  0.3423 | valid_acc:  84.38%\n",
            "Epoch: 81 | train_loss:  0.3424 | train_acc:  89.29% | valid_loss:  0.3408 | valid_acc:  87.50%\n",
            "Epoch: 82 | train_loss:  0.3341 | train_acc:  90.18% | valid_loss:  0.3396 | valid_acc:  87.50%\n",
            "Epoch: 83 | train_loss:  0.3314 | train_acc:  90.18% | valid_loss:  0.3387 | valid_acc:  87.50%\n",
            "Epoch: 84 | train_loss:  0.3205 | train_acc:  90.18% | valid_loss:  0.3379 | valid_acc:  87.50%\n",
            "Epoch: 85 | train_loss:  0.3208 | train_acc:  90.18% | valid_loss:  0.3367 | valid_acc:  87.50%\n",
            "Epoch: 86 | train_loss:  0.3329 | train_acc:  89.29% | valid_loss:  0.3356 | valid_acc:  87.50%\n",
            "Epoch: 87 | train_loss:  0.3310 | train_acc:  91.07% | valid_loss:  0.3334 | valid_acc:  87.50%\n",
            "Epoch: 88 | train_loss:  0.3205 | train_acc:  91.07% | valid_loss:  0.3322 | valid_acc:  87.50%\n",
            "Epoch: 89 | train_loss:  0.3369 | train_acc:  90.18% | valid_loss:  0.3312 | valid_acc:  87.50%\n",
            "Epoch: 90 | train_loss:  0.3310 | train_acc:  91.07% | valid_loss:  0.3297 | valid_acc:  87.50%\n",
            "Epoch: 91 | train_loss:  0.3264 | train_acc:  90.62% | valid_loss:  0.3294 | valid_acc:  87.50%\n",
            "Epoch: 92 | train_loss:  0.3254 | train_acc:  90.62% | valid_loss:  0.3284 | valid_acc:  87.50%\n",
            "Epoch: 93 | train_loss:  0.3105 | train_acc:  91.07% | valid_loss:  0.3283 | valid_acc:  87.50%\n",
            "Epoch: 94 | train_loss:  0.3365 | train_acc:  89.29% | valid_loss:  0.3274 | valid_acc:  87.50%\n",
            "Epoch: 95 | train_loss:  0.3042 | train_acc:  91.52% | valid_loss:  0.3277 | valid_acc:  87.50%\n",
            "Epoch: 96 | train_loss:  0.3393 | train_acc:  88.84% | valid_loss:  0.3284 | valid_acc:  85.94%\n",
            "Epoch: 97 | train_loss:  0.3210 | train_acc:  89.73% | valid_loss:  0.3262 | valid_acc:  87.50%\n",
            "Epoch: 98 | train_loss:  0.3231 | train_acc:  90.18% | valid_loss:  0.3247 | valid_acc:  87.50%\n",
            "Epoch: 99 | train_loss:  0.3224 | train_acc:  89.73% | valid_loss:  0.3236 | valid_acc:  87.50%\n",
            "Epoch: 100 | train_loss:  0.3165 | train_acc:  90.62% | valid_loss:  0.3225 | valid_acc:  87.50%\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "train_accs = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "for epoch in range(1, epochs+1):\n",
        "    ##################### train #####################\n",
        "    total_train_loss = 0\n",
        "    total_train_acc = 0\n",
        "\n",
        "    mlp.train()\n",
        "    for X, y in train_dataloader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()               # set gradient 0\n",
        "        logit = mlp(X)                      # calculate y_pred\n",
        "        train_loss = criterion(logit, y)    # calculate loss\n",
        "        train_loss.backward()               # backward\n",
        "        optimizer.step()                    # parameter update\n",
        "\n",
        "        predicted_label = torch.where(logit > 0.5, 1, 0)\n",
        "        train_acc = (predicted_label == y).float().mean()\n",
        "        total_train_loss += train_loss\n",
        "        total_train_acc += train_acc\n",
        "    \n",
        "    mean_train_loss = total_train_loss / len(train_dataloader)\n",
        "    mean_train_acc = total_train_acc / len(train_dataloader)\n",
        "    train_losses.append(mean_train_loss)\n",
        "    train_accs.append(mean_train_acc)\n",
        "\n",
        "    ##################### validation #####################\n",
        "    total_valid_loss = 0\n",
        "    total_valid_acc = 0\n",
        "\n",
        "    mlp.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, y in valid_dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            logit = mlp(X)                      # calculate y_pred\n",
        "            valid_loss = criterion(logit, y)    # calculate loss\n",
        "\n",
        "            predicted_label = torch.where(logit > 0.5, 1, 0)\n",
        "            valid_acc = (predicted_label == y).float().mean()\n",
        "            total_valid_loss += valid_loss\n",
        "            total_valid_acc += valid_acc\n",
        "        \n",
        "    mean_valid_loss = total_valid_loss / len(valid_dataloader)\n",
        "    mean_valid_acc = total_valid_acc / len(valid_dataloader)\n",
        "    valid_losses.append(mean_valid_loss)\n",
        "    valid_accs.append(mean_valid_acc)\n",
        "\n",
        "    print(f'Epoch: {epoch} | train_loss: {mean_train_loss: .4f} | train_acc: {mean_train_acc*100: .2f}% | valid_loss: {mean_valid_loss: .4f} | valid_acc: {mean_valid_acc*100: .2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overfitting check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.DataFrame({\n",
        "    'train_loss': [train_loss.item() for train_loss in train_losses],\n",
        "    'valid_loss': [valid_loss.item() for valid_loss in valid_losses]\n",
        "}).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test\n",
        "\n",
        "학습에서 사용한 모델의 성능 평가. <br>\n",
        "train의 정확도가 높았을지라도 test의 정확도가 낮을 수 있음. <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;이는 학습 데이터와 test 데이터가 상이함을 의미. <br>\n",
        "학습 평가 시 eval() 사용. <br>\n",
        "validation data와의 차이는 validation data는 학습 중에 사용되는 데이터이지만 <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;테스트 데이터는 학습이 종료된 이후 사용되는 데이터 <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> 사용 예제 </font> <p>\n",
        "\n",
        "> ```python\n",
        "> model.eval()                            # dropout, batch norm 등 train과 train이 아닌 경우의 동작이 다를 때 학습이 아닐 시 적용\n",
        "> with torch.no_grad:                     # 가중치 업데이트를 진행하지 않기에 gradient 제거\n",
        ">     for X, y in test_loader:\n",
        ">         X = X.reshape(batch_size, -1).to(device)\n",
        ">         y = y.to(device)\n",
        "> \n",
        ">         y_pred = model(X)                \n",
        ">         test_loss = criterion(y_pred, y)\n",
        "> \n",
        ">         total_test_loss += test_loss\n",
        ">         total_test_acc += (y == result.argmax(axis=-1)).sum()\n",
        "> \n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_test_loss = 0 \n",
        "total_test_acc = 0 \n",
        "\n",
        "mlp.eval()\n",
        "with torch.no_grad():\n",
        "    for X, y in test_dataloader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        logit = mlp(X)                     # calculate y_pred\n",
        "        test_loss = criterion(logit, y)    # calculate loss\n",
        "\n",
        "        predicted_label = torch.where(logit > 0.5, 1, 0)\n",
        "        test_acc = (predicted_label == y).float().mean()\n",
        "        total_test_loss += test_loss\n",
        "        total_test_acc += test_acc\n",
        "\n",
        "    mean_test_loss = total_test_loss / len(test_dataloader)\n",
        "    mean_test_acc = total_test_acc / len(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.859375"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean_test_acc.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save & Load\n",
        "\n",
        "학습된 모델의 weight를 저장 및 로드\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> Save </font> <p>\n",
        "\n",
        "> ```python\n",
        "> torch.save(model.state_dict(), './checkpoint/model_state_dict.pth')\n",
        "> ```\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> Load </font> <p>\n",
        "\n",
        "> ```python\n",
        "> model = Model()\n",
        "> model.load_state_dict(torch.load('./checkpoint/model_state_dict.pth'), map_location='cpu')\n",
        "> ```\n",
        "\n",
        "<br>\n",
        "\n",
        "<font style=\"font-size:20px\"> torch script </font> <p>\n",
        "\n",
        "```python\n",
        "scripted_model = torch.jit.script(model)\n",
        "\n",
        "# save\n",
        "scripted_model.save('./checkpoint/scripted_model.pt')\n",
        "\n",
        "# load\n",
        "loaded_model = torch.jit.load('./checkpoint/scripted_model.pt')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(mlp.state_dict(), './model/mlp.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_mlp = MLP(2, 4, 1)\n",
        "new_mlp.load_state_dict(torch.load('./model/mlp.pth'))\n",
        "new_mlp.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "scripted_model = torch.jit.script(mlp)\n",
        "scripted_model.save('./model/scripted_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_scripted_model = torch.jit.load('./model/scripted_model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEim4kEdi4VB"
      },
      "source": [
        "## MNIST\n",
        "\n",
        "- MNIST 데이터베이스 (Modified National Institute of Standards and Technology database)는 <br>\n",
        "손으로 쓴 숫자들로 이루어진 대형 데이터베이스\n",
        "- 딥러닝 예제에서 자주 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 1/20 [00:00<00:12,  1.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss:  1.6072 | train_acc:  87.02% | valid_loss:  1.5341 | valid_acc:  93.06%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 2/20 [00:01<00:12,  1.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 | train_loss:  1.5217 | train_acc:  94.35% | valid_loss:  1.5121 | valid_acc:  95.31%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 3/20 [00:02<00:12,  1.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3 | train_loss:  1.5054 | train_acc:  95.88% | valid_loss:  1.5036 | valid_acc:  95.97%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 4/20 [00:02<00:11,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4 | train_loss:  1.4974 | train_acc:  96.58% | valid_loss:  1.4972 | valid_acc:  96.56%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 5/20 [00:03<00:11,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5 | train_loss:  1.4908 | train_acc:  97.24% | valid_loss:  1.4993 | valid_acc:  96.41%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 6/20 [00:04<00:10,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6 | train_loss:  1.4867 | train_acc:  97.61% | valid_loss:  1.4921 | valid_acc:  97.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 7/20 [00:05<00:10,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7 | train_loss:  1.4837 | train_acc:  97.89% | valid_loss:  1.4958 | valid_acc:  96.64%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 8/20 [00:06<00:09,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 8 | train_loss:  1.4811 | train_acc:  98.13% | valid_loss:  1.4893 | valid_acc:  97.37%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 9/20 [00:06<00:08,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 9 | train_loss:  1.4784 | train_acc:  98.38% | valid_loss:  1.4887 | valid_acc:  97.36%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 10/20 [00:07<00:07,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10 | train_loss:  1.4781 | train_acc:  98.39% | valid_loss:  1.4877 | valid_acc:  97.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 11/20 [00:08<00:07,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11 | train_loss:  1.4757 | train_acc:  98.64% | valid_loss:  1.4868 | valid_acc:  97.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 12/20 [00:09<00:06,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12 | train_loss:  1.4757 | train_acc:  98.62% | valid_loss:  1.4867 | valid_acc:  97.54%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 13/20 [00:10<00:05,  1.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 13 | train_loss:  1.4740 | train_acc:  98.80% | valid_loss:  1.4889 | valid_acc:  97.24%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 14/20 [00:10<00:04,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 14 | train_loss:  1.4738 | train_acc:  98.80% | valid_loss:  1.4883 | valid_acc:  97.35%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 15/20 [00:11<00:04,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 15 | train_loss:  1.4734 | train_acc:  98.84% | valid_loss:  1.4880 | valid_acc:  97.31%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 16/20 [00:12<00:03,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 16 | train_loss:  1.4721 | train_acc:  98.94% | valid_loss:  1.4856 | valid_acc:  97.62%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 17/20 [00:13<00:02,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 17 | train_loss:  1.4712 | train_acc:  99.06% | valid_loss:  1.4847 | valid_acc:  97.69%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 18/20 [00:14<00:01,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 18 | train_loss:  1.4715 | train_acc:  99.00% | valid_loss:  1.4873 | valid_acc:  97.44%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 19/20 [00:15<00:00,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19 | train_loss:  1.4704 | train_acc:  99.11% | valid_loss:  1.4842 | valid_acc:  97.72%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:16<00:00,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 20 | train_loss:  1.4698 | train_acc:  99.18% | valid_loss:  1.4859 | valid_acc:  97.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# seed\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# hyperprameter\n",
        "batch_size = 256\n",
        "epochs = 20\n",
        "learning_rate = 4e-3\n",
        "\n",
        "# data and preprocessing\n",
        "train = ds.MNIST(\n",
        "    root='data/mnist',\n",
        "    train=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "test = ds.MNIST(\n",
        "    root='data/mnist',\n",
        "    train=False,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "train, valid = train_test_split(train, test_size=0.2)\n",
        "\n",
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        X, y = self.data[idx]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "train_dataset = MNISTDataset(train)\n",
        "valid_dataset = MNISTDataset(valid)\n",
        "test_dataset = MNISTDataset(test)\n",
        "\n",
        "# data loader\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "# model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "    \n",
        "        self.linear = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.output(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = Model(28*28, 256, 10).to(device)\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        ")\n",
        "\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    ###################### train ######################\n",
        "    total_train_acc = 0\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for X, y in train_dataloader:\n",
        "        X = X.to(device)\n",
        "        X = X.flatten(start_dim=1)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X)\n",
        "        logit = F.softmax(output, dim=-1)\n",
        "        train_loss = criterion(logit, y)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc = (logit.argmax(dim=-1) == y).float().mean()\n",
        "        total_train_acc += train_acc\n",
        "        total_train_loss += train_loss\n",
        "    \n",
        "    mean_train_acc = total_train_acc / len(train_dataloader)\n",
        "    mean_train_loss = total_train_loss / len(train_dataloader)\n",
        "    train_losses.append(mean_train_loss.item())\n",
        "    train_accs.append(mean_train_acc)\n",
        "\n",
        "    ###################### valid ######################\n",
        "    total_valid_acc = 0\n",
        "    total_valid_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, y in valid_dataloader:\n",
        "            X = X.to(device)\n",
        "            X = X.flatten(start_dim=1)\n",
        "            y = y.to(device)\n",
        "\n",
        "            output = model(X)\n",
        "            logit = F.softmax(output, dim=-1)\n",
        "            valid_loss = criterion(logit, y)\n",
        "\n",
        "            valid_acc = (logit.argmax(dim=-1) == y).float().mean()\n",
        "            total_valid_acc += valid_acc\n",
        "            total_valid_loss += valid_loss\n",
        "        \n",
        "    mean_valid_acc = total_valid_acc / len(valid_dataloader)\n",
        "    mean_valid_loss = total_valid_loss / len(valid_dataloader)\n",
        "    valid_losses.append(mean_valid_loss.item())\n",
        "    valid_accs.append(mean_valid_acc)\n",
        "\n",
        "    print(f'Epoch: {epoch} | train_loss: {mean_train_loss: .4f} | train_acc: {mean_train_acc*100: .2f}% | valid_loss: {mean_valid_loss: .4f} | valid_acc: {mean_valid_acc*100: .2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19628\\1641817439.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('./model/mnist.pth'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 276,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.save(model.state_dict(), './model/mnist.pth')\n",
        "model = Model(28*28, 256, 10)\n",
        "model.load_state_dict(torch.load('./model/mnist.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9778645634651184\n"
          ]
        }
      ],
      "source": [
        "total_test_acc = 0\n",
        "total_test_loss = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X, y in test_dataloader:\n",
        "        X = X.to(device)\n",
        "        X = X.flatten(start_dim=1)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(X)\n",
        "        logit = F.softmax(output, dim=-1)\n",
        "        test_loss = criterion(logit, y)\n",
        "\n",
        "        test_acc = (logit.argmax(dim=-1) == y).float().mean()\n",
        "        total_test_acc += test_acc\n",
        "        total_test_loss += test_loss\n",
        "    \n",
        "mean_test_acc = total_test_acc / len(test_dataloader)\n",
        "print(mean_test_acc.item())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "e4af6128c7e0808fede432f38729c473c5b0d80882e83c469acdb54455c56396"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
