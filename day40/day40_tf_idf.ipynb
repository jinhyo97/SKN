{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kiwipiepy import Kiwi\n",
    "from kiwipiepy.utils import Stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "reference: [TF-IDF](https://wikidocs.net/31698)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기자회견"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_pickle('./data/comments_minheejin.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiwi = Kiwi()\n",
    "# 단어 사전에 단어 추가\n",
    "kiwi.add_user_word('어도어', 'NNP')\n",
    "kiwi.add_user_word('빌리프랩', 'NNP')\n",
    "kiwi.add_user_word('빌리프렙', 'NNP')\n",
    "kiwi.add_user_word('아일리스', 'NNP')\n",
    "kiwi.add_user_word('르세라핌', 'NNP')\n",
    "kiwi.add_user_word('피프티피프티', 'NNP')\n",
    "kiwi.add_user_word('뉴진스', 'NNP')\n",
    "kiwi.add_user_word('아일릿', 'NNP')\n",
    "kiwi.add_user_word('하이브', 'NNP')\n",
    "kiwi.add_user_word('방시혁', 'NNP')\n",
    "kiwi.add_user_word('힛뱅맨', 'NNP')\n",
    "kiwi.add_user_word('힛맨뱅', 'NNP')\n",
    "kiwi.add_user_word('민희진', 'NNP')\n",
    "kiwi.add_user_word('미니진', 'NNP')\n",
    "kiwi.add_user_word('희진', 'NNP')\n",
    "kiwi.add_user_word('레퍼런스', 'NNG')\n",
    "kiwi.add_user_word('언플', 'NNG')\n",
    "kiwi.add_user_word('대퓨', 'NNG')\n",
    "kiwi.add_user_word('대퓨님', 'NNG')\n",
    "kiwi.add_user_word('개저씨', 'NNG')\n",
    "\n",
    "# 불용어 사전에 불용어 추가\n",
    "stopwords = Stopwords()\n",
    "stopwords.add(('웩퉥', 'NNG'))\n",
    "stopwords.add(('결국', 'NNG'))\n",
    "\n",
    "def extract_tokens(string: str, tokenizer: Kiwi, stopwords: Stopwords, tags={'NNP', 'NNG'}):\n",
    "    # 주어진 문자열(string)을 입력으로 받아, 지정된 품사 태그와 길이 조건을 만족하는 토큰들을 추출하는 함수\n",
    "\n",
    "    # Kiwi 객체를 사용하여 문자열을 토크나이즈(tokenize)하고, 불용어(stopwords)를 적용\n",
    "    tokens = tokenizer.tokenize(string, stopwords=stopwords)\n",
    "    \n",
    "    # 토크나이즈된 토큰 중에서, 지정된 태그 집합(tags)에 포함되며 길이가 2 이상인 토큰들의 형태소를 추출하여 리스트에 저장\n",
    "    target_tokens = [token.form for token in tokens if token.tag in tags and len(token.form) >= 2]\n",
    "\n",
    "    # 조건을 만족하는 토큰들의 리스트를 반환\n",
    "    return target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments 데이터프레임의 'textOriginal' 열에 있는 텍스트에 대해\n",
    "# extract_tokens 함수를 적용하여 추출된 토큰들을 'tokens' 열에 저장\n",
    "comments['tokens'] = comments.textOriginal.apply(lambda x: extract_tokens(x, kiwi, stopwords))\n",
    "\n",
    "# 'tokens' 열에 있는 토큰 리스트를 문자열로 변환(join)하여, \n",
    "# 각각의 리스트를 공백으로 구분된 문자열로 합치고, 이를 리스트로 변환하여 'tokens' 변수에 저장\n",
    "tokens = comments.tokens.str.join(' ').tolist()  # 혹은 comments.tokens.apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer 객체를 생성하여, 단어의 빈도를 계산할 준비를 함\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# tokens 리스트에 있는 각 문서(토큰 문자열)에 대해, CountVectorizer를 적용하여 문서-단어 행렬(dtm)을 생성\n",
    "dtm = count_vector.fit_transform(tokens)\n",
    "\n",
    "# dtm을 배열 형태로 변환한 후, Pandas DataFrame으로 변환\n",
    "# 각 열은 CountVectorizer에서 추출된 단어(특징)를 나타내고, 각 행은 문서를 나타냄\n",
    "dtm = pd.DataFrame(\n",
    "    dtm.toarray(),  # 희소 행렬을 밀집 배열로 변환\n",
    "    columns=count_vector.get_feature_names_out(),  # 각 열의 이름을 단어(feature)로 설정\n",
    ")\n",
    "\n",
    "# 최종적으로 생성된 문서-단어 행렬을 출력\n",
    "dtm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer 객체를 생성하여, 단어의 TF-IDF 값을 계산할 준비를 함\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# tokens 리스트에 있는 각 문서(토큰 문자열)에 대해, TfidfVectorizer를 적용하여 TF-IDF 행렬(tfidf_vector)을 생성\n",
    "tfidf_vector = tfidf.fit_transform(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/10169 [00:01<07:36, 22.24it/s]C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15420\\2504669301.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cos_sim = vector@reference.T / (np.sqrt((vector**2).sum()) * np.sqrt((reference**2).sum()))\n",
      " 10%|█         | 1041/10169 [00:47<06:57, 21.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## for문 사용하지 않고 계산 (optional)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m similarities \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vector \u001b[38;5;129;01min\u001b[39;00m tqdm(tfidf_vector\u001b[38;5;241m.\u001b[39mtoarray()):\n\u001b[0;32m      5\u001b[0m     reference \u001b[38;5;241m=\u001b[39m tfidf_vector\u001b[38;5;241m.\u001b[39mtoarray()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m     cos_sim \u001b[38;5;241m=\u001b[39m vector\u001b[38;5;129m@reference\u001b[39m\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39msqrt((vector\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum()) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt((reference\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum()))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\std.py:1191\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1189\u001b[0m dt \u001b[38;5;241m=\u001b[39m cur_t \u001b[38;5;241m-\u001b[39m last_print_t\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m mininterval \u001b[38;5;129;01mand\u001b[39;00m cur_t \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_start_t:\n\u001b[1;32m-> 1191\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_print_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1192\u001b[0m     last_print_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_n\n\u001b[0;32m   1193\u001b[0m     last_print_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_t\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\std.py:1242\u001b[0m, in \u001b[0;36mtqdm.update\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_dn(dn)\n\u001b[0;32m   1241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_dt(dt)\n\u001b[1;32m-> 1242\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlock_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlock_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_miniters:\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;66;03m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m     \u001b[38;5;66;03m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;66;03m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;66;03m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;66;03m# at least 5 more iterations.\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxinterval \u001b[38;5;129;01mand\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxinterval:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\std.py:1347\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[1;34m(self, nolock, lock_args)\u001b[0m\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m-> 1347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\std.py:1495\u001b[0m, in \u001b[0;36mtqdm.display\u001b[1;34m(self, msg, pos)\u001b[0m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(pos)\n\u001b[1;32m-> 1495\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[0;32m   1497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(\u001b[38;5;241m-\u001b[39mpos)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\std.py:459\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_status\u001b[39m(s):\n\u001b[0;32m    458\u001b[0m     len_s \u001b[38;5;241m=\u001b[39m disp_len(s)\n\u001b[1;32m--> 459\u001b[0m     \u001b[43mfp_write\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_len\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlen_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m     last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m len_s\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\std.py:452\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfp_write\u001b[39m(s):\n\u001b[1;32m--> 452\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m     fp_flush()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\utils.py:196\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\iostream.py:694\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\iostream.py:590\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel\\iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     f()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\zmq\\sugar\\socket.py:701\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    695\u001b[0m             data,\n\u001b[0;32m    696\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    697\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    698\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    699\u001b[0m         )\n\u001b[0;32m    700\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m_zmq.py:1092\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_zmq.py:1140\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_zmq.py:1339\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_zmq.py:160\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## for문 사용하지 않고 계산 (optional)\n",
    "\n",
    "# 유사도를 저장할 리스트 초기화\n",
    "similarities = []\n",
    "\n",
    "# tfidf_vector의 각 문서 벡터에 대해 반복문 실행 (진행 상황을 표시하기 위해 tqdm 사용)\n",
    "for vector in tqdm(tfidf_vector.toarray()):\n",
    "    # 첫 번째 문서를 기준(reference)으로 설정\n",
    "    reference = tfidf_vector.toarray()[0]\n",
    "    \n",
    "    # 코사인 유사도 계산: 두 벡터의 내적을 벡터의 크기(노름)의 곱으로 나눈 값\n",
    "    cos_sim = vector @ reference.T / (np.sqrt((vector**2).sum()) * np.sqrt((reference**2).sum()))\n",
    "    \n",
    "    # 계산된 코사인 유사도를 similarities 리스트에 추가\n",
    "    similarities.append(cos_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    4,     4,     6, ..., 10162, 10163, 10168], dtype=int64),\n",
       " array([ 3040, 10068,  2750, ...,  7847,  4162, 10142], dtype=int64))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf_vector의 문서들 간의 코사인 유사도를 계산\n",
    "similarities = cosine_similarity(tfidf_vector.toarray())\n",
    "\n",
    "# 대각선의 값(자기 자신과의 유사도)을 0으로 채워서 제외\n",
    "np.fill_diagonal(similarities, 0)\n",
    "\n",
    "# 유사도가 0.9를 초과하는 위치(인덱스)를 반환\n",
    "np.where(similarities > 0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수정이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day 39 comments data, video_id: JPaubSOSxeM에 대해서 유사 댓글 분석\n",
    "comments = pd.read_csv('./data/comments.csv')\n",
    "comments = comments.query('video_id==\"JPaubSOSxeM\"').drop(columns=['video_id'])\n",
    "comments['tokens'] = comments.comments.apply(lambda x: extract_tokens(x, kiwi, stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "tf_idf_vector = tf_idf.fit_transform(comments.tokens.str.join(' ').tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vector = tf_idf_vector.toarray()\n",
    "similarities = cosine_similarity(tf_idf_vector)\n",
    "np.fill_diagonal(similarities, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   1,    4,    5, ..., 3836, 3836, 3836], dtype=int64),\n",
       " array([  28, 2062,  589, ..., 3688, 3702, 3729], dtype=int64))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(similarities > 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>아영님 짧대에서 보다가 여기서 보니까 신기하당</td>\n",
       "      <td>[아영, 짧대]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>아영님 어디서 많이 봤다했더니 짧대에 나오신분이셨네요</td>\n",
       "      <td>[짧대]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          comments    tokens\n",
       "5        아영님 짧대에서 보다가 여기서 보니까 신기하당  [아영, 짧대]\n",
       "589  아영님 어디서 많이 봤다했더니 짧대에 나오신분이셨네요      [짧대]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.iloc[[5, 589]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [00:00<00:00, 14737.48it/s]\n"
     ]
    }
   ],
   "source": [
    "news = []\n",
    "file_paths = glob.glob('./data/news_data/**/*.txt', recursive=True)\n",
    "for file_path in tqdm(file_paths):\n",
    "    with open(file_path) as file:\n",
    "        temp = file.read()\n",
    "        news.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.DataFrame(news, columns=['contents'])\n",
    "news = news.drop_duplicates()\n",
    "news.contents = news.contents.str.replace('\\s{1,}', ' ', regex=True)\n",
    "news['tokens'] = news.contents.apply(lambda x: extract_tokens(x, kiwi, stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = news.tokens.str.join(' ').tolist()\n",
    "tf_idf = TfidfVectorizer()\n",
    "tf_idf_vector = tf_idf.fit_transform(tokens)\n",
    "cos_sim = cosine_similarity(tf_idf_vector.toarray())\n",
    "np.fill_diagonal(cos_sim, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([195, 232, 239, 242, 289], dtype=int64),\n",
       " array([ 289,  239,  232, 1025,  195], dtype=int64))"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.where(cos_sim > 0.9)[0][:5], np.where(cos_sim > 0.9)[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>반포현대 재건축 부담금 850만→1억4천만원으로 16배 '껑충'(종합) 서초구청, ...</td>\n",
       "      <td>[반포, 현대, 건축, 부담금, 종합, 서초구청, 조합, 통지, 조합, 구청, 고무...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>재건축 부담금 '첫타자' 반포현대, 예상액 1억4천만원 서초구청, 조합에 통지…조합...</td>\n",
       "      <td>[건축, 부담금, 타자, 반포, 현대, 예상액, 서초구청, 조합, 통지, 조합, 예...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               contents  \\\n",
       "248   반포현대 재건축 부담금 850만→1억4천만원으로 16배 '껑충'(종합) 서초구청, ...   \n",
       "1049  재건축 부담금 '첫타자' 반포현대, 예상액 1억4천만원 서초구청, 조합에 통지…조합...   \n",
       "\n",
       "                                                 tokens  \n",
       "248   [반포, 현대, 건축, 부담금, 종합, 서초구청, 조합, 통지, 조합, 구청, 고무...  \n",
       "1049  [건축, 부담금, 타자, 반포, 현대, 예상액, 서초구청, 조합, 통지, 조합, 예...  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.iloc[[242, 1025]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다트 사업의 개요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./data/crawl_data.pickle')\n",
    "data = data.query('dates == \"2022.03\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['business_info'] = data['사업의 개요'].apply(lambda x: BeautifulSoup(x, 'lxml').text)\n",
    "data.business_info = data.business_info.str.replace('\\s+', ' ', regex=True)\n",
    "data.business_info = data.business_info.str.replace('\\d?\\.? ? 사업의 개요 ?', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tokens(string: str, tokenizer: Kiwi, stopwords: Stopwords, tags={'NNP', 'NNG'}):\n",
    "    # 주어진 문자열(string)을 입력으로 받아, 지정된 품사 태그와 길이 조건을 만족하는 토큰들을 추출하는 함수\n",
    "\n",
    "    # Kiwi 객체를 사용하여 문자열을 토크나이즈(tokenize)하고, 불용어(stopwords)를 적용\n",
    "    tokens = tokenizer.tokenize(string, stopwords=stopwords)\n",
    "    \n",
    "    # 토크나이즈된 토큰 중에서, 지정된 태그 집합(tags)에 포함되며 길이가 2 이상인 토큰들의 형태소를 추출하여 리스트에 저장\n",
    "    target_tokens = [token.form for token in tokens if token.tag in tags and len(token.form) >= 2]\n",
    "\n",
    "    # 조건을 만족하는 토큰들의 리스트를 반환\n",
    "    return target_tokens\n",
    "\n",
    "kiwi = Kiwi()\n",
    "kiwi.add_user_word('바이오시밀러', 'NNG')\n",
    "kiwi.add_user_word('웅진씽크빅', 'NNP')\n",
    "\n",
    "stopwords = Stopwords()\n",
    "stopwords.add(('당사', 'NNG'))\n",
    "stopwords.add(('산업', 'NNG'))\n",
    "stopwords.add(('특성', 'NNG'))\n",
    "\n",
    "data['tokens'] = data.business_info.apply(lambda x: extract_tokens(x, kiwi, stopwords))\n",
    "data['tokens_joined'] = data.tokens.str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data.tokens_joined.tolist()\n",
    "tf_idf = TfidfVectorizer()\n",
    "tf_idf_vector = tf_idf.fit_transform(documents)\n",
    "similarities = cosine_similarity(tf_idf_vector.toarray())\n",
    "np.fill_diagonal(similarities, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   1, ..., 789, 789, 790], dtype=int64),\n",
       " array([346, 775, 439, ..., 326, 741, 608], dtype=int64))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(similarities > 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corp_code</th>\n",
       "      <th>corp_name</th>\n",
       "      <th>stock_code</th>\n",
       "      <th>corp_cls</th>\n",
       "      <th>report_nm</th>\n",
       "      <th>rcept_no</th>\n",
       "      <th>flr_nm</th>\n",
       "      <th>rcept_dt</th>\n",
       "      <th>rm</th>\n",
       "      <th>modified_report_nm</th>\n",
       "      <th>dates</th>\n",
       "      <th>회사의 개요</th>\n",
       "      <th>사업의 개요</th>\n",
       "      <th>business_info</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01510489</td>\n",
       "      <td>프레스티지바이오파마</td>\n",
       "      <td>950210</td>\n",
       "      <td>Y</td>\n",
       "      <td>분기보고서 (2022.03)</td>\n",
       "      <td>20220530001024</td>\n",
       "      <td>프레스티지바이오파마</td>\n",
       "      <td>20220530</td>\n",
       "      <td></td>\n",
       "      <td>분기보고서 (2022.03)</td>\n",
       "      <td>2022.03</td>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...</td>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...</td>\n",
       "      <td>당사는 바이오시밀러와 항체 신약 개발에 집중해 온 항체의약품 개발 전문 제약회사로...</td>\n",
       "      <td>[바이오시밀러, 항체, 신약, 개발, 집중, 항체, 의약품, 개발, 전문, 제약, ...</td>\n",
       "      <td>바이오시밀러 항체 신약 개발 집중 항체 의약품 개발 전문 제약 회사 일자 한국 유가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>00401731</td>\n",
       "      <td>LG전자</td>\n",
       "      <td>066570</td>\n",
       "      <td>Y</td>\n",
       "      <td>분기보고서 (2022.03)</td>\n",
       "      <td>20220516001009</td>\n",
       "      <td>LG전자</td>\n",
       "      <td>20220516</td>\n",
       "      <td></td>\n",
       "      <td>분기보고서 (2022.03)</td>\n",
       "      <td>2022.03</td>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...</td>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...</td>\n",
       "      <td>연결회사의 보고부문인 사업본부는 서로 다른 제품과 용역을 제공하는 전략적 사업단위...</td>\n",
       "      <td>[연결, 회사, 보고, 부문, 사업, 본부, 제품, 용역, 제공, 전략, 사업, 단...</td>\n",
       "      <td>연결 회사 보고 부문 사업 본부 제품 용역 제공 전략 사업 단위 사업 기술 마케팅 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    corp_code   corp_name stock_code corp_cls        report_nm  \\\n",
       "0    01510489  프레스티지바이오파마     950210        Y  분기보고서 (2022.03)   \n",
       "446  00401731        LG전자     066570        Y  분기보고서 (2022.03)   \n",
       "\n",
       "           rcept_no      flr_nm  rcept_dt rm modified_report_nm    dates  \\\n",
       "0    20220530001024  프레스티지바이오파마  20220530       분기보고서 (2022.03)  2022.03   \n",
       "446  20220516001009        LG전자  20220516       분기보고서 (2022.03)  2022.03   \n",
       "\n",
       "                                                회사의 개요  \\\n",
       "0    <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...   \n",
       "446  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...   \n",
       "\n",
       "                                                사업의 개요  \\\n",
       "0    <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...   \n",
       "446  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...   \n",
       "\n",
       "                                         business_info  \\\n",
       "0     당사는 바이오시밀러와 항체 신약 개발에 집중해 온 항체의약품 개발 전문 제약회사로...   \n",
       "446   연결회사의 보고부문인 사업본부는 서로 다른 제품과 용역을 제공하는 전략적 사업단위...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [바이오시밀러, 항체, 신약, 개발, 집중, 항체, 의약품, 개발, 전문, 제약, ...   \n",
       "446  [연결, 회사, 보고, 부문, 사업, 본부, 제품, 용역, 제공, 전략, 사업, 단...   \n",
       "\n",
       "                                         tokens_joined  \n",
       "0    바이오시밀러 항체 신약 개발 집중 항체 의약품 개발 전문 제약 회사 일자 한국 유가...  \n",
       "446  연결 회사 보고 부문 사업 본부 제품 용역 제공 전략 사업 단위 사업 기술 마케팅 ...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[[0, 446]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4af6128c7e0808fede432f38729c473c5b0d80882e83c469acdb54455c56396"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
