{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "|||\n",
    "|-|-|\n",
    "|![](https://wikidocs.net/images/page/80437/sentence_matrix.PNG)|![](https://wikidocs.net/images/page/80437/conv1d.PNG)|\n",
    "\n",
    "<br>\n",
    "\n",
    "이미지나 영상 데이터를 처리할 때 사용하는 convolution을 자연어에 적용. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style=\"font-size=20px\"> 특징 </font>\n",
    "\n",
    "병렬 처리: 입력 데이터의 모든 위치에서 필터를 동시에 적용할 수 있어, 각 시간 단계에 대해 순차적으로 계산해야 하는 RNN에 비해 병렬 처리 속도가 훨씬 빠름 <br>\n",
    "\n",
    "국소적 특징 추출: convolution 연산을 통해 입력 데이터에서 국소적인 패턴이나 특징을 효과적으로 추출. <br>\n",
    "-> 단어나 구의 의미를 파악하는 데 유리. <br>\n",
    "\n",
    "과적합 방지: filter의 수와 크기를 조정함으로써 과적합을 줄이는 데 도움을 줄 수 있음. <br>\n",
    "-> RNN보다 더 적은 수의 매개변수로도 높은 성능을 유지할 수 있는 가능성을 제공. <br>\n",
    "\n",
    "Scalability: 다양한 크기의 filter를 적용하여 다중 해상도에서 특징을 학습할 수 있음. <br>\n",
    "-> 문맥의 다양한 수준에서 패턴을 잡아낼 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution\n",
    "\n",
    "<img src=\"https://wikidocs.net/images/page/80437/%EB%84%A4%EB%B2%88%EC%A7%B8%EC%8A%A4%ED%85%9D.PNG\" width=\"600\">\n",
    "\n",
    "filter를 이용해 이미지를 스캔하면서 특징을 추출. <br>\n",
    "filter는 학습 과정에서 업데이트. <br>\n",
    "다양한 필터를 통해 문장 내 주요 정보 파악. <br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<font style=\"font-size:20px\"> 사용 방법 </font>\n",
    "\n",
    "> ```python\n",
    "> nn.Conv1d(\n",
    ">     in_channels,     # (int) 입력 채널 수. seq_len 또는 이전 out_channels의 수와 동일\n",
    ">     out_channels,    # (int) 출력 채널 수. filter의 개수. 생성될 출력 텐서의 채널 수.\n",
    ">     kernel_size,     # (int or tuple) filter의 크기. 몇 개 단위의 토큰 내 정보를 파악할 것인지 결정.\n",
    ">     stride=1,        # (int or tuple) 스트라이드. 필터를 적용할 때 이동하는 간격.\n",
    ">     padding='same',  # (int, tuple, or str) 패딩. 'same'으로 설정하면 입력과 동일한 크기의 출력을 얻도록 패딩을 자동으로 추가. 'valid'는 padding을 사용하지 않음.\n",
    "> )\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0, 20, (32, 20))\n",
    "x.shape # batch_size, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= nn.Embedding(20, 128)(x)\n",
    "x.shape # batch_size, seq_len, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_out = nn.Conv1d(\n",
    "    20,\n",
    "    64,\n",
    "    kernel_size=2,\n",
    "    padding='same'\n",
    ")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling\n",
    "\n",
    "<img src=\"https://wikidocs.net/images/page/80437/%EB%A7%A5%EC%8A%A4%ED%92%80%EB%A7%81.PNG\" width=\"400\">\n",
    "\n",
    "특성을 요약하여 데이터 크기를 줄이고 연산 효율을 높입. <br>\n",
    "convolution의 연산 결과에 적용. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Max Pooling: 가장 두드러지는 특징을 찾음. <br>\n",
    "\n",
    "Average Pooling: 평균적은 특징을 찾음. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_out = nn.MaxPool1d(4)(conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_out = nn.Conv1d(\n",
    "    20,\n",
    "    20,\n",
    "    kernel_size=2,\n",
    "    padding='same'\n",
    ")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x + conv_out).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected Layer\n",
    "\n",
    "최종 예측을 위한 layer. <br>\n",
    "이전 층에서 추출한 특징을 바탕으로 텍스트가 어떤 클래스에 속하는지 예측. <br>\n",
    "전통적인 다층 퍼셉트론처럼 동작하며, CNN의 분류 결과를 출력. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = max_out.flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.0051e-01, -4.1858e-01],\n",
       "        [ 1.3573e-01, -5.2509e-01],\n",
       "        [-2.5074e-02, -6.0886e-01],\n",
       "        [-9.8061e-02, -5.8438e-01],\n",
       "        [ 1.2339e-01, -4.9635e-01],\n",
       "        [ 1.4166e-01, -1.0940e+00],\n",
       "        [-2.4857e-01, -2.1598e-01],\n",
       "        [-3.5043e-02, -5.5456e-01],\n",
       "        [-6.5026e-02, -3.3361e-01],\n",
       "        [ 2.1597e-01, -2.6495e-01],\n",
       "        [ 2.8623e-01, -2.2976e-01],\n",
       "        [ 4.3730e-01, -1.0205e-01],\n",
       "        [-3.3234e-01, -4.5240e-01],\n",
       "        [ 8.2908e-02, -5.2466e-01],\n",
       "        [ 4.2935e-01, -3.5379e-01],\n",
       "        [-7.8750e-02, -2.2148e-01],\n",
       "        [ 2.6232e-01, -4.4683e-02],\n",
       "        [ 3.3722e-01, -5.6358e-01],\n",
       "        [ 2.5005e-01, -5.0370e-01],\n",
       "        [ 7.8430e-01, -3.4337e-01],\n",
       "        [-1.1817e-02, -4.5781e-01],\n",
       "        [ 3.6433e-02, -3.6756e-01],\n",
       "        [ 1.1437e-01, -1.7608e-01],\n",
       "        [-7.4911e-02, -8.1453e-01],\n",
       "        [ 2.0693e-01, -4.4502e-02],\n",
       "        [ 1.6072e-01, -4.2147e-01],\n",
       "        [ 1.1877e-02, -6.8338e-01],\n",
       "        [ 4.0276e-01, -3.5486e-01],\n",
       "        [ 3.9192e-01, -1.8005e-01],\n",
       "        [-3.7885e-04, -6.9548e-01],\n",
       "        [ 1.3819e-01, -5.9420e-01],\n",
       "        [-2.1056e-01, -5.5984e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(640, 2)(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (3.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from datasets) (0.25.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.32.2->datasets) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset('stanfordnlp/imdb', split='train')\n",
    "test_dataset = load_dataset('stanfordnlp/imdb', split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = dict(zip(words, range(len(words))))\n",
    "idx_to_word = dict(zip(range(len(words)), words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Invalid key: 0. Please first select a split. For example: `my_dataset_dictionary['train'][0]`. Available splits: ['test', 'train', 'unsupervised']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mimdb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\.conda\\envs\\nlp\\lib\\site-packages\\datasets\\dataset_dict.py:78\u001b[0m, in \u001b[0;36mDatasetDict.__getitem__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     74\u001b[0m available_suggested_splits \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     75\u001b[0m     split \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m (Split\u001b[38;5;241m.\u001b[39mTRAIN, Split\u001b[38;5;241m.\u001b[39mTEST, Split\u001b[38;5;241m.\u001b[39mVALIDATION) \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m     76\u001b[0m ]\n\u001b[0;32m     77\u001b[0m suggested_split \u001b[38;5;241m=\u001b[39m available_suggested_splits[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m available_suggested_splits \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please first select a split. For example: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`my_dataset_dictionary[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggested_split\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable splits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Invalid key: 0. Please first select a split. For example: `my_dataset_dictionary['train'][0]`. Available splits: ['test', 'train', 'unsupervised']\""
     ]
    }
   ],
   "source": [
    "def preprocessisng(sample):\n",
    "    text = re.sub('([,?!\\'\",\\[\\]\\(\\)\\{\\}])', ' \\\\1', sample['text'])\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    ids = [word_to_idx.get(word) for word in words]\n",
    "\n",
    "    return {'text': ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB datasets\n",
    "imdb = load_dataset('imdb')\n",
    "\n",
    "train, valid = imdb.train_test_split(\n",
    "    train,\n",
    "    test_size=0.2\n",
    "    )\n",
    "\n",
    "train_text = ''.join(train['text'])\n",
    "test_text = ''.join(test['text'])\n",
    "\n",
    "train_text = re.sub('([,?!\\'\",\\[\\]\\(\\)\\{\\}])', ' \\\\1', train_text)\n",
    "test_text = re.sub('([,?!\\'\",\\[\\]\\(\\)\\{\\}])', ' \\\\1', train_text)\n",
    "\n",
    "total_text = ' '.join([train_text, test_text])\n",
    "total_text = total_text.lower()\n",
    "\n",
    "words = total_text.split()\n",
    "words = set(words)\n",
    "words = list(words)\n",
    "\n",
    "word_to_idx = dict(zip(words, range(len(words))))\n",
    "idx_to_word = dict(zip(range(len(words)), words))\n",
    "\n",
    "def preprocessisng(sample):\n",
    "    text = re.sub('([,?!\\'\",\\[\\]\\(\\)\\{\\}])', ' \\\\1', sample['text'])\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    ids = [word_to_idx.get(word) for word in words]\n",
    "\n",
    "    return {'text': ids}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple CNN Filters\n",
    "\n",
    "<img src=\"https://figures.semanticscholar.org/7c35b1ccefedcadefa9670deccc0bf651b996666/9-Figure3-1.png\" width=600>\n",
    "\n",
    "<br>\n",
    "\n",
    "다양한 CNN filter를 결합하여 예측 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 128])\n",
      "torch.Size([32, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "conv_out_with_3 = nn.Conv1d(\n",
    "    20,\n",
    "    64,\n",
    "    kernel_size=3,\n",
    "    padding='same'\n",
    ")(x)\n",
    "print(conv_out_with_3.shape)\n",
    "\n",
    "conv_out_with_5 = nn.Conv1d(\n",
    "    20,\n",
    "    64,\n",
    "    kernel_size=5,\n",
    "    padding='same'\n",
    ")(x)\n",
    "print(conv_out_with_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = torch.cat([conv_out_with_3, conv_out_with_5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_out_with_3 = nn.MaxPool1d(kernel_size=2)(conv_out_with_3)\n",
    "max_out_with_5 = nn.MaxPool1d(kernel_size=2)(conv_out_with_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([max_out_with_3, max_out_with_5], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_out_with_3 = nn.MaxPool1d(kernel_size=128)(conv_out_with_3)\n",
    "max_out_with_5 = nn.MaxPool1d(kernel_size=128)(conv_out_with_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([max_out_with_3, max_out_with_5], axis=-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-LSTM\n",
    "\n",
    "<img src=\"https://konukoii.com/blog/wp-content/uploads/2018/02/cnn-lstm-konukoii.png\" width=600>\n",
    "\n",
    "<br>\n",
    "\n",
    "CNN으로 feature extraction 이후 LSTM을 통해 학습."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-CNN\n",
    "\n",
    "<img src=\"https://konukoii.com/blog/wp-content/uploads/2018/02/lstm-cnn-konukoii.png\" width=600>\n",
    "\n",
    "<br>\n",
    "\n",
    "LSTM Layer로 feature extraction 이후 CNN layer로 feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + LSTM\n",
    "\n",
    "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S1532046420301672-gr4.jpg\" width=600>\n",
    "\n",
    "<br>\n",
    "\n",
    "각 CNN과 LSTM 결과물을 concat하여 활용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
