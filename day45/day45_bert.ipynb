{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "from tokenizers import BertWordPieceTokenizer, Tokenizer\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForMaskedLM,\n",
    "    BertForSequenceClassification,\n",
    "    BertForQuestionAnswering,\n",
    "    BertConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT\n",
    "\n",
    "reference: [BERT](https://wikidocs.net/115055) <br>\n",
    "paper: [BERT](https://arxiv.org/pdf/1810.04805) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    matmul_qk = query @ key.transpose(-2, -1)\n",
    "    depth = query.shape[-1]\n",
    "\n",
    "    logits = matmul_qk / np.sqrt(depth)\n",
    "\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    attention_weights = F.softmax(logits, dim=1)\n",
    "    output = attention_weights @ value\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert self.d_model%self.num_heads == 0\n",
    "\n",
    "        self.depth = self.d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = nn.Linear(self.d_model, self.d_model)\n",
    "        self.key_dense = nn.Linear(self.d_model, self.d_model)\n",
    "        self.value_dense = nn.Linear(self.d_model, self.d_model)\n",
    "\n",
    "        self.dense = nn.Linear(self.d_model, self.d_model)\n",
    "    \n",
    "    def forward(self, inputs: dict):\n",
    "        query, key, value = inputs.get('query'), inputs.get('key'), inputs.get('value')\n",
    "        mask = inputs.get('mask')\n",
    "        batch_size, seq_len = query.shape[:2]\n",
    "\n",
    "        query = self.query_dense(query) # batch_size, seq_len, dim\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        query = query.reshape(batch_size, seq_len, self.num_heads, self.depth)  # batch, seq_len, num_heads, depth\n",
    "        key = key.reshape(batch_size, seq_len, self.num_heads, self.depth)\n",
    "        value = value.reshape(batch_size, seq_len, self.num_heads, self.depth)\n",
    "\n",
    "        query = query.permute(0, 2, 1, 3)   # batch, num_heads, seq_len, depth\n",
    "        key = key.permute(0, 2, 1, 3)\n",
    "        value = value.permute(0, 2, 1, 3)\n",
    "\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)   # batch, num_heads, seq_len, depth\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3)                 # batch, seq_len, num_heads, depth\n",
    "        concat_attention = scaled_attention.reshape(batch_size, seq_len, self.d_model)  # batch, seq_len, dim\n",
    "\n",
    "        outputs = self.dense(concat_attention)  # batch, seq_len, dim\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, num_heads: int, dropout_ratio: float):    \n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "\n",
    "        self.multi_head_attention = MultiheadAttention(self.d_model, self.num_heads)\n",
    "        self.dropout1 = nn.Dropout(self.dropout_ratio)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.d_model)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(self.d_model, self.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.d_ff, self.d_model),\n",
    "        )\n",
    "\n",
    "        self.dropout2 = nn.Dropout(self.dropout_ratio)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        inputs = {'query': x, 'key': x, 'value': x, 'mask': mask}\n",
    "        x_multi_head_output = self.multi_head_attention(inputs)\n",
    "        x_multi_head_output = self.dropout1(x_multi_head_output)\n",
    "        x = self.layer_norm1(x_multi_head_output + x)\n",
    "        \n",
    "        ffn_output = self.ffn(x)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        output = self.layer_norm2(x + ffn_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class BERT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_len: int,\n",
    "        vocab_size: int,\n",
    "        num_layers: int,\n",
    "        d_model: int,\n",
    "        d_ff: int,\n",
    "        num_heads: int,\n",
    "        dropout_ratio: float,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.d_model)\n",
    "        self.positional_embedding = nn.Embedding(self.seq_len, self.d_model)\n",
    "        self.segment_embedding = nn.Embedding(2, self.d_model)\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(self.d_model, self.d_ff, self.num_heads, self.dropout_ratio)\n",
    "            for _ in range(self.num_layers)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x *= (self.d_model ** 0.5)\n",
    "\n",
    "        positional_encoding = (torch.ones(x.shape[:2]).cumsum(axis=1)-1).long()\n",
    "        positional_embedding = self.positional_embedding(positional_encoding)\n",
    "        x += positional_embedding\n",
    "\n",
    "        segment_encoding = torch.zeros(x.shape[:2]).long()\n",
    "        segment_embedding = self.segment_embedding(segment_encoding)\n",
    "        x += segment_embedding\n",
    "\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            x = encoder_layer(x, mask)\n",
    "        output = x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2906, -0.6584,  1.9619,  ..., -1.0357, -0.2678,  0.5728],\n",
       "         [-0.0104, -1.9197,  1.0588,  ..., -0.2179, -1.6125, -0.0701],\n",
       "         [ 0.5030,  0.0756,  1.1953,  ...,  0.5741, -1.0067,  1.6260],\n",
       "         ...,\n",
       "         [-0.1088, -0.2704,  0.4653,  ..., -0.2513, -1.8823, -0.3770],\n",
       "         [ 0.6014, -1.2329,  0.6875,  ..., -0.1052, -1.5198,  0.4144],\n",
       "         [ 0.1390, -1.5423,  0.5434,  ..., -0.9341, -0.8175, -0.2473]],\n",
       "\n",
       "        [[ 0.2578,  0.4389, -0.5429,  ..., -1.3440,  0.8259, -0.4212],\n",
       "         [-0.2401, -0.3437, -0.2433,  ..., -1.4168, -0.0399,  0.1204],\n",
       "         [ 1.0967, -0.4443,  0.7128,  ..., -1.0174,  1.0468,  0.8848],\n",
       "         ...,\n",
       "         [-0.5167, -0.3882, -0.8720,  ...,  0.1111,  0.3167, -0.2946],\n",
       "         [ 0.3027, -1.2595,  0.0768,  ..., -0.4451,  0.6046, -0.4611],\n",
       "         [-0.8294,  0.0169,  0.5167,  ..., -0.1644,  0.0142,  1.4447]],\n",
       "\n",
       "        [[ 0.4527, -0.6503,  0.2345,  ..., -0.1982, -1.2915,  0.1563],\n",
       "         [ 0.8184, -0.3630,  0.5080,  ...,  0.0506, -2.1922, -0.6322],\n",
       "         [-0.0122, -1.5273, -0.0720,  ..., -0.7974,  0.8421, -0.1471],\n",
       "         ...,\n",
       "         [ 0.5828, -1.8357,  0.0101,  ..., -0.5347, -1.9473, -0.0345],\n",
       "         [ 0.3667, -1.7582,  0.4395,  ..., -0.5286, -0.4925,  0.4165],\n",
       "         [ 0.4657, -0.2505,  0.0743,  ..., -0.3132, -0.7355,  0.6427]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4044, -0.2696,  0.4547,  ..., -0.1074,  0.9727, -0.3274],\n",
       "         [-0.5282,  0.9650,  0.9927,  ...,  0.6619, -1.2222, -0.7259],\n",
       "         [-0.9619,  0.6906,  0.5773,  ..., -0.2720, -0.9622, -1.6032],\n",
       "         ...,\n",
       "         [-0.5100, -0.3866, -0.0814,  ...,  1.1811, -1.4567,  0.1354],\n",
       "         [-0.3501,  0.7796,  0.9380,  ..., -0.5421, -0.6814, -0.7379],\n",
       "         [-0.0719, -0.4953,  0.5538,  ...,  0.2205,  0.4269, -1.1032]],\n",
       "\n",
       "        [[-0.7419, -0.1704, -0.2386,  ..., -0.3798, -0.1979, -1.2759],\n",
       "         [ 0.6489,  0.7216, -0.3562,  ..., -1.0322, -0.2352, -1.5169],\n",
       "         [ 0.0531, -0.3115, -0.3216,  ..., -0.5997,  0.4267, -0.3240],\n",
       "         ...,\n",
       "         [ 0.1741, -1.1247, -0.7723,  ..., -1.0475,  0.1056,  0.4499],\n",
       "         [ 0.4444,  1.2710, -0.1278,  ..., -1.1978,  0.6895, -0.6125],\n",
       "         [-0.8415, -0.0741, -0.2348,  ...,  0.0536,  0.8047, -1.2049]],\n",
       "\n",
       "        [[-1.6387, -0.5787, -0.1786,  ...,  0.4818, -0.3913, -0.7811],\n",
       "         [-0.3765,  0.3349,  0.6212,  ...,  0.1840, -0.0755, -0.5575],\n",
       "         [ 0.2740,  0.3620, -0.3207,  ..., -0.0469,  0.2823, -1.4063],\n",
       "         ...,\n",
       "         [-0.2132, -0.1030, -0.6525,  ...,  0.1878,  0.0059, -1.2033],\n",
       "         [-0.1420, -0.2182,  0.3035,  ...,  0.1657, -0.3726, -0.8626],\n",
       "         [ 0.0520, -0.0337,  0.1039,  ...,  1.5883, -0.1269, -1.1709]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0, 1000, (32, 20))\n",
    "x\n",
    "\n",
    "bert = BERT(20, 1000, 12, 768, 2048, 12, 0.1)\n",
    "bert(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\datasets--imdb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 25000/25000 [00:00<00:00, 314271.41 examples/s]\n",
      "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 400721.51 examples/s]\n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 426128.28 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train'].select(range(2000))\n",
    "eval_data = dataset['test'].select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocessing(row):\n",
    "    return tokenizer(row['text'], truncation=True, max_length=256, padding='max_length')\n",
    "\n",
    "tokenized_train_data = train_data.map(preprocessing, batched=True)\n",
    "tokenized_eval_data = eval_data.map(preprocessing, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    {'input_ids': row.get('input_ids'),\n",
    "     'token_type_ids': row.get('token_type_ids'),\n",
    "     'attention_mask': row.get('attention_mask'),\n",
    "     'label': row.get('label'),\n",
    "    } for row in tokenized_train_data\n",
    "]\n",
    "eval_data = [\n",
    "    {'input_ids': row.get('input_ids'),\n",
    "     'token_type_ids': row.get('token_type_ids'),\n",
    "     'attention_mask': row.get('attention_mask'),\n",
    "     'label': row.get('label'),\n",
    "    } for row in tokenized_eval_data\n",
    "]\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.data[idx].get('input_ids'),\n",
    "            'attention_mask': self.data[idx].get('attention_mask'),\n",
    "            'labels': self.data[idx].get('label'),\n",
    "        }\n",
    "\n",
    "train_dataset = IMDBDataset(train_data)\n",
    "eval_dataset = IMDBDataset(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 유튜브"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/ratings_test.txt', <http.client.HTTPMessage at 0x25b7b31fa30>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    'https://raw.githubusercontent.com/e9t/nsmc/refs/heads/master/ratings_train.txt',\n",
    "    filename='data/ratings_train.txt',\n",
    ")\n",
    "urllib.request.urlretrieve(\n",
    "    'https://raw.githubusercontent.com/e9t/nsmc/refs/heads/master/ratings_test.txt',\n",
    "    filename='data/ratings_test.txt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_table('data/ratings_train.txt', usecols=['document', 'label']).iloc[:5000]\n",
    "valid = pd.read_table('data/ratings_test.txt', usecols=['document', 'label']).iloc[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['tokenized_comment'] = train.document.apply(lambda x: tokenizer(x))\n",
    "valid['tokenized_comment'] = valid.document.apply(lambda x: tokenizer(x))\n",
    "train.tokenized_comment.apply(lambda x: x.get('input_ids')).apply(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_comment = tokenizer(\n",
    "    train.document.tolist(),\n",
    "    return_tensors='pt',\n",
    "    padding='max_length',\n",
    "    max_length=100,\n",
    "    truncation=True,\n",
    ")\n",
    "tokenized_valid_comment = tokenizer(\n",
    "    valid.document.tolist(),\n",
    "    return_tensors='pt',\n",
    "    padding='max_length',\n",
    "    max_length=100,\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "train_data = [\n",
    "    {'input_ids': input_ids,\n",
    "     'token_type_ids': token_type_ids,\n",
    "     'attention_mask': attention_mask,\n",
    "     'label': label,\n",
    "    } \n",
    "    for input_ids, token_type_ids, attention_mask, label \n",
    "    in zip(tokenized_train_comment.get('input_ids'),\n",
    "           tokenized_train_comment.get('token_type_ids'),\n",
    "           tokenized_train_comment.get('attention_mask'),\n",
    "           train.label.values)\n",
    "]\n",
    "\n",
    "eval_data = [\n",
    "    {'input_ids': input_ids,\n",
    "     'token_type_ids': token_type_ids,\n",
    "     'attention_mask': attention_mask,\n",
    "     'label': label,\n",
    "    } \n",
    "    for input_ids, token_type_ids, attention_mask, label \n",
    "    in zip(tokenized_valid_comment.get('input_ids'),\n",
    "           tokenized_valid_comment.get('token_type_ids'),\n",
    "           tokenized_valid_comment.get('attention_mask'),\n",
    "           train.label.values)\n",
    "]\n",
    "\n",
    "class CommentDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.data[idx].get('input_ids'),\n",
    "            'attention_mask': self.data[idx].get('attention_mask'),\n",
    "            'labels': self.data[idx].get('label'),\n",
    "        }\n",
    "\n",
    "train_dataset = CommentDataset(train_data)\n",
    "eval_dataset = CommentDataset(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('google-bert/bert-base-multilingual-uncased')\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokenizer(valid.document.iloc[3], return_tensors='pt')).logits.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Infernce (NLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question and Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.15 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a56403b4074e681ecb36004649c5fb19e7bcf1144081029ba5f2cf549331f5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
