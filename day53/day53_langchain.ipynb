{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_chroma faiss-cpu lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "c:\\ProgramData\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\io\\image.py:14: UserWarning: Failed to load image Python extension: '[WinError 127] 지정된 프로시저를 찾을 수 없습니다'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from src.utils import show_stream, naver_news_crawler\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import uuid\n",
    "import nest_asyncio\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from seaborn import load_dataset\n",
    "\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain_core.load import dumpd, dumps, load, loads\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.example_selectors import (\n",
    "    SemanticSimilarityExampleSelector,\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    ")\n",
    "from langchain_core.output_parsers import (\n",
    "    StrOutputParser,\n",
    "    PydanticOutputParser,\n",
    "    CommaSeparatedListOutputParser,\n",
    "    JsonOutputParser,\n",
    ")\n",
    "from langchain.output_parsers.structured import (\n",
    "    ResponseSchema,\n",
    "    StructuredOutputParser,\n",
    ")\n",
    "from langchain.output_parsers.pandas_dataframe import PandasDataFrameOutputParser\n",
    "from langchain.output_parsers.datetime import DatetimeOutputParser\n",
    "from langchain.output_parsers.fix import OutputFixingParser\n",
    "from langchain.output_parsers.retry import RetryOutputParser\n",
    "from langchain_core.runnables import (\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    "    RunnableLambda,\n",
    "    ConfigurableField,\n",
    ")\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import (\n",
    "    UnstructuredPDFLoader,\n",
    "    PyPDFium2Loader,\n",
    "    PDFMinerLoader,\n",
    "    PyPDFDirectoryLoader,\n",
    "    PDFPlumberLoader,\n",
    "    UnstructuredExcelLoader,\n",
    "    DataFrameLoader,\n",
    "    Docx2txtLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    "    UnstructuredPowerPointLoader,\n",
    "    WebBaseLoader,\n",
    "    TextLoader,\n",
    "    DirectoryLoader,\n",
    "    JSONLoader,\n",
    "    ArxivLoader,\n",
    ")\n",
    "\n",
    "from langchain_text_splitters import (\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    Language,\n",
    "    MarkdownHeaderTextSplitter,\n",
    "    HTMLHeaderTextSplitter,\n",
    "    RecursiveJsonSplitter,\n",
    ")\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.storage import (\n",
    "    LocalFileStore,\n",
    "    InMemoryByteStore,\n",
    "    InMemoryStore,\n",
    ")\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain_teddynote.document_compressors import LLMChainExtractor\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain.retrievers import (\n",
    "    ContextualCompressionRetriever,\n",
    "    BM25Retriever,\n",
    "    EnsembleRetriever,\n",
    "    ParentDocumentRetriever,\n",
    "    TimeWeightedVectorStoreRetriever,\n",
    ")\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "자연어 처리와 대화형 AI 애플리케이션을 구축하는 데 도움을 주는 프레임워크. <br>\n",
    "여러 가지 NLP 모델과 데이터 소스를 쉽게 통합할 수 있도록 설계. <br>\n",
    "복잡한 대화형 시스템을 개발하는 데 필요한 다양한 도구와 컴포넌트를 제공. <br>\n",
    "대화형 애플리케이션, 챗봇, 자동화된 고객 서비스 솔루션 등을 보다 효율적으로 개발 가능. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style=\"font-size:20px\"> 특징 </font>\n",
    "\n",
    "- 모델 통합: 다양한 언어 모델(예: GPT, Claude 등)을 쉽게 사용할 수 있도록 지원\n",
    "- 데이터 소스 연결: 데이터베이스, API, 파일 시스템 등 여러 소스와 연결할 수 있는 기능 제공\n",
    "- 체인 구성: 여러 작업을 순차적으로 연결하여 복잡한 프로세스를 만들 수 있는 체인 개념 도입\n",
    "- 사용자 정의: 사용자 요구에 맞게 쉽게 확장하고 커스터마이즈 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG\n",
    "\n",
    "Retrieval-Augmented Generation(RAG)는 정보 검색과 생성을 통합하는 방법론. <br>\n",
    "RAG는 대규모 문서 데이터베이스에서 관련 정보를 검색하고, 이를 통해 모델이 더 정확하고 상세한 답변을 생성할 수 있도록 함. <br>\n",
    "최신 뉴스 이벤트나 특정 분야의 전문 지식과 같은 주제에 대해 물어보면, RAG는 관련 문서를 찾아 그 내용을 바탕으로 답변.\n",
    "\n",
    "|사전 준비 단계|Runtime 단계|\n",
    "|-----------|-----------|\n",
    "|![](https://wikidocs.net/images/page/233780/rag-graphic-1.png)|![](https://wikidocs.net/images/page/233780/rag-graphic-2.png)|\n",
    "|Document Load: 외부 데이터 소스에서 필요한 문서를 로드|Retriever: 질문이 주어지면 관련된 내용을 벡터 데이터베이스에서 검색|\n",
    "|Text Splitter: 로드된 문서를 처리 가능한 작은 단위로 분할|Prompt: 검색된 정보를 바탕으로 언어 모델을 위한 질문 구성|\n",
    "|Embedding: 각 문서 또는 문서의 일부를 벡터 형태로 변환|LLM: 구성된 프롬프트를 사용하여 언어 모델이 답변 생성|\n",
    "|Vector Store: 임베딩된 벡터들을 데이터베이스에 저장. 요약된 키워드를 색인화하여 나중에 빠르게 찾을 수 있도록 함|Chain: 이전의 모든 과정의 하나의 파이프라인으로 묶어주는 Chain 생성|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "한국어 검색을 위한 임베딩 벤치마크: https://github.com/teddylee777/Kor-IR?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAIEmbeddings\n",
    "\n",
    "OpenAI의 embeding API를 사용한 embedding.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> embedding_model = OpenAIEmbeddings(\n",
    ">     model='text-embedding-3-small',\n",
    ">     # dimensions=1024, # 차원 조정\n",
    "> )\n",
    "> \n",
    "> # text embedding\n",
    "> embedded_text = embedding_model.embed_query(text)\n",
    "> \n",
    "> # document embedding\n",
    "> embedded_documents = embeddings.embed_documents([text])\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(\n",
    "    model='text-embedding-3-small'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9341421221189211"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'hello world!'라는 쿼리를 임베딩하여 numpy 배열로 변환\n",
    "a = np.array(embedding_model.embed_query('hello world!'))\n",
    "\n",
    "# 'hello world'라는 쿼리를 임베딩하여 numpy 배열로 변환\n",
    "b = np.array(embedding_model.embed_query('hello world'))\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "# a와 b의 내적을 a의 노름과 b의 노름으로 나누어 코사인 유사도를 구함\n",
    "cos_sim = (a @ b.T) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# 계산된 코사인 유사도 출력\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여러 문서에 대해 임베딩을 생성\n",
    "# 'hello world!'와 'hello world'라는 두 개의 문서가 포함된 리스트를 전달\n",
    "np.array(embedding_model.embed_documents([\n",
    "    'hello world!',\n",
    "    'hello world',\n",
    "])).shape    # 생성된 임베딩의 형태(shape)를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1536)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp_keywords를 text loader를 통해서 load\n",
    "loader = TextLoader('./data/nlp_keywords.txt')\n",
    "document = loader.load()\n",
    "\n",
    "# splitter를 통해서 chunk 단위로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    ")\n",
    "documents = text_splitter.create_documents([document[0].page_content])\n",
    "\n",
    "# 분할된 데이터를 embedding\n",
    "documents = [document.page_content for document in documents]\n",
    "model_embedding = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "documents_embedded = model_embedding.embed_documents(documents)\n",
    "np.array(documents_embedded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14, 15], dtype=int64), array([15, 14], dtype=int64))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim = cosine_similarity(np.array(documents_embedded))\n",
    "np.fill_diagonal(cos_sim, 0)\n",
    "threshold = 0.7\n",
    "np.where(cos_sim > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Token\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer',\n",
       "       'Tokenizer\\n\\n정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore'],\n",
       "      dtype='<U215')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(documents)[[14, 15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CacheBackedEmbeddings\n",
    "\n",
    "재계산을 피하기 위해 저장하거나 일시적으로 caching. <br>\n",
    "embeddings을 key-value 저장소에 caching하는 wrapper. <br>\n",
    "텍스트는 해시되고 이 해시는 캐시에서 키로 사용. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "CacheBackedEmbeddings:\n",
    "- underlying_embeddings: embedding을 위해 사용하는 모델.\n",
    "- document_embedding_cache: 문서 임베딩을 캐싱하기 위한 ByteStore.\n",
    "- namespace (optional): 다른 캐시와의 충돌을 피하기 위해 사용하는 네임스페이스.\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> store = LocalFileStore(\"./cache/\")    # 영구적\n",
    "> store = InMemoryByteStore()           # 비영구적\n",
    "> \n",
    "> cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    ">     underlying_embeddings=embedding,\n",
    ">     document_embedding_cache=store,\n",
    ">     namespace=embedding.model,\n",
    "> )\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embedding = OpenAIEmbeddings(\n",
    "    model='text-embedding-3-small'\n",
    ")\n",
    "\n",
    "store = LocalFileStore('./cache/')   # 비휘발성 (하드)\n",
    "store = InmemoryByteStore()          # 휘발성   (메모리)\n",
    "\n",
    "model_cache_embedding = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=model_embedding,\n",
    "    document_embedding_cache=store,\n",
    "    namespace=model_embedding.model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace Embeddings\n",
    "\n",
    "huggingface endpoint를 통한 embedding. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> embedding_model = HuggingFaceEndpointEmbeddings(\n",
    ">     model='BAAI/bge-m3',\n",
    ">     task='feature-extraction',\n",
    ">     # model_kwargs: optional ={'device': 'cuda'},  # cuda, cpu\n",
    ">     # encode_kwargs={'normalize_embeddings': True},\n",
    "> )\n",
    "> \n",
    "> # 문서 임베딩\n",
    "> embedded_documents = embedding_model.embed_documents(texts)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.04039410501718521,\n",
       "  0.0370350144803524,\n",
       "  -0.028974439948797226,\n",
       "  0.01611720770597458,\n",
       "  -0.03569155931472778,\n",
       "  -0.04073759913444519,\n",
       "  -0.0550544299185276,\n",
       "  -0.040867533534765244,\n",
       "  0.003238329663872719,\n",
       "  0.001956742024049163,\n",
       "  -0.006565415300428867,\n",
       "  0.011655457317829132,\n",
       "  0.021531231701374054,\n",
       "  -0.013461880385875702,\n",
       "  0.030359994620084763,\n",
       "  0.0038853585720062256,\n",
       "  0.02051585167646408,\n",
       "  -0.02315090410411358,\n",
       "  -0.021936513483524323,\n",
       "  -0.03128373250365257,\n",
       "  -0.05100717768073082,\n",
       "  -0.01739712432026863,\n",
       "  0.0123360026627779,\n",
       "  -0.014076601713895798,\n",
       "  0.015406228601932526,\n",
       "  0.04133284091949463,\n",
       "  -0.036864809691905975,\n",
       "  -0.0005830508889630437,\n",
       "  0.00033308894489891827,\n",
       "  -0.06086040660738945,\n",
       "  0.037107087671756744,\n",
       "  0.08012109249830246,\n",
       "  -0.017788074910640717,\n",
       "  -0.04983343556523323,\n",
       "  -0.03419807553291321,\n",
       "  -0.035880349576473236,\n",
       "  0.004637434612959623,\n",
       "  0.0005803846870549023,\n",
       "  -0.06894704699516296,\n",
       "  0.010874012485146523,\n",
       "  0.01592210866510868,\n",
       "  0.02258642017841339,\n",
       "  0.023137064650654793,\n",
       "  -0.05890844389796257,\n",
       "  0.0022468853276222944,\n",
       "  -0.04434964433312416,\n",
       "  -0.0403624102473259,\n",
       "  -0.0024729715660214424,\n",
       "  0.0031872426625341177,\n",
       "  -0.06471838057041168,\n",
       "  0.008993289433419704,\n",
       "  0.0318743921816349,\n",
       "  0.03772875666618347,\n",
       "  -0.001202810206450522,\n",
       "  0.0034979970660060644,\n",
       "  0.022246098145842552,\n",
       "  -0.01693238876760006,\n",
       "  -0.023046212270855904,\n",
       "  -0.0621916688978672,\n",
       "  0.0021645696833729744,\n",
       "  -0.020522719249129295,\n",
       "  -0.00969005562365055,\n",
       "  -0.0035016501788049936,\n",
       "  -0.007989616133272648,\n",
       "  0.0029983713757246733,\n",
       "  0.1550516039133072,\n",
       "  0.030606331303715706,\n",
       "  -0.01320109236985445,\n",
       "  -0.004796323832124472,\n",
       "  -0.015057767741382122,\n",
       "  -0.018100401386618614,\n",
       "  -0.012224270962178707,\n",
       "  -0.0008975795935839415,\n",
       "  0.022377651184797287,\n",
       "  -0.06573615223169327,\n",
       "  0.0469324104487896,\n",
       "  -0.015008543618023396,\n",
       "  -0.01148801576346159,\n",
       "  0.013654102571308613,\n",
       "  0.03617386892437935,\n",
       "  0.07965092360973358,\n",
       "  -0.004306177143007517,\n",
       "  -0.00014813260349910706,\n",
       "  0.017645200714468956,\n",
       "  -0.013407708145678043,\n",
       "  0.04799695685505867,\n",
       "  0.01496871467679739,\n",
       "  0.03673914074897766,\n",
       "  -0.004318693187087774,\n",
       "  -0.01352436188608408,\n",
       "  -0.03722316771745682,\n",
       "  -0.023028280586004257,\n",
       "  0.02777731791138649,\n",
       "  -0.051526524126529694,\n",
       "  -0.02842158079147339,\n",
       "  0.016847042366862297,\n",
       "  -0.00543755479156971,\n",
       "  0.019748125225305557,\n",
       "  0.03629971295595169,\n",
       "  0.033107057213783264,\n",
       "  0.04887472093105316,\n",
       "  0.018898243084549904,\n",
       "  0.009175491519272327,\n",
       "  -0.01309354230761528,\n",
       "  0.002610791241750121,\n",
       "  0.004009501077234745,\n",
       "  0.02673739567399025,\n",
       "  0.026981091126799583,\n",
       "  0.022860459983348846,\n",
       "  0.013222581706941128,\n",
       "  0.04867943003773689,\n",
       "  0.027506479993462563,\n",
       "  0.020129019394516945,\n",
       "  0.022082412615418434,\n",
       "  0.013256813399493694,\n",
       "  -0.008234279230237007,\n",
       "  0.002783501986414194,\n",
       "  -0.016664808616042137,\n",
       "  -0.003898100694641471,\n",
       "  -0.02220306359231472,\n",
       "  -0.007607342209666967,\n",
       "  0.026623982936143875,\n",
       "  0.023318393155932426,\n",
       "  0.009662488475441933,\n",
       "  0.028936630114912987,\n",
       "  -0.04966419190168381,\n",
       "  0.008967314846813679,\n",
       "  0.035097990185022354,\n",
       "  -0.017560554668307304,\n",
       "  -0.0268249474465847,\n",
       "  0.06391165405511856,\n",
       "  0.007055433467030525,\n",
       "  -0.03429223597049713,\n",
       "  0.004585358779877424,\n",
       "  -0.006181742064654827,\n",
       "  -0.03060075268149376,\n",
       "  -0.0026075837668031454,\n",
       "  -0.025933779776096344,\n",
       "  -0.013353959657251835,\n",
       "  -0.028442736715078354,\n",
       "  0.022517981007695198,\n",
       "  0.06849654018878937,\n",
       "  -0.021376844495534897,\n",
       "  -0.015005815774202347,\n",
       "  -0.013669825159013271,\n",
       "  -0.0524991899728775,\n",
       "  -0.028522642329335213,\n",
       "  0.013989019207656384,\n",
       "  0.018606053665280342,\n",
       "  -0.04136687517166138,\n",
       "  -0.0040506646037101746,\n",
       "  -0.021492283791303635,\n",
       "  0.03353980556130409,\n",
       "  0.04690714552998543,\n",
       "  0.03251153975725174,\n",
       "  0.003230603178963065,\n",
       "  -0.042864833027124405,\n",
       "  0.032092005014419556,\n",
       "  -0.005386509466916323,\n",
       "  -0.01461506262421608,\n",
       "  0.013870722614228725,\n",
       "  -0.005585066508501768,\n",
       "  -0.04088636487722397,\n",
       "  -0.0138021819293499,\n",
       "  -0.0023651672527194023,\n",
       "  0.004401655402034521,\n",
       "  0.03641725331544876,\n",
       "  0.024872593581676483,\n",
       "  0.0037469302769750357,\n",
       "  0.003732874058187008,\n",
       "  -0.012898179702460766,\n",
       "  -0.009925435297191143,\n",
       "  0.026742087677121162,\n",
       "  -0.020239001139998436,\n",
       "  -0.015350337140262127,\n",
       "  0.02306722290813923,\n",
       "  0.056975800544023514,\n",
       "  0.024388255551457405,\n",
       "  0.01784929819405079,\n",
       "  -0.03664800897240639,\n",
       "  -0.04267274960875511,\n",
       "  0.006546743214130402,\n",
       "  -0.0003471836098469794,\n",
       "  -0.02314700558781624,\n",
       "  -0.04461689293384552,\n",
       "  0.034806057810783386,\n",
       "  -0.029781004413962364,\n",
       "  -0.009519975632429123,\n",
       "  0.023959239944815636,\n",
       "  0.010975473560392857,\n",
       "  0.0012738301884382963,\n",
       "  -0.009331971406936646,\n",
       "  0.03150897100567818,\n",
       "  -0.0388062410056591,\n",
       "  0.007656776811927557,\n",
       "  0.00803978182375431,\n",
       "  0.00402250187471509,\n",
       "  -0.011737801134586334,\n",
       "  -0.030142927542328835,\n",
       "  -0.0009863941231742501,\n",
       "  -0.03323574736714363,\n",
       "  -0.004283853806555271,\n",
       "  -0.004297447390854359,\n",
       "  0.07079699635505676,\n",
       "  -0.0630708634853363,\n",
       "  0.0006048132199794054,\n",
       "  -0.012085551396012306,\n",
       "  -0.009879599325358868,\n",
       "  0.030870851129293442,\n",
       "  -0.01922009326517582,\n",
       "  0.02150309458374977,\n",
       "  0.03371142968535423,\n",
       "  0.026015713810920715,\n",
       "  -0.021763144060969353,\n",
       "  -0.06059221178293228,\n",
       "  0.013135856948792934,\n",
       "  -0.04245726391673088,\n",
       "  0.0019644577987492085,\n",
       "  -0.004542411305010319,\n",
       "  -0.017917988821864128,\n",
       "  0.01255133654922247,\n",
       "  -0.016391383484005928,\n",
       "  -0.004923729225993156,\n",
       "  0.018882302567362785,\n",
       "  0.014346031472086906,\n",
       "  0.006059268955141306,\n",
       "  0.009067511186003685,\n",
       "  0.004260041750967503,\n",
       "  0.023404963314533234,\n",
       "  0.013590408489108086,\n",
       "  0.037153877317905426,\n",
       "  -0.007626422680914402,\n",
       "  0.0032881724182516336,\n",
       "  -0.028024928644299507,\n",
       "  -0.008768720552325249,\n",
       "  -0.01899859681725502,\n",
       "  -0.05587507784366608,\n",
       "  -0.0011292094131931663,\n",
       "  0.03701076656579971,\n",
       "  0.008666617795825005,\n",
       "  -0.003765885252505541,\n",
       "  -0.009951790794730186,\n",
       "  -0.011572013609111309,\n",
       "  -0.007134721148759127,\n",
       "  -0.04270271956920624,\n",
       "  0.05381862074136734,\n",
       "  -0.009404974058270454,\n",
       "  0.013211861252784729,\n",
       "  0.003779271151870489,\n",
       "  0.005404641851782799,\n",
       "  0.012482225894927979,\n",
       "  -0.02552003413438797,\n",
       "  -0.0034164192620664835,\n",
       "  0.026382053270936012,\n",
       "  0.06614408642053604,\n",
       "  0.000653065973892808,\n",
       "  -0.010513641871511936,\n",
       "  -0.010253354907035828,\n",
       "  -0.005149453412741423,\n",
       "  -0.024383364245295525,\n",
       "  0.02342810668051243,\n",
       "  -0.06013328582048416,\n",
       "  0.01360668707638979,\n",
       "  0.05241479352116585,\n",
       "  0.027261996641755104,\n",
       "  0.009798071347177029,\n",
       "  -0.02319956012070179,\n",
       "  -0.014810974709689617,\n",
       "  0.018317468464374542,\n",
       "  0.008535129018127918,\n",
       "  0.01563931070268154,\n",
       "  -0.06762480735778809,\n",
       "  -0.01083429716527462,\n",
       "  -0.01983540505170822,\n",
       "  -0.00803456362336874,\n",
       "  0.016289932653307915,\n",
       "  -0.012568947859108448,\n",
       "  -0.047135546803474426,\n",
       "  0.02033301442861557,\n",
       "  0.012736168690025806,\n",
       "  0.04293346032500267,\n",
       "  -0.0030360971577465534,\n",
       "  0.03600709140300751,\n",
       "  -0.017816035076975822,\n",
       "  -0.0013188947923481464,\n",
       "  0.017199743539094925,\n",
       "  -0.06809644401073456,\n",
       "  0.014710682444274426,\n",
       "  0.029741907492280006,\n",
       "  -0.04726915434002876,\n",
       "  0.016118116676807404,\n",
       "  0.056422654539346695,\n",
       "  0.030663885176181793,\n",
       "  -0.008880636654794216,\n",
       "  0.020933082327246666,\n",
       "  -0.0032616083044558764,\n",
       "  -0.01033436693251133,\n",
       "  -0.16271434724330902,\n",
       "  0.003333696397021413,\n",
       "  0.013572321273386478,\n",
       "  -0.048586469143629074,\n",
       "  0.007300214841961861,\n",
       "  -0.03250149264931679,\n",
       "  -0.032316263765096664,\n",
       "  0.04712877795100212,\n",
       "  -0.0014051074394956231,\n",
       "  0.02005525678396225,\n",
       "  -0.026136886328458786,\n",
       "  -0.001120160915888846,\n",
       "  -0.037740617990493774,\n",
       "  0.03273126482963562,\n",
       "  -0.020704038441181183,\n",
       "  0.026853585615754128,\n",
       "  0.009267260320484638,\n",
       "  -0.03527776896953583,\n",
       "  0.05858679488301277,\n",
       "  -0.056308284401893616,\n",
       "  0.0049387020990252495,\n",
       "  -0.010593734681606293,\n",
       "  0.07067122310400009,\n",
       "  -0.02994394674897194,\n",
       "  0.02259240858256817,\n",
       "  0.002100801793858409,\n",
       "  0.035395298153162,\n",
       "  -0.043204255402088165,\n",
       "  -0.053544770926237106,\n",
       "  0.002181766089051962,\n",
       "  -0.03254978358745575,\n",
       "  0.011608535423874855,\n",
       "  -0.006446517538279295,\n",
       "  0.021069657057523727,\n",
       "  0.024117548018693924,\n",
       "  0.05087751895189285,\n",
       "  0.022973211482167244,\n",
       "  -0.037817295640707016,\n",
       "  0.004428013693541288,\n",
       "  0.019999070093035698,\n",
       "  0.004412442445755005,\n",
       "  0.01570504903793335,\n",
       "  0.005161854904145002,\n",
       "  0.023606076836586,\n",
       "  -0.01803639344871044,\n",
       "  -0.045821499079465866,\n",
       "  -0.03663361817598343,\n",
       "  0.00409341137856245,\n",
       "  -0.0140240378677845,\n",
       "  -0.0015891174552962184,\n",
       "  -0.014496787451207638,\n",
       "  -0.004105832427740097,\n",
       "  -0.02195996232330799,\n",
       "  -0.05633625015616417,\n",
       "  -0.01800500601530075,\n",
       "  0.013063515536487103,\n",
       "  -0.03197923302650452,\n",
       "  0.01811094954609871,\n",
       "  -0.012671446427702904,\n",
       "  -0.010698985308408737,\n",
       "  -0.014562519267201424,\n",
       "  -0.0379166305065155,\n",
       "  0.018211977556347847,\n",
       "  0.003119794651865959,\n",
       "  -0.013994154520332813,\n",
       "  0.018465178087353706,\n",
       "  0.01829637587070465,\n",
       "  -0.029881708323955536,\n",
       "  0.01591041125357151,\n",
       "  -0.01505958754569292,\n",
       "  0.020420940592885017,\n",
       "  0.00236864504404366,\n",
       "  0.00353417475707829,\n",
       "  -0.03205287456512451,\n",
       "  0.01692088693380356,\n",
       "  -0.010320569388568401,\n",
       "  0.03469201177358627,\n",
       "  -0.010001474991440773,\n",
       "  -0.036447763442993164,\n",
       "  -0.14940106868743896,\n",
       "  -0.02820349670946598,\n",
       "  0.0029165579471737146,\n",
       "  -0.028450436890125275,\n",
       "  -0.00027326779672876,\n",
       "  -0.02853131853044033,\n",
       "  -0.015708254650235176,\n",
       "  -0.0033855359070003033,\n",
       "  0.039382051676511765,\n",
       "  0.07356374710798264,\n",
       "  0.30598777532577515,\n",
       "  0.03341853618621826,\n",
       "  0.03246555104851723,\n",
       "  -0.03010561689734459,\n",
       "  0.07381248474121094,\n",
       "  -0.032426267862319946,\n",
       "  0.005274211056530476,\n",
       "  0.004848274402320385,\n",
       "  0.0004563590919133276,\n",
       "  -0.021812228485941887,\n",
       "  -0.018367426469922066,\n",
       "  -0.03175869211554527,\n",
       "  0.006158573552966118,\n",
       "  0.03281599283218384,\n",
       "  0.01827654056251049,\n",
       "  0.05128779262304306,\n",
       "  -0.06004945561289787,\n",
       "  -0.015531700104475021,\n",
       "  0.04820352420210838,\n",
       "  0.025995291769504547,\n",
       "  0.008011188358068466,\n",
       "  0.01782057248055935,\n",
       "  0.004697984550148249,\n",
       "  -0.023195790126919746,\n",
       "  -0.020886698737740517,\n",
       "  -0.012003334239125252,\n",
       "  -0.004963367711752653,\n",
       "  0.030865008011460304,\n",
       "  0.007096805144101381,\n",
       "  0.021434731781482697,\n",
       "  0.007991177961230278,\n",
       "  0.0045969365164637566,\n",
       "  0.022174840793013573,\n",
       "  -0.0031073957215994596,\n",
       "  -0.04016304016113281,\n",
       "  0.007108929567039013,\n",
       "  0.0067558614537119865,\n",
       "  -0.0392145998775959,\n",
       "  -0.016654809936881065,\n",
       "  0.022388407960534096,\n",
       "  -0.03004015050828457,\n",
       "  -0.02106422185897827,\n",
       "  0.030005795881152153,\n",
       "  0.019120601937174797,\n",
       "  0.041636113077402115,\n",
       "  0.02542438916862011,\n",
       "  0.0244226586073637,\n",
       "  -0.025928718969225883,\n",
       "  -0.03724557161331177,\n",
       "  0.029054109007120132,\n",
       "  -0.03709224984049797,\n",
       "  -0.004213040694594383,\n",
       "  -0.004353083670139313,\n",
       "  0.014443667605519295,\n",
       "  -0.009142286144196987,\n",
       "  -0.01639026403427124,\n",
       "  0.0027104681357741356,\n",
       "  -0.0510457418859005,\n",
       "  0.02516261488199234,\n",
       "  0.03335452079772949,\n",
       "  0.020814793184399605,\n",
       "  0.062400687485933304,\n",
       "  -0.020947271957993507,\n",
       "  -0.0409034825861454,\n",
       "  -0.023150499910116196,\n",
       "  -0.00886822585016489,\n",
       "  0.015726052224636078,\n",
       "  -0.004636398050934076,\n",
       "  -0.008184830658137798,\n",
       "  0.03815832361578941,\n",
       "  0.008516701869666576,\n",
       "  -0.04098266363143921,\n",
       "  -0.01973653957247734,\n",
       "  0.0199570469558239,\n",
       "  0.02926153503358364,\n",
       "  0.014659815467894077,\n",
       "  0.004195179790258408,\n",
       "  0.030671557411551476,\n",
       "  0.018239827826619148,\n",
       "  0.01982812024652958,\n",
       "  0.002620314946398139,\n",
       "  -0.02294606901705265,\n",
       "  -0.039969783276319504,\n",
       "  -0.032858286052942276,\n",
       "  -0.009650185704231262,\n",
       "  -0.017242327332496643,\n",
       "  -0.004704022780060768,\n",
       "  0.0728674829006195,\n",
       "  0.029116827994585037,\n",
       "  -0.027857445180416107,\n",
       "  0.030920276418328285,\n",
       "  0.003783681197091937,\n",
       "  -0.052302341908216476,\n",
       "  0.02046118676662445,\n",
       "  -0.04732915386557579,\n",
       "  -0.0558135062456131,\n",
       "  0.028673041611909866,\n",
       "  -0.016661813482642174,\n",
       "  -0.015341288410127163,\n",
       "  0.017853928729891777,\n",
       "  -0.03087313286960125,\n",
       "  0.00025874326820485294,\n",
       "  -0.04395835101604462,\n",
       "  0.0646260604262352,\n",
       "  0.02180529572069645,\n",
       "  -0.03664800524711609,\n",
       "  0.006497588474303484,\n",
       "  -0.00015383232675958425,\n",
       "  0.013397269882261753,\n",
       "  0.018964236602187157,\n",
       "  0.026911649852991104,\n",
       "  -0.02099984511733055,\n",
       "  0.026059547439217567,\n",
       "  0.03920681029558182,\n",
       "  0.010644610039889812,\n",
       "  0.01237926259636879,\n",
       "  0.01856561191380024,\n",
       "  -0.00942656584084034,\n",
       "  0.03002968057990074,\n",
       "  0.008392499759793282,\n",
       "  -0.029192142188549042,\n",
       "  -0.0460321381688118,\n",
       "  -0.01656544767320156,\n",
       "  0.051599640399217606,\n",
       "  -0.00035031826701015234,\n",
       "  0.019269010052084923,\n",
       "  -0.026622995734214783,\n",
       "  0.01469664927572012,\n",
       "  -0.019561300054192543,\n",
       "  0.01824578270316124,\n",
       "  -0.0013176595093682408,\n",
       "  -0.018792474642395973,\n",
       "  -0.0005475220386870205,\n",
       "  0.05361101031303406,\n",
       "  0.06559854000806808,\n",
       "  0.0057520754635334015,\n",
       "  0.05435039848089218,\n",
       "  -0.0020040906965732574,\n",
       "  -0.013008402660489082,\n",
       "  0.04529094323515892,\n",
       "  0.006140794139355421,\n",
       "  0.024996913969516754,\n",
       "  -0.006995155941694975,\n",
       "  -0.009582070633769035,\n",
       "  -0.01306877564638853,\n",
       "  0.01975252293050289,\n",
       "  -0.0203848909586668,\n",
       "  -0.012940800748765469,\n",
       "  -0.0014844300458207726,\n",
       "  0.017962852492928505,\n",
       "  0.005556908436119556,\n",
       "  -0.014657623134553432,\n",
       "  -4.3667718273354694e-05,\n",
       "  -0.023226384073495865,\n",
       "  -0.016787076368927956,\n",
       "  0.0016942765796557069,\n",
       "  -0.032125141471624374,\n",
       "  -0.03531726822257042,\n",
       "  0.02479494921863079,\n",
       "  -0.009424506686627865,\n",
       "  0.014860500581562519,\n",
       "  0.029849983751773834,\n",
       "  0.07538975775241852,\n",
       "  0.12631137669086456,\n",
       "  0.026418890804052353,\n",
       "  -0.0036776734050363302,\n",
       "  0.0104463966563344,\n",
       "  0.043908119201660156,\n",
       "  0.007658438757061958,\n",
       "  -0.009001772850751877,\n",
       "  0.005920275114476681,\n",
       "  -0.03465283662080765,\n",
       "  -0.035714324563741684,\n",
       "  0.0091248182579875,\n",
       "  0.016969244927167892,\n",
       "  -0.021867824718356133,\n",
       "  -0.008044647052884102,\n",
       "  0.023843133822083473,\n",
       "  -0.027757328003644943,\n",
       "  0.03639055788516998,\n",
       "  0.06549329310655594,\n",
       "  0.006142443511635065,\n",
       "  0.0069024935364723206,\n",
       "  -0.012985493056476116,\n",
       "  0.024050218984484673,\n",
       "  -0.01789437048137188,\n",
       "  0.013254640623927116,\n",
       "  -0.011363549157977104,\n",
       "  0.016259023919701576,\n",
       "  -0.017367541790008545,\n",
       "  0.014721083454787731,\n",
       "  0.053685519844293594,\n",
       "  -0.002116932300850749,\n",
       "  -0.021865760907530785,\n",
       "  0.049384456127882004,\n",
       "  -0.026108518242836,\n",
       "  0.041917622089385986,\n",
       "  0.013296118937432766,\n",
       "  -0.01783931814134121,\n",
       "  -0.043615564703941345,\n",
       "  -0.012857168912887573,\n",
       "  0.0037120822817087173,\n",
       "  0.021904440596699715,\n",
       "  -0.03062831051647663,\n",
       "  -0.026576370000839233,\n",
       "  -0.023466644808650017,\n",
       "  0.0011108954204246402,\n",
       "  -0.016447611153125763,\n",
       "  -0.014082716777920723,\n",
       "  0.02790267951786518,\n",
       "  0.01006358489394188,\n",
       "  -0.038859352469444275,\n",
       "  -0.014943494461476803,\n",
       "  0.021767549216747284,\n",
       "  -0.020269686356186867,\n",
       "  -0.028326524421572685,\n",
       "  0.01214455533772707,\n",
       "  0.046655718237161636,\n",
       "  -0.02841828763484955,\n",
       "  -0.038227636367082596,\n",
       "  -0.004117453005164862,\n",
       "  0.007422857917845249,\n",
       "  0.06320555508136749,\n",
       "  -0.05372437834739685,\n",
       "  0.01325567252933979,\n",
       "  -0.009352338500320911,\n",
       "  0.04776046797633171,\n",
       "  -0.029629260301589966,\n",
       "  -0.017990872263908386,\n",
       "  0.024349166080355644,\n",
       "  0.0002857521758414805,\n",
       "  -0.02779342234134674,\n",
       "  0.006330494768917561,\n",
       "  -0.01521163247525692,\n",
       "  0.046116121113300323,\n",
       "  -0.03323414549231529,\n",
       "  -0.026243004947900772,\n",
       "  0.01790110394358635,\n",
       "  -0.015290648676455021,\n",
       "  0.03590197488665581,\n",
       "  0.005304430611431599,\n",
       "  -0.0040383958257734776,\n",
       "  0.004549130331724882,\n",
       "  0.05420168489217758,\n",
       "  0.006460280157625675,\n",
       "  0.010330582037568092,\n",
       "  0.027606600895524025,\n",
       "  -0.045506227761507034,\n",
       "  0.007835791446268559,\n",
       "  0.006535777822136879,\n",
       "  -0.06745611876249313,\n",
       "  0.005720962304621935,\n",
       "  0.03617969900369644,\n",
       "  -0.025538265705108643,\n",
       "  -0.04224755987524986,\n",
       "  0.018824152648448944,\n",
       "  0.02387823723256588,\n",
       "  -0.004554289393126965,\n",
       "  -0.036615412682294846,\n",
       "  0.023643143475055695,\n",
       "  0.004361588042229414,\n",
       "  0.034737661480903625,\n",
       "  -0.010855051688849926,\n",
       "  -0.014796946197748184,\n",
       "  -0.0184980146586895,\n",
       "  -0.009387504309415817,\n",
       "  0.03560966998338699,\n",
       "  0.006351661868393421,\n",
       "  -0.016486579552292824,\n",
       "  -0.02485625259578228,\n",
       "  0.021513361483812332,\n",
       "  -0.0076179769821465015,\n",
       "  0.02371981181204319,\n",
       "  -0.0029849109705537558,\n",
       "  -0.018076421692967415,\n",
       "  0.031148549169301987,\n",
       "  -0.0227824617177248,\n",
       "  0.034279730170965195,\n",
       "  0.018984602764248848,\n",
       "  0.005899669602513313,\n",
       "  -0.05744389817118645,\n",
       "  0.009789162315428257,\n",
       "  -0.035006530582904816,\n",
       "  0.039743829518556595,\n",
       "  -0.008110594004392624,\n",
       "  -0.0013241720153018832,\n",
       "  0.025532113388180733,\n",
       "  -0.013267497532069683,\n",
       "  -0.008391836658120155,\n",
       "  -0.008371125906705856,\n",
       "  -0.0026579045224934816,\n",
       "  -0.034811004996299744,\n",
       "  -0.0409209281206131,\n",
       "  0.01839573308825493,\n",
       "  -0.04675271362066269,\n",
       "  0.045047760009765625,\n",
       "  -0.009644823148846626,\n",
       "  0.013644791208207607,\n",
       "  -0.039318617433309555,\n",
       "  0.008860188536345959,\n",
       "  -0.01908387616276741,\n",
       "  0.04995037242770195,\n",
       "  -0.013340097852051258,\n",
       "  -0.01813490316271782,\n",
       "  -0.0006151698180474341,\n",
       "  -0.001044999691657722,\n",
       "  -0.008151575922966003,\n",
       "  -0.01940954104065895,\n",
       "  0.0198377575725317,\n",
       "  -0.0023270337842404842,\n",
       "  -0.013069809414446354,\n",
       "  -0.036563191562891006,\n",
       "  -0.0029352609999477863,\n",
       "  -0.02135971188545227,\n",
       "  0.03859112784266472,\n",
       "  -0.01848876290023327,\n",
       "  0.03135063499212265,\n",
       "  -0.06235587224364281,\n",
       "  -0.009680422022938728,\n",
       "  0.040191106498241425,\n",
       "  0.046115219593048096,\n",
       "  0.01638043113052845,\n",
       "  0.039651621133089066,\n",
       "  0.03583146259188652,\n",
       "  0.04505066201090813,\n",
       "  -0.01550237275660038,\n",
       "  -0.006264543626457453,\n",
       "  -0.004500343929976225,\n",
       "  -0.02366616576910019,\n",
       "  -0.002609790535643697,\n",
       "  -0.028088156133890152,\n",
       "  0.030387328937649727,\n",
       "  0.007580826058983803,\n",
       "  -0.05321593955159187,\n",
       "  -0.017310254275798798,\n",
       "  -0.02215730771422386,\n",
       "  0.054164767265319824,\n",
       "  0.024349449202418327,\n",
       "  -0.029752859845757484,\n",
       "  -0.03780936077237129,\n",
       "  -0.023498425260186195,\n",
       "  0.07164973765611649,\n",
       "  0.00921908114105463,\n",
       "  -0.019775260239839554,\n",
       "  0.007017130497843027,\n",
       "  -0.012112856842577457,\n",
       "  -0.0007648952887393534,\n",
       "  -0.015328061766922474,\n",
       "  0.030363233759999275,\n",
       "  0.004950747359544039,\n",
       "  -0.015982644632458687,\n",
       "  0.030243312940001488,\n",
       "  -0.03692520409822464,\n",
       "  -0.027846354991197586,\n",
       "  0.03168383985757828,\n",
       "  0.030612844973802567,\n",
       "  -0.0376020222902298,\n",
       "  -0.02069963701069355,\n",
       "  0.007475686725229025,\n",
       "  -0.003441095119342208,\n",
       "  -0.02276906929910183,\n",
       "  0.053069815039634705,\n",
       "  0.004510751459747553,\n",
       "  0.015137097798287868,\n",
       "  0.026907745748758316,\n",
       "  0.018480349332094193,\n",
       "  -0.03236870840191841,\n",
       "  0.053389772772789,\n",
       "  0.0071020787581801414,\n",
       "  -0.0024191087577492,\n",
       "  -0.004916421603411436,\n",
       "  0.04067061096429825,\n",
       "  0.008154327049851418,\n",
       "  0.004623505752533674,\n",
       "  -0.053545597940683365,\n",
       "  0.02976285293698311,\n",
       "  -0.010772145353257656,\n",
       "  0.0024076877161860466,\n",
       "  0.025138651952147484,\n",
       "  0.014364952221512794,\n",
       "  -0.0023612610530108213,\n",
       "  -0.05005037412047386,\n",
       "  -0.028689421713352203,\n",
       "  -0.04377148300409317,\n",
       "  0.018926899880170822,\n",
       "  -0.03344501182436943,\n",
       "  -0.012665822170674801,\n",
       "  0.00664476165547967,\n",
       "  -0.0019973330199718475,\n",
       "  0.017692390829324722,\n",
       "  -0.03217615559697151,\n",
       "  -0.030248912051320076,\n",
       "  -0.02915649302303791,\n",
       "  -0.0044904304668307304,\n",
       "  -0.1960560828447342,\n",
       "  0.024146992713212967,\n",
       "  -0.00963734183460474,\n",
       "  -0.012408803217113018,\n",
       "  -0.017044641077518463,\n",
       "  -0.010797170922160149,\n",
       "  -0.0194601621478796,\n",
       "  -0.008816899731755257,\n",
       "  0.01655244641005993,\n",
       "  0.00012896390398964286,\n",
       "  -0.039890795946121216,\n",
       "  0.031640756875276566,\n",
       "  -2.3318467356148176e-05,\n",
       "  -0.04141993448138237,\n",
       "  0.047484781593084335,\n",
       "  -0.002342613646760583,\n",
       "  -0.007457300554960966,\n",
       "  -0.0039479853585362434,\n",
       "  0.00438693119212985,\n",
       "  0.03811576962471008,\n",
       "  0.01714719459414482,\n",
       "  -0.0056363786570727825,\n",
       "  0.024983247742056847,\n",
       "  0.011105508543550968,\n",
       "  0.0613006055355072,\n",
       "  -0.014497485011816025,\n",
       "  -0.020110230892896652,\n",
       "  0.0028831602539867163,\n",
       "  -0.02963915839791298,\n",
       "  -0.02241557091474533,\n",
       "  -0.012910761870443821,\n",
       "  -0.060041166841983795,\n",
       "  0.00031248474260792136,\n",
       "  0.010013005696237087,\n",
       "  -0.013265497051179409,\n",
       "  0.023671859875321388,\n",
       "  -0.003982448484748602,\n",
       "  -0.0035334154963493347,\n",
       "  0.010600807145237923,\n",
       "  0.0076247393153607845,\n",
       "  -0.01732376404106617,\n",
       "  0.007433832623064518,\n",
       "  -0.05756978690624237,\n",
       "  0.00038015362224541605,\n",
       "  -0.0461953803896904,\n",
       "  0.02142152190208435,\n",
       "  -0.039977364242076874,\n",
       "  -0.04298211634159088,\n",
       "  -0.036484476178884506,\n",
       "  -0.05490569397807121,\n",
       "  0.012065245769917965,\n",
       "  -0.017789432778954506,\n",
       "  0.0008630191441625357,\n",
       "  0.024899346753954887,\n",
       "  -0.021412786096334457,\n",
       "  -0.014454237185418606,\n",
       "  -0.009455312043428421,\n",
       "  0.014206944033503532,\n",
       "  -0.012402367778122425,\n",
       "  0.03199467808008194,\n",
       "  -0.025968696922063828,\n",
       "  -0.01690206304192543,\n",
       "  -0.004911208059638739,\n",
       "  -0.07048586755990982,\n",
       "  -0.06307100504636765,\n",
       "  0.0007578872609883547,\n",
       "  -0.058533769100904465,\n",
       "  0.015259744599461555,\n",
       "  0.026521580293774605,\n",
       "  0.016108771786093712,\n",
       "  -0.007110224105417728,\n",
       "  -0.03190847486257553,\n",
       "  0.04466164484620094,\n",
       "  -0.014138923026621342,\n",
       "  0.019370535388588905,\n",
       "  -0.005547173786908388,\n",
       "  0.018855277448892593,\n",
       "  -0.022398963570594788,\n",
       "  -0.03723079711198807,\n",
       "  0.013235019519925117,\n",
       "  -0.02520293928682804,\n",
       "  -0.032688263803720474,\n",
       "  -0.025981547310948372,\n",
       "  -0.015634262934327126,\n",
       "  -0.020604316145181656,\n",
       "  -0.0021996668074280024,\n",
       "  -0.012094426900148392,\n",
       "  0.006805360782891512,\n",
       "  -0.07533818483352661,\n",
       "  0.004047927912324667,\n",
       "  -0.03933962434530258,\n",
       "  -0.027105385437607765,\n",
       "  -0.04279624670743942,\n",
       "  0.017378387972712517,\n",
       "  -0.024187590926885605,\n",
       "  -0.002829505130648613,\n",
       "  -0.01285699661821127,\n",
       "  -0.03847452998161316,\n",
       "  -0.020353998988866806,\n",
       "  -0.0025160128716379404,\n",
       "  -0.02128416672348976,\n",
       "  -0.037514492869377136,\n",
       "  0.005742394365370274,\n",
       "  -0.027981532737612724,\n",
       "  0.0006450215587392449,\n",
       "  0.010571165941655636,\n",
       "  -0.00017975356604438275,\n",
       "  -0.01438291184604168,\n",
       "  0.007303259335458279,\n",
       "  -0.0008017458021640778,\n",
       "  -0.03510648384690285,\n",
       "  -0.03457152098417282,\n",
       "  0.005341953132301569,\n",
       "  0.02309964969754219,\n",
       "  0.04035533592104912,\n",
       "  0.02286922186613083,\n",
       "  -0.0020495159551501274,\n",
       "  -0.0018260958604514599,\n",
       "  -0.006594653241336346,\n",
       "  0.03885478526353836,\n",
       "  -0.04333864524960518,\n",
       "  0.005372025538235903,\n",
       "  0.01248325314372778,\n",
       "  -0.041920918971300125,\n",
       "  -0.010414518415927887,\n",
       "  -0.011107233352959156,\n",
       "  0.013396130874752998,\n",
       "  0.014620667323470116,\n",
       "  -0.01406887173652649,\n",
       "  -0.04063976928591728,\n",
       "  0.034610647708177567,\n",
       "  -0.027733685448765755,\n",
       "  0.03072129376232624,\n",
       "  0.0051416740752756596,\n",
       "  0.00945042259991169,\n",
       "  -0.0024583262857049704,\n",
       "  -0.019251009449362755,\n",
       "  0.010718516074120998,\n",
       "  -0.05061624199151993,\n",
       "  -0.03148709982633591,\n",
       "  -0.01710066758096218,\n",
       "  0.017844732850790024,\n",
       "  0.010000525042414665,\n",
       "  -0.04547690600156784,\n",
       "  -0.01678171381354332,\n",
       "  0.005206388421356678,\n",
       "  0.04728500545024872,\n",
       "  0.001672267448157072,\n",
       "  -0.03607446700334549,\n",
       "  -0.01685202307999134,\n",
       "  0.03232167661190033,\n",
       "  0.03983186557888985,\n",
       "  0.0019025751389563084,\n",
       "  0.012941267341375351,\n",
       "  -0.03413637354969978,\n",
       "  -0.013247023336589336,\n",
       "  -0.0061838035471737385,\n",
       "  0.01501985639333725,\n",
       "  0.048210032284259796,\n",
       "  0.026933778077363968,\n",
       "  -0.0007770485244691372,\n",
       "  0.013791507109999657,\n",
       "  -0.026463951915502548,\n",
       "  -0.014547402039170265,\n",
       "  -0.008682790212333202,\n",
       "  0.035840753465890884,\n",
       "  0.0034411465749144554,\n",
       "  -0.0012810779735445976,\n",
       "  -0.009177963249385357,\n",
       "  -0.05696344003081322,\n",
       "  -0.0020484747365117073,\n",
       "  0.036016467958688736,\n",
       "  -0.03586264327168465,\n",
       "  0.021666843444108963,\n",
       "  0.05939056724309921,\n",
       "  -0.006370142102241516,\n",
       "  0.0159433726221323,\n",
       "  0.04801395907998085,\n",
       "  0.042681384831666946,\n",
       "  0.0004092347517143935,\n",
       "  0.03900976851582527,\n",
       "  0.007056481670588255,\n",
       "  0.034419555217027664,\n",
       "  0.027193209156394005,\n",
       "  -0.038849785923957825,\n",
       "  -0.02233138121664524,\n",
       "  -0.003659670939669013,\n",
       "  -0.001771235722117126,\n",
       "  0.010646938346326351,\n",
       "  0.02082718349993229,\n",
       "  -0.018761683255434036,\n",
       "  0.022612689062952995,\n",
       "  0.006611451040953398,\n",
       "  -0.01964988373219967,\n",
       "  0.0639411211013794,\n",
       "  0.05417132005095482,\n",
       "  0.012467412278056145,\n",
       "  0.011920293793082237,\n",
       "  0.012355184182524681,\n",
       "  0.003950623329728842,\n",
       "  -0.02180495858192444,\n",
       "  -0.03322552517056465,\n",
       "  0.012269441038370132,\n",
       "  -0.035729166120290756,\n",
       "  -0.001740136998705566,\n",
       "  0.03116588108241558,\n",
       "  -0.017695371061563492,\n",
       "  2.93684297503205e-05,\n",
       "  -0.014024095609784126,\n",
       "  0.00781903974711895,\n",
       "  0.021852081641554832,\n",
       "  -0.03157493844628334,\n",
       "  0.0156394075602293,\n",
       "  0.028202546760439873,\n",
       "  -0.00331141147762537,\n",
       "  0.038428258150815964,\n",
       "  -0.012215581722557545,\n",
       "  -0.01830325275659561,\n",
       "  -0.016181351616978645,\n",
       "  -0.001854612142778933,\n",
       "  ...]]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_embedding = HuggingFaceEndpointEmbeddings(\n",
    "    model='BAAI/bge-m3',\n",
    "    task='feature-extraction',\n",
    ")\n",
    "\n",
    "model_embedding.embed_documents(['hello world'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OllamaEmbeddings\n",
    "\n",
    "ollama를 통한 embedding. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> ollama_embeddings = OllamaEmbeddings(\n",
    ">     model=<model_name>,\n",
    "> )\n",
    "> \n",
    "> # 문서 임베딩\n",
    "> embedded_documents = ollama_embeddings.embed_documents(texts)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embedding = OllamaEmbeddings(\n",
    "    model='llama3.2:1b'\n",
    ")\n",
    "model_embedding.embed_documents(['hello world'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database\n",
    "\n",
    "[langchain 지원 db](https://python.langchain.com/v0.2/docs/integrations/vectorstores/)\n",
    "\n",
    "[VectorDB 비교](https://discuss.pytorch.kr/t/2023-picking-a-vector-database-a-comparison-and-guide-for-2023/2625)\n",
    "\n",
    "임베딩된 벡터들을 효율적으로 저장하고 관리하는 과정. <br>\n",
    "이 단계는 향후 검색 과정에서 벡터들을 빠르게 조회하고, 관련 문서를 신속하게 찾아내는 데 중요. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style=\"font-size:20px\"> 특징 </font>\n",
    "\n",
    "- 빠른 검색 속도: 임베딩 벡터들을 효과적으로 저장하고 색인화함으로써, 대량의 데이터 중에서도 관련된 정보를 빠르게 검색 가능. <br>\n",
    "- Scailability: 데이터가 지속적으로 증가함에 따라 이를 수용할 수 있는 충분한 scailability를 제공해야 함. 효율적인 저장 구조는 데이터베이스의 확장성을 보장하며, 시스템의 성능 저하 없이 대규모 데이터를 관리할 수 있도록 함.\n",
    "- Semantic Search: 사용자의 질문과 의미상으로 유사한 단락 조회."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAISS\n",
    "\n",
    "paper: [FAISS](https://arxiv.org/pdf/1702.08734) <br>\n",
    "blog: [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)\n",
    "\n",
    "reference: [FAISS](https://python.langchain.com/v0.2/docs/integrations/vectorstores/faiss/)\n",
    "\n",
    "documentation: [FAISS](https://faiss.ai/)\n",
    "\n",
    "FAISS: Facebook AI Similarity Search <br>\n",
    "밀집 벡터의 효율적인 유사도 검색과 클러스터링을 위한 library. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create\n",
    "\n",
    "> ```python\n",
    "> dimension_size = 1536\n",
    ">\n",
    "> # FAISS Vector Store 생성\n",
    "> db = FAISS(\n",
    ">     embedding_function=OpenAIEmbeddings(),\n",
    ">     index=faiss.IndexFlatL2(dimension_size),\n",
    ">     docstore=InMemoryDocstore(),\n",
    ">     index_to_docstore_id={},\n",
    "> )\n",
    ">\n",
    "> # Document로부터 FAISS Vector Store 생성\n",
    "> db = FAISS.from_documents(\n",
    ">     documents=documents,\n",
    ">     embedding=OpenAIEmbeddings(),\n",
    "> )\n",
    ">\n",
    "> # text로부터 FAISS Vector Store 생성\n",
    "> db = FAISS.from_texts(\n",
    ">     texts=texts,\n",
    ">     embedding=OpenAIEmbeddings(),\n",
    ">     metadatas=None,\n",
    ">     ids=None,\n",
    "> )\n",
    ">\n",
    "> db.index_to_docstore_id # 문서 저장소 ID 확인\n",
    "> db.docstore._dict       # 저장된 문서의 ID: Document\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('./data/nlp_keywords.txt')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "documents = loader.load_and_split(text_splitter)\n",
    "\n",
    "db = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=OpenAIEmbeddings(model='text-embedding-3-small'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'f48b3541-b55f-4f67-b828-5175e5fd94ad',\n",
       " 1: '8d113398-d5e8-40af-b5dc-3cdfce382f13',\n",
       " 2: 'fdc229cf-1bc1-45e2-8603-f508e3ee5f9f',\n",
       " 3: 'c3bef6e6-c1f6-4394-b25e-8f93e62d0dc9',\n",
       " 4: 'db52abbb-2d71-45b9-8c56-7623f8a19a39',\n",
       " 5: '096ac4ca-654a-4453-8d69-8ffb3160e530',\n",
       " 6: '8704f47a-015d-46ac-9b85-a19d83f67d72',\n",
       " 7: '1339500a-343b-4229-b9d3-9d23a68f5071',\n",
       " 8: '726a8782-251a-4895-878b-c097ef229cd2',\n",
       " 9: 'b5e4443b-df91-4c69-bc4e-7fa1a9cb2e48',\n",
       " 10: '8e347d59-c599-44f8-8f89-a84ea02c9cde',\n",
       " 11: 'f98312e2-6610-423a-904e-55c71e257658',\n",
       " 12: 'f8b81d8a-44fc-44e3-bb46-ad910b322ec7',\n",
       " 13: '3598b1ff-2bd8-453c-8a38-5c6aaab96f72',\n",
       " 14: 'a00408ce-c968-40c9-a432-1747484fd362',\n",
       " 15: '1658521e-7ebf-47cf-93b8-1fc7870c3977',\n",
       " 16: '5a4ed1c9-71af-4369-b85a-60d0de4af9cb',\n",
       " 17: '48fbd35d-c6f7-45f6-ae81-4784b0ea653d',\n",
       " 18: '38719c94-791e-41ef-ad8a-2d1e2c1f98b3',\n",
       " 19: 'd259c738-dc28-467d-9bd1-b9033b88db72'}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f48b3541-b55f-4f67-b828-5175e5fd94ad': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nAttention 메커니즘'),\n",
       " '8d113398-d5e8-40af-b5dc-3cdfce382f13': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content=\"Attention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\"),\n",
       " 'fdc229cf-1bc1-45e2-8603-f508e3ee5f9f': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\\n\\nDeep Learning'),\n",
       " 'c3bef6e6-c1f6-4394-b25e-8f93e62d0dc9': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Deep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nDataFrame'),\n",
       " 'db52abbb-2d71-45b9-8c56-7623f8a19a39': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='DataFrame\\n\\n정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nLLM (Large Language Model)'),\n",
       " '096ac4ca-654a-4453-8d69-8ffb3160e530': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='LLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nHuggingFace'),\n",
       " '8704f47a-015d-46ac-9b85-a19d83f67d72': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='HuggingFace\\n\\n정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nTransformer'),\n",
       " '1339500a-343b-4229-b9d3-9d23a68f5071': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Transformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nSQL'),\n",
       " '726a8782-251a-4895-878b-c097ef229cd2': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='SQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nJSON'),\n",
       " 'b5e4443b-df91-4c69-bc4e-7fa1a9cb2e48': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='JSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nCSV'),\n",
       " '8e347d59-c599-44f8-8f89-a84ea02c9cde': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='CSV\\n\\n정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nStructured Data'),\n",
       " 'f98312e2-6610-423a-904e-55c71e257658': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Structured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
       " 'f8b81d8a-44fc-44e3-bb46-ad910b322ec7': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nSemantic Search'),\n",
       " '3598b1ff-2bd8-453c-8a38-5c6aaab96f72': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nToken'),\n",
       " 'a00408ce-c968-40c9-a432-1747484fd362': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Token\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer'),\n",
       " '1658521e-7ebf-47cf-93b8-1fc7870c3977': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Tokenizer\\n\\n정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore'),\n",
       " '5a4ed1c9-71af-4369-b85a-60d0de4af9cb': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='VectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nCrawling'),\n",
       " '48fbd35d-c6f7-45f6-ae81-4784b0ea653d': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Crawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec'),\n",
       " '38719c94-791e-41ef-ad8a-2d1e2c1f98b3': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Word2Vec\\n\\n정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\n\\nFAISS (Facebook AI Similarity Search)'),\n",
       " 'd259c738-dc28-467d-9bd1-b9033b88db72': Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='FAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화')}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.docstore._dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_temp = FAISS.from_texts(\n",
    "    ['hello', 'hi', 'nice to meet you'],\n",
    "    embedding=OpenAIEmbeddings(model='text-embedding-3-small'),\n",
    "    metadatas=[\n",
    "        {'source': 'greeting'},\n",
    "        {'source': 'greeting'},\n",
    "        {'source': 'greeting'},\n",
    "    ],\n",
    "    ids=['1', '2', '3']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': Document(metadata={'source': 'greeting'}, page_content='hello'),\n",
       " '2': Document(metadata={'source': 'greeting'}, page_content='hi'),\n",
       " '3': Document(metadata={'source': 'greeting'}, page_content='nice to meet you')}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_temp.docstore._dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: SPRi AI brief\n",
    "# pdf load\n",
    "loader = PyPDFLoader('./data/SPRi AI Brief_10월호_산업동향_F.pdf')\n",
    "documents = loader.load()\n",
    "\n",
    "# splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# to db\n",
    "db = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=OpenAIEmbeddings(model='text-embedding-3-small')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Similarity Search\n",
    "\n",
    "주어진 쿼리와 가장 유사한 문서 검색. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> db.similarity_search(\n",
    ">     'TF IDF 에 대하여 알려줘',\n",
    ">     # filter={'source': './data/keywords.txt'},\n",
    ">     # fetch_k=20,   # 필터링 이전 가져올 문서 수.\n",
    ">     # k=2,          # fetch_k로 가져온 문서 중에서 필터링을 거쳐 최종 몇 개의 문서를 선택할지 결정\n",
    "> )\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nAttention 메커니즘')]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\n",
    "    'GPT가 뭐야?',\n",
    "    k=1,\n",
    "    filter={\n",
    "        'source': './data/nlp_keywords.txt'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add\n",
    "\n",
    "DB에 문서를 추가하거나 업데이트. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> # Document 추가\n",
    "> db.add_documents(\n",
    ">     [\n",
    ">         Document(\n",
    ">             page_content='new document',\n",
    ">           metadata={'source': 'my brain'},\n",
    ">         )\n",
    ">     ],\n",
    ">     ids=['new_id1'],\n",
    "> )\n",
    "> \n",
    "> # text를 통한 추가\n",
    "> db.add_texts(\n",
    ">     ['new text data', 'new text data2'],\n",
    ">     metadatas=[{'source': 'my brain'}, {'source': 'my brain'}],\n",
    ">     ids=['new_id2', 'new_id3'],\n",
    "> )\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cf6a667e-8d3b-47db-b21f-f1fc8e097a74']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_documents(\n",
    "    [\n",
    "        Document(\n",
    "            page_content='test',\n",
    "            metadata={'source': 'my_brain'}\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'my_brain'}, page_content='test'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='SQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nJSON'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Transformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nSQL'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Tokenizer\\n\\n정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore')]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['429a17ec-311a-4215-a953-8a6a43f67e8c',\n",
       " 'ace820f5-d3c5-4bf5-b32b-d2117dda2bac']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 텍스트: KOSPI, KOSDAQ\n",
    "# metadata: 'source': 'KRX'\n",
    "\n",
    "db.add_texts(\n",
    "    ['KOSPI', 'KOSDAQ'],\n",
    "    metadatas=[{'source': 'KRX'}, {'source': 'KRX'}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'KRX'}, page_content='KOSDAQ'),\n",
       " Document(metadata={'source': 'KRX'}, page_content='KOSPI')]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search('KOS', k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete\n",
    "\n",
    "DB에서 특정 ID의 문서 제거 <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> db.delete(ids)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.delete(['cf6a667e-8d3b-47db-b21f-f1fc8e097a74'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'KRX'}, page_content='KOSDAQ'),\n",
       " Document(metadata={'source': 'KRX'}, page_content='KOSPI'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='SQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nJSON'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Transformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nSQL')]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save/Load\n",
    "\n",
    "DB를 로컬 디스크에 저장. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    ">```python\n",
    "> # save\n",
    "> db.save_local(\n",
    ">     folder_path='faiss_db',\n",
    ">     index_name='faiss_index',\n",
    "> )\n",
    "> \n",
    "> # load\n",
    "> db = FAISS.load_local(\n",
    ">     folder_path='faiss_db',\n",
    ">     index_name='faiss_index',\n",
    ">     embeddings=OpenAIEmbedding(),\n",
    ">     allow_dangerous_deserialization=True,   # pickle 파일 역직렬화 허용 여부\n",
    "> )\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(\n",
    "    folder_path='faiss_db',\n",
    "    index_name='faiss_index',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_temp = FAISS.load_local(\n",
    "    folder_path='faiss_db',\n",
    "    index_name='faiss_index',\n",
    "    embeddings=OpenAIEmbeddings(model='text-embedding-3-small'),\n",
    "    allow_dangerous_deserialization=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'KRX'}, page_content='KOSDAQ'),\n",
       " Document(metadata={'source': 'KRX'}, page_content='KOSPI'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Transformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nSQL'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='JSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nCSV')]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_temp.similarity_search('KOS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge\n",
    "\n",
    "두 FAISS 객체를 병합. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> db.merge_from(db2)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: finance_keywords\n",
    "# load\n",
    "loader = TextLoader('./data/finance_keywords.txt')\n",
    "\n",
    "# splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "documents = loader.load_and_split(text_splitter)\n",
    "\n",
    "# to db\n",
    "db2 = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=OpenAIEmbeddings(model='text-embedding-3-small')\n",
    ")\n",
    "\n",
    "# merge\n",
    "db.merge_from(db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/finance_keywords.txt'}, page_content='헤지 (Hedge)\\n\\n정의: 헤지는 투자에서 손실을 줄이기 위해 위험을 줄이는 전략을 의미합니다.\\n예시: 파생상품을 이용해 가격 변동 리스크를 헤지할 수 있습니다.\\n연관키워드: 리스크 관리, 투자, 파생상품\\n\\n유가증권 (Securities)\\n\\n정의: 유가증권은 투자자에게 소유권이나 채권을 부여하는 재무 자산입니다.\\n예시: 주식과 채권이 유가증권에 해당합니다.\\n연관키워드: 투자, 금융 시장, 증권\\n\\n세금 (Tax)'),\n",
       " Document(metadata={'source': './data/finance_keywords.txt'}, page_content='시장 (Market)\\n\\n정의: 시장은 상품이나 서비스가 거래되는 공간을 의미합니다.\\n예시: 주식 시장, 외환 시장 등이 있습니다.\\n연관키워드: 경제, 거래, 투자\\n\\n재무제표 (Financial Statement)\\n\\n정의: 재무제표는 기업의 재무 상태와 성과를 나타내는 공식 문서입니다.\\n예시: 손익계산서, 대차대조표가 재무제표의 일종입니다.\\n연관키워드: 회계, 재무, 분석\\n\\n헤지 (Hedge)'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content=\"Attention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\"),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Tokenizer\\n\\n정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore')]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search('헤지가 뭐야?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### as_retriever\n",
    "\n",
    "현재 db를 기반으로 VectorStoreRetriver 객체 생성. <br>\n",
    "\n",
    "MMR: $ \\lambda \\cdot \\text{Sim}(d, Q) + (1 - \\lambda) \\cdot max_{d' \\in D'} Sim (d, d') $\n",
    "- $ \\text{Sim}(d, Q) $: 문서와 쿼리 간 유사도\n",
    "- $ max_{d' \\in D'} Sim (d, d') $: 문서(d)와 이미 선택된 문서 집합 (D') 중 가장 유사한 문서와의 유사성\n",
    "- $ \\lambda $: 유사성과 다양성의 반영도를 조절하는 파라미터\n",
    "    - $ \\lambda = 1 $: 유사성만 고려\n",
    "    - $ \\lambda = 0 $: 다양성 최대화\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> # similarity\n",
    "> retriever = db.as_retriever()\n",
    "> retriever.invoke('tf-idf에 대해서 알려줘')\n",
    "> \n",
    "> # mmr (maximal marginal relavance)\n",
    "> retriever = db.as_retriever(\n",
    ">     searcy_type='mmr',\n",
    ">     search_kwargs={\n",
    ">         'fetch_k': 20,        # mmr에 전달할 문서 수\n",
    ">         'k': 6,               # 반환 무서 수\n",
    ">         'lambda_mult': 0.25,  # 다양성 조정 파라미터\n",
    ">         # 'filter': {'source': './data/keywords.txt'}        # 메타데이터 기반 필터링\n",
    ">     }\n",
    "> )\n",
    "> retriever.invoke('tf-idf에 대해서 알려줘')\n",
    ">\n",
    "> # score threshold\n",
    "> retriever = db.as_retriever(\n",
    ">     search_type='similarity_score_threshold',\n",
    ">     search_kwargs={'score_threshold': 0.8},\n",
    "> )\n",
    "> retriever.invoke('tf-idf에 대해서 알려줘') \n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={\n",
    "        'fetch_k': 20,\n",
    "        'k': 1,\n",
    "        'lambda_mult': 0.3,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nAttention 메커니즘')]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('GPT가 뭐야?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chroma\n",
    "\n",
    "reference: [Chroma](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/)\n",
    "\n",
    "<br>\n",
    "\n",
    "개발자의 생산성과 행복에 초점을 맞춘 AI 네이티브 오픈 소스 벡터 데이터베이스. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create\n",
    "\n",
    "> ```python\n",
    "> # document로부터 Chroma Vector Store 생성\n",
    "> db = Chroma.from_documents(\n",
    ">     documents=documents,\n",
    ">     embedding=OpenAIEmbeddings(),\n",
    ">     collection_name='db',\n",
    ">     # persist_directory=<db_path> # disk에 파일 형태로 저장\n",
    "> )\n",
    "> \n",
    "> # 텍스트로부터 Chroma Vector Store 생성\n",
    "> db2 = Chroma.from_texts(\n",
    ">     ['python', 'cpp'],\n",
    ">     embedding=OpenAIEmbeddings(),\n",
    "> )\n",
    "> \n",
    "> db.get()    # 정보 확인\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Similarity Search\n",
    "\n",
    "주어진 쿼리와 가장 유사한 문서 검색. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> db.similarity_search(\n",
    ">     'TF IDF 에 대하여 알려줘',\n",
    ">     # filter={'source': './data/keywords.txt'},\n",
    ">     # k=2,          # fetch_k로 가져온 문서 중에서 필터링을 거쳐 최종 몇 개의 문서를 선택할지 결정\n",
    "> )\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add\n",
    "\n",
    "DB에 문서를 추가하거나 업데이트. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> # Document 추가\n",
    "> db.add_documents(\n",
    ">     [\n",
    ">         Document(\n",
    ">             page_content='new document',\n",
    ">             metadata={'source': 'my brain'},\n",
    ">             id='1',    # 제공되지 않으면 자동생성\n",
    ">         )\n",
    ">     ],\n",
    "> )\n",
    "> \n",
    "> # text를 통한 추가\n",
    "> db.add_texts(\n",
    ">     ['new text data', 'new text data2'],\n",
    ">     metadatas=[{'source': 'my brain'}, {'source': 'my brain'}],\n",
    ">     ids=['new_id2', 'new_id3'],\n",
    "> )\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete\n",
    "\n",
    "DB에서 특정 ID의 문서 제거 <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> db.delete(ids)           # 특정 id 삭제\n",
    "> db.reset_collection()    # collection 초기화\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### as_retriever\n",
    "\n",
    "현재 db를 기반으로 VectorStoreRetriver 객체 생성. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> # similarity\n",
    "> retriever = db.as_retriever()\n",
    "> retriever.invoke('tf-idf에 대해서 알려줘')\n",
    "> \n",
    "> # mmr (maximal marginal relavance)\n",
    "> retriever = db.as_retriever(\n",
    ">     searcy_type='mmr',\n",
    ">     search_kwargs={\n",
    ">         'fetch_k': 20,        # mmr에 전달할 문서 수\n",
    ">         'k': 6,               # 반환 무서 수\n",
    ">         'lambda_mult': 0.25,  # 다양성 조정 파라미터\n",
    ">         # 'filter': {'source': './data/keywords.txt'}        # 메타데이터 기반 필터링\n",
    ">     }\n",
    "> )\n",
    "> retriever.invoke('tf-idf에 대해서 알려줘')\n",
    ">\n",
    "> # score threshold\n",
    "> retriever = db.as_retriever(\n",
    ">     search_type='similarity_score_threshold',\n",
    ">     search_kwargs={'score_threshold': 0.8},\n",
    "> )\n",
    "> retriever.invoke('tf-idf에 대해서 알려줘') \n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice\n",
    "# 네이버 뉴스 경제 세션의 기사 크롤링\n",
    "## 기사 url 찾기\n",
    "response = requests.get('https://news.naver.com/section/101')\n",
    "bs_response = BeautifulSoup(response.text, 'lxml')\n",
    "urls = [\n",
    "    item.get('href')\n",
    "    for item\n",
    "    in bs_response.select('div#newsct div.sa_text > a')\n",
    "]\n",
    "\n",
    "## 전체 기사 크롤링\n",
    "news = naver_news_crawler(urls)\n",
    "\n",
    "# splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "documents = text_splitter.split_documents(\n",
    "    news\n",
    ")\n",
    "\n",
    "# db (Chroma)\n",
    "db_chroma = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=OpenAIEmbeddings(model='text-embedding-3-small'),\n",
    "    collection_name='news',\n",
    "    persist_directory='./db'\n",
    ")\n",
    "\n",
    "# as_retriever\n",
    "retriever_chroma = db_chroma.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever\n",
    "\n",
    "저장된 벡터 데이터베이스에서 사용자의 질문과 관련된 문서를 검색하는 과정. <br> RAG 시스템의 전반적인 성능과 직결. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style=\"font-size=20\"> 특징 </font>\n",
    "\n",
    "1\\. 정확한 정보 제공: 사용자의 질문과 가장 관련성 높은 정보를 검색. <br>\n",
    "시스템이 정확하고 유용한 답변을 생성할 수 있도록 함. <br>\n",
    "이 과정이 효과적으로 이루어지지 않으면, 답변의 품질이 떨어질 수 있음. <br>\n",
    "\n",
    "2\\.응답 시간 단축: 효율적인 검색 알고리즘을 사용하여 데이터베이스에서 적절한 정보를 빠르게 검색함으로써, 전체적인 시스템 응답 시간 단축. <br>\n",
    "사용자 경험 향상에 직접적인 영향. <br>\n",
    "\n",
    "3\\.최적화: 효과적인 검색 과정을 통해 필요한 정보만을 추출함. <br> \n",
    "-> 시스템 자원 사용 최적화, 불필요한 데이터 처리 감소.\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style=\"font-size=20\"> 동작 방식 </font>\n",
    "\n",
    "1\\. 질문의 벡터화: 사용자의 질문을 벡터 형태로 변환. <br>\n",
    "임베딩 단계와 유사한 기술을 사용하여 진행되며, 변환된 질문 벡터는 후속 검색 작업의 기준점으로 사용. <br>\n",
    "\n",
    "2\\.벡터 유사성 비교: 저장된 문서 벡터와 질문 벡터 사이의 유사성을 계산. <br> cosine similarity,, Max Marginal Relevance(MMR) 등의 수학적 방법을 통하여 수행.\n",
    "\n",
    "3\\.상위 문서 선정: 계산된 유사성 점수를 기준으로 상위 N개의 가장 관련성 높은 문서 선정. <br>\n",
    "이 문서들은 다음 단계에서 사용자의 질문에 대한 답변을 생성하는 데 사용. <br>\n",
    "\n",
    "4\\.문서 정보 반환: 선정된 문서들의 정보를 전달. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style=\"font-size=20\"> Sparse vs Dense </font>\n",
    "\n",
    "Sparse Retriever와 Dense Retriever는 정보 검색 시스템에서 사용되는 두 가지 주요 방법. <br>\n",
    "대규모 문서 집합에서 관련 문서를 검색할 때 사용. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style=\"font-size=18\"> Sparse Retriever </font>\n",
    "\n",
    "문서와 질문을 이산적인 키워드 벡터로 변환하여 처리. <br>\n",
    "TF-IDF나 BM25와 같은 정보 검색 기법 사용. <br>\n",
    "\n",
    "- TF-IDF: 단어가 문서에 나타나는 빈도와 그 단어가 몇 개의 문서에서 나타나는지를 반영하여 단어의 중요도 계산. <br>\n",
    "자주 나타나면서도 문서 집합 전체에서 드물게 나타나는 단어가 높은 가중치를 받음.\n",
    "- BM25: TF-IDF를 개선한 모델. <br>\n",
    "문서의 길이를 고려하여 검색 정확도를 향상. <br>\n",
    "긴 문서와 짧은 문서 간의 가중치를 조정하여, 단어 빈도의 영향을 상대적으로 조절.\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style=\"font-size=18\"> Dense Retriever </font>\n",
    "\n",
    "딥러닝 기법을 사용하여 문서와 쿼리를 연속적인 고차원 벡터로 인코딩. <br>\n",
    "문서의 의미적 내용을 보다 풍부하게 표현 가능. <br>\n",
    "키워드가 완벽히 일치하지 않더라도 의미적으로 관련된 문서를 검색 가능. <br>\n",
    "\n",
    "벡터 공간에서의 거리를 사용하여 쿼리와 가장 관련성 높은 문서를 찾음. <br>\n",
    "언어의 뉘앙스와 문맥을 이해하는 데 유리하며, 복잡한 쿼리에 대해 더 정확한 검색 결과를 제공 가능. <br>\n",
    "\n",
    "||Sparse Retriever|Dense Retriever|\n",
    "|-|----------------|---------------|\n",
    "|표현 방식|이산적 키워드|연속 벡터|\n",
    "|의미 처리 능력|문맥과 의미 파악 어려움, 키워드가 정확하게 일치해야 함|문맥과 의미 파악 가능, 키워드가 정확하게 일치하지 않아도 됨|\n",
    "|적용 범위|간단, 명확한 키워드 검색| 복잡한 질문 등|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VectorStore Retriever\n",
    "\n",
    "vector store를 사용하여 문서를 검색하는 retriever. <br>\n",
    "similarity search나 MMR과 같은 기법을 통하여 vector store 내 텍스트 쿼리. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> # Retriever를 호출하여 주어진 쿼리에 대한 관련 문서를 반환\n",
    "> retriever.invoke('tf-idf란 무엇인가?')\n",
    "> \n",
    "> # Configurable\n",
    "> retriever = db.as_retriever(\n",
    ">     search_kwargs={'k': 1}\n",
    "> ).configurable_fields(\n",
    ">     search_type=ConfigurableField(\n",
    ">         id='search_type',\n",
    ">         name='Search Type',\n",
    ">         description='검색 방법',\n",
    ">     ),\n",
    ">     search_kwargs=ConfigurableField(\n",
    ">         id='search_kwargs',\n",
    ">         name='Search Kwargs',\n",
    ">         description='검색 kwargs',\n",
    ">     ),\n",
    "> )\n",
    "> \n",
    "> # 상위 세 개 반환\n",
    "> config = {'configurable': {'search_kwargs': {'k': 3}}}\n",
    "> retriever.invoke('what embedding is?', config=config)\n",
    "> \n",
    "> # 검색 설정 지정, score_threshold 0.7이상의 문서 반환\n",
    "> config = {\n",
    ">     'configurable': {\n",
    ">         'search_type': 'similarity_score_threshold',\n",
    ">         'search_kwargs': {\n",
    ">             'score_threshold': 0.7,\n",
    ">         },\n",
    ">     }\n",
    "> }\n",
    "> retriever.invoke('what embedding is?', config=config)\n",
    "> \n",
    "> # 검색 설정 지정, mmr 사용.\n",
    "> config = {\n",
    ">     'configurable': {\n",
    ">         'search_type': 'mmr',\n",
    ">         'search_kwargs': {\n",
    ">             'k': 2,\n",
    ">             'fetch_k': 10,\n",
    ">             'lambda_mult': 0.6,\n",
    ">         },\n",
    ">     }\n",
    "> }\n",
    "> retriever.invoke('what embedding is?', config=config)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_chroma를 리트리버로 변환\n",
    "retriever_chroma = db_chroma.as_retriever(\n",
    "    # 검색할 결과의 개수를 1로 설정\n",
    "    search_kwargs={'k': 1},    \n",
    ").configurable_fields(\n",
    "    # 검색 알고리즘을 선택할 수 있는 필드 설정\n",
    "    search_type=ConfigurableField(\n",
    "        id='search_type',  # 필드의 고유 ID\n",
    "        name='Search Type',  # 사용자에게 보여질 필드 이름\n",
    "        description='검색 알고리즘 선택'  # 필드에 대한 설명\n",
    "    ),\n",
    "    # 검색 알고리즘의 설정을 위한 필드 설정\n",
    "    search_kwargs=ConfigurableField(\n",
    "        id='search_kwargs',  # 필드의 고유 ID\n",
    "        name='Search Kwargs',  # 사용자에게 보여질 필드 이름\n",
    "        description='검색 알고리즘의 config'  # 필드에 대한 설명\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://n.news.naver.com/mnews/article/018/0005868170'}, page_content='가족들을 비롯해 삼성 계열사 사장단 및 임직원 등 1000여 명이 참석했다. 공연장 로비에는 이 선대회장의 생전 사진과 삼성 경영과 관련해 당부했던 메시지가 전시됐다. ‘휴대폰 개발에 신경을 쓰십시오. 반드시 한 명당 한 대의 무선 단말기를 가지는 시대가 옵니다’(1995년), ‘미래 사회에는 손톱 크기의 반도체에 지구 상의 모든 정보를 담아 휴대가 가능해지고, 인간의 두뇌에 버금가는 인공지능(AI)이 개발될 것입니다’(2000년)등 이 선대회장의 주요 발언이 소개됐다.이 선대회장은 1987년 부친인 이병철 창업회장 별세 이후'),\n",
       " Document(metadata={'source': 'https://n.news.naver.com/mnews/article/422/0000689027'}, page_content='주가 반등세를 보이는 반면 삼성전자 주가가 연일 하락하면서 52주 신저가를 재차 경신했습니다. 외국인은 역대 최장인 33거래일 연속 삼성전자를 순매도하고 있는데 어떻습니까? 언제쯤 반등할 수 있을까요? 연합뉴스TV 기사문의 및 제보 : 카톡/라인 jebo23')]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever_chroma를 사용하여 '삼성전자'에 대한 검색 수행\n",
    "results = retriever_chroma.invoke(\n",
    "    '삼성전자',  # 검색할 쿼리\n",
    "    config={  # 검색 설정을 포함하는 구성\n",
    "        'configurable': {\n",
    "            'search_type': 'mmr',  # 사용할 검색 알고리즘 타입 (MMR - Maximal Marginal Relevance)\n",
    "            'search_kwargs': {  # 검색 알고리즘에 대한 추가 설정\n",
    "                'k': 2,  # 반환할 결과의 수 (상위 2개 결과)\n",
    "                'fetch_k': 10,  # 내부적으로 가져올 결과의 수 (10개)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# 검색 결과 출력\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ContextualCompressionRetriever\n",
    "\n",
    "<img src=\"https://wikidocs.net/images/page/234097/01-Contextual-Compression.jpeg\" width=\"400\">\n",
    "\n",
    "<br>\n",
    "\n",
    "사용자의 질문에 대하여 관련성이 높은 정보가 많은 양의 무관한 텍스트를 포함한 문서에 묻혀 있을 수 있을 가능성이 높음. <br>\n",
    "이러한 전체 문서를 전달하면 LLM 호출에 많은 비용이 들어가며, 낮은 품질의 응답으로 이어질 수 있음. <br>\n",
    "\n",
    "ContextualCompressionRetriever 검색된 문서를 그대로 반환하는 대신, 주어진 질의의 맥락을 사용하여 문서를 압축함으로써 관련 정보만 반환되도록 함. <br>\n",
    "- 압축: 개별 문서의 내용을 압축하는 것, 문서를 전체적으로 필터링하는 것\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> # EmbeddingsFilter: 문서와 쿼리를 임베딩하고 쿼리와 충분히 유사한 임베딩을 가진 문서만 반환하여 더 저렴하고 빠른 옵션 제공.\n",
    "> embeddings_filter = EmbeddingsFilter(\n",
    ">     embeddings=OpenAIEmbeddings(),\n",
    ">     similarity_threshold=0.8,   # 유사도가 0.8 이상인 문서 필터\n",
    "> )\n",
    "> \n",
    "> compression_retriever = ContextualCompressionRetriever(\n",
    ">     base_compressor=embeddings_filter,\n",
    ">     base_retriever=retriever,\n",
    "> )\n",
    "> \n",
    "> compression_retriever.invoke(<question>)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAIEmbeddings를 사용하여 임베딩 필터를 생성\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=OpenAIEmbeddings(model='text-embedding-3-small'),  # 사용할 임베딩 모델 지정\n",
    "    similarity_threshold=0.7,  # 유사도 임계값 설정 (0.7 이상인 경우만 필터링)\n",
    ")\n",
    "\n",
    "# ContextualCompressionRetriever를 생성하여 압축된 검색 결과를 반환\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter,  # 임베딩 필터를 압축기로 사용\n",
    "    base_retriever=retriever_chroma,     # 기본 리트리버로 retriever_chroma 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.7 이상의 유사도를 가진 문서가 없음음\n",
    "compression_retriever.invoke('삼성전자')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EnsembleRetriever\n",
    "\n",
    "EnsembleRetriever는 여러 검색기를 결합하여 더 강력한 검색 결과를 제공하는 LangChain의 기능. <br>\n",
    "다양한 검색 알고리즘의 장점을 활용하여 단일 알고리즘보다 더 나은 성능을 달성 가능. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<font style='font-size:20px'> 특징 </font>\n",
    "\n",
    "1. 여러 검색기 통합: 다양한 유형의 검색기를 입력으로 받아 결과 결합.\n",
    "2. 결과 재순위화: Reciprocal Rank Fusion 알고리즘을 사용하여 결과의 순위 조정.\n",
    "3. 하이브리드 검색: 주로 sparse retriever와 dense retriever를 결합하여 사용.\n",
    "- Sparse retriever: 키워드 기반 검색에 효과적\n",
    "- Dense retriever: 의미적 유사성 기반 검색에 효과적\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> documents: list[str]\n",
    "> \n",
    "> bm25_retriever = BM25Retriever.from_texts(\n",
    ">     doc_list,\n",
    "> )\n",
    "> bm25_retriever.k = 1\n",
    "> \n",
    "> faiss_vectorstore = FAISS.from_texts(\n",
    ">     doc_list,\n",
    ">     embedding=OpenAIEmbeddings(model_name='gpt-4o-mini'),\n",
    "> )\n",
    "> faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={'k': 1})\n",
    "> \n",
    "> ensemble_retriever = EnsembleRetriever(\n",
    ">     retrievers=[bm25_retriever, faiss_retriever],\n",
    ">     weights=[0.7, 0.3],\n",
    "> )\n",
    "> \n",
    "> query = 'query'\n",
    "> ensemble_result = ensemble_retriever.invoke(query)\n",
    "> \n",
    "> # configurable\n",
    "> ensemble_retriever = EnsembleRetriever(\n",
    ">     retrievers=[bm25_retriever, faiss_retriever],\n",
    "> ).configurable_fields(\n",
    ">     weights=ConfigurableField(\n",
    ">         id='ensemble_weights',\n",
    ">         name='Ensemble Weights',\n",
    ">         description='Ensemble Weights',\n",
    ">     )\n",
    "> )\n",
    "> \n",
    "> config = {'configurable': {'ensemble_weights': [1, 0]}}\n",
    "> ensemble_retriever.invoke('what embedding is', config=config)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25Retriever를 사용하여 문서에서 검색을 수행하는 리트리버 생성\n",
    "retriever_b25 = BM25Retriever.from_documents(news)\n",
    "retriever_b25.k = 1  # 반환할 결과의 개수를 1로 설정\n",
    "\n",
    "# Chroma를 사용하여 문서로부터 임베딩 데이터베이스 생성\n",
    "db_chroma_temp = Chroma.from_documents(\n",
    "    news,  # 사용될 문서\n",
    "    embedding=OpenAIEmbeddings(model='text-embedding-3-small'),  # 사용할 임베딩 모델 지정\n",
    ")\n",
    "\n",
    "# Chroma 데이터베이스를 리트리버로 변환하고 검색할 결과의 개수를 1로 설정\n",
    "retriever_temp_chroma = db_chroma_temp.as_retriever(search_kwargs={'k': 1})\n",
    "\n",
    "# 앙상블 리트리버 생성: 두 개의 리트리버를 결합하여 결과를 통합\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[retriever_b25, retriever_temp_chroma],  # 사용할 리트리버 목록\n",
    "    weights=[0.5, 0.5],  # 각 리트리버에 대한 가중치 (합이 1이 되도록 설정)\n",
    ").configurable_fields(\n",
    "    # 앙상블 리트리버의 가중치를 설정할 수 있는 필드 추가\n",
    "    weights=ConfigurableField(\n",
    "        id='ensemble_weights',  # 필드의 고유 ID\n",
    "        name='Ensemble Weights',  # 사용자에게 보여질 필드 이름\n",
    "        description='앙상블된 두 retriever의 비율 (비율의 합은 1)'  # 필드에 대한 설명\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://n.news.naver.com/mnews/article/008/0005105524'}, page_content='\\nLG전자, 아쉬운 3분기 실적…장중 5%대 급락\\n\\n\\n\\n입력2024.10.25. 오후 1:18\\n\\n\\n수정2024.10.25. 오후 1:19\\n\\n기사원문\\n \\n\\n\\n\\n\\n김진석 기자\\n\\nTALK\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n김진석 기자\\n\\nTALK\\n구독\\n구독중\\n\\n\\n\\n\\n구독자\\n0\\n\\n\\n응원수\\n0\\n\\n\\n\\n더보기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n추천\\n\\n\\n\\n\\n쏠쏠정보\\n0\\n\\n\\n\\n\\n흥미진진\\n0\\n\\n\\n\\n\\n공감백배\\n0\\n\\n\\n\\n\\n분석탁월\\n0\\n\\n\\n\\n\\n후속강추\\n0\\n\\n\\n \\n\\n\\n\\n댓글\\n\\n\\n\\n\\n\\n본문 요약봇\\n\\n\\n\\n본문 요약봇도움말\\n자동 추출 기술로 요약된 내용입니다. 요약 기술의 특성상 본문의 주요 내용이 제외될 수 있어, 전체 맥락을 이해하기 위해서는 기사 본문 전체보기를 권장합니다.\\n닫기\\n\\n\\n\\n\\n\\n\\n\\n\\n텍스트 음성 변환 서비스 사용하기\\n\\n\\n\\n성별\\n남성\\n여성\\n\\n\\n말하기 속도\\n느림\\n보통\\n빠름\\n\\n이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다.\\n본문듣기 시작\\n\\n닫기\\n\\n\\n \\n\\n글자 크기 변경하기\\n\\n\\n\\n가1단계\\n작게\\n\\n\\n가2단계\\n보통\\n\\n\\n가3단계\\n크게\\n\\n\\n가4단계\\n아주크게\\n\\n\\n가5단계\\n최대크게\\n\\n\\n\\n\\n\\n\\nSNS 보내기\\n\\n\\n\\n인쇄하기\\n\\n\\n\\n\\n\\n[특징주]\\n\\n\\n\\n /사진=임종철 기자LG전자가 장 중 5%대 급락 중이다. 25일 오후 1시 10분 기준 코스피 시장에서 LG전자는 전날보다 4900원(5.04%) 하락한 9만2300원에 거래 중이다. 3분기 시장 기대치에 못 미친 실적을 내면서 투자심리가 악화한 것으로 해석된다. LG전자의 3분기 연결 매출액은 22조1764억원, 이 기간 영업이익은 7519억원이다. 매출액의 경우 역대 최대치를 기록했지만 영업이익은 전년동기 대비 24.6% 감소했다. 컨센서스(증권사 전망치)를 밑돌았다. 최보영 교보증권 연구원은 \"신흥국 중심의 매출 성장이 있었으나 물류비 증가, LCD패널가격 상승, VS사업 부진 영향으로 영업이익이 아쉬웠다\"며 \"4분기 비수기 시즌이 도래한 상황\"이라고 했다. 이어 \"다만 기업가치 제고를 위한 계획은 고무적\"이라고 평가했다. \\n\\n'),\n",
       " Document(metadata={'source': 'https://n.news.naver.com/mnews/article/629/0000332274'}, page_content=\"\\n고 이건희 4주기 추도식…이재용·홍라희·이부진 삼성 일가 참석\\n\\n\\n\\n입력2024.10.25. 오후 1:20\\n\\n기사원문\\n \\n\\n\\n\\n\\n오승혁 기자\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n오승혁 기자\\n\\n구독\\n구독중\\n\\n\\n\\n\\n구독자\\n0\\n\\n\\n응원수\\n0\\n\\n\\n\\n더보기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n추천\\n\\n\\n\\n\\n쏠쏠정보\\n0\\n\\n\\n\\n\\n흥미진진\\n0\\n\\n\\n\\n\\n공감백배\\n0\\n\\n\\n\\n\\n분석탁월\\n0\\n\\n\\n\\n\\n후속강추\\n0\\n\\n\\n \\n\\n\\n\\n댓글\\n\\n\\n\\n\\n\\n본문 요약봇\\n\\n\\n\\n본문 요약봇도움말\\n자동 추출 기술로 요약된 내용입니다. 요약 기술의 특성상 본문의 주요 내용이 제외될 수 있어, 전체 맥락을 이해하기 위해서는 기사 본문 전체보기를 권장합니다.\\n닫기\\n\\n\\n\\n\\n\\n\\n\\n\\n텍스트 음성 변환 서비스 사용하기\\n\\n\\n\\n성별\\n남성\\n여성\\n\\n\\n말하기 속도\\n느림\\n보통\\n빠름\\n\\n이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다.\\n본문듣기 시작\\n\\n닫기\\n\\n\\n \\n\\n글자 크기 변경하기\\n\\n\\n\\n가1단계\\n작게\\n\\n\\n가2단계\\n보통\\n\\n\\n가3단계\\n크게\\n\\n\\n가4단계\\n아주크게\\n\\n\\n가5단계\\n최대크게\\n\\n\\n\\n\\n\\n\\nSNS 보내기\\n\\n\\n\\n인쇄하기\\n\\n\\n\\n\\n\\n수원 선영 25일 이건희 선대회장 추도식 진행 삼성전자 위기론 속 조용한 추모 노력\\n\\n\\n\\n이재용 삼성전자 회장(오른쪽)과 홍라희 전 삼성미술관 리움 관장(왼쪽), 이부진 호텔 신라 사장(가운데)이 25일 오전 경기 수원 이목동 선영에서 열린 고 이건희 회장 4주기 추도식에 참석하고 있다. /임영무 기자고(故) 삼성 이건희 선대회장의 4주기 추도식이 수원 선영에서 엄숙한 분위기 속에 치뤄졌다. 이건희 선대회장의 기일인 25일 경기도 수원시 소재 선대회장 선영에 이재용 삼성전자 회장을 비롯한 삼성가가 고인을 추모하기 위해 자리했다.삼성전자 위기론이 대두되는 가운데 삼성가는 최대한 조용하게 이건희 선대회장의 추도식을 진행했다. 이재용 삼성전자 회장과 홍라희 전 삼성미술관 리움 관장, 이부진 호텔신라 사장, 이서현 삼성물산 사장 등 총 4인이 선영에 입장한 뒤 헌화와 묵념 등을 했다. 이들은 홍 전 관장의 수행차를 포함해 검은색 세단 5대로 이동했다.\\n\\n\\n\\n이재용 삼성전자 회장이 25일 오전 경기 수원시 장안구 선영에서 열린 고 이건희 삼성전자 회장의 4주기 추도식에 참석하고 있다. /서예원 기자이재용 회장과 홍 전 관장은 선글라스를 착용하고 선영 내를 이동했다. 이재용 회장은 작년 3주기 추도식 이후 경기도 용인에 있는 인재개발원으로 이동해 사장단과의 오찬을 진행했다. 올해도 비슷한 일정을 소화할 전망이다.50명가량의 사장단은 6대의 검은 밴을 이용해 삼성가 보다 먼저 선영에 도착해 추모했다. 정현호 삼성전자 사업지원TF장(부회장), 전영현 삼성전자 DS부문장(부회장), 한종희 삼성전자 부회장 등이 사장단 중 선두에서 국화를 헌화했다.이달 초 공개된 삼성전자의 3분기 실적이 영업이익 9조1000억원으로 시장 기대치에 비해 크게 낮았다. 이에 재계에서는 이재용 회장이 추도식 이후 사장단 오찬에서 '위기극복'을 위한 전략 발표 여부에 촉각을 곤두세우고 있다.다만 삼성전자가 이건희 선대회장의 올해 4주기 추도식을 조용히 치르는 만큼, 이재용 회장이 사업 관련 발언을 할 가능성은 낮다. 삼성전자는 지난해 3주기 추모식에서는 추도식 1주일 전에 추모 음악회를 진행하고 추도식에서는 추모 영상을 함께 관람했다. 하지만, 올해는 전날인 24일에 추모 음악회와 추모 영상 관람을 진행해 이번 4주기 추도식에서는 행사를 최소화시켰다.또한 삼성전자는 지난해 사내 임직원의 인트라넷에 추모 관련 게시글을 올렸지만, 올해는 로그인했을 때 이건희 선대회장 관련 팝업 이미지만 올리는 식으로 사내 추모 행보도 축소했다.한편 이건희 선대회장은 1987년 부친인 이병철 창업회장 별세 후 삼성 2대 회장에 올랐다. 2014년 5월 서울 용산구 자택에서 심근경색으로 쓰러졌다. 이후 6년 동안 투병하다 2020년 10월 25일 향년 78세를 일기로 별세했다.발로 뛰는 더팩트는 24시간 여러분의 제보를 기다립니다.▶카카오톡: '더팩트제보' 검색▶이메일: jebo@tf.co.kr▶뉴스 홈페이지: http://talk.tf.co.kr/bbs/report/write\\n\\n\")]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble_retriever를 사용하여 '삼성전자'에 대한 검색 수행\n",
    "results = ensemble_retriever.invoke(\n",
    "    '삼성전자',  # 검색할 쿼리\n",
    "    config={  # 검색 설정을 포함하는 구성\n",
    "        'configurable': {\n",
    "            'ensemble_weights': [0.2, 0.8]  # 각 리트리버에 대한 가중치를 설정 (비율의 합은 1)\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# 검색 결과 출력\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LongContextReorder\n",
    "\n",
    "paper: https://arxiv.org/pdf/2307.03172\n",
    "\n",
    "모델이 긴 컨텍스트 중간에 있는 관련 정보에 접근해야 할 때, 제공된 문서를 무시하는 경향이 있음. <br>\n",
    "-> 검색 후 문서의 순서를 재배열하여 성능 저하 방지. \n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "> texts = [\n",
    ">     \"영화는 다양한 이야기를 시각적으로 표현하는 매체입니다.\",\n",
    ">     \"좋은 영화는 관객의 감정을 깊이 있게 자극합니다.\",\n",
    ">     \"영화의 배경 음악은 이야기의 분위기를 한층 더 풍부하게 만듭니다.\",\n",
    ">     \"고전 영화는 오늘날에도 여전히 많은 사랑을 받고 있습니다.\",\n",
    ">     \"상상력이 풍부한 영화는 관객을 새로운 세계로 안내합니다.\",\n",
    ">     \"여행은 새로운 경험과 추억을 만들어 줍니다.\",\n",
    ">     \"커피 한 잔과 좋은 책은 완벽한 조합입니다.\",\n",
    ">     \"친구와의 대화는 언제나 즐거운 시간이 됩니다.\",\n",
    ">     \"가을의 바람은 특별한 감성을 불러일으킵니다.\",\n",
    ">     \"정원에서 꽃을 가꾸는 것은 마음을 편안하게 합니다.\"\n",
    "> ]\n",
    "> \n",
    "> retriever = Chroma.from_texts(\n",
    ">     texts,\n",
    ">     embedding=embeddings\n",
    ">     ).as_retriever(search_kwargs={'k': 10}\n",
    "> )\n",
    "> \n",
    "> reordering = LongContextReorder()\n",
    "> documents_reordered = reordering.transform_documents(documents)\n",
    "> \n",
    "> ###################################\n",
    "> # 사용 예제\n",
    "> \n",
    "> def reorder_documents(documents):\n",
    ">     reordering = LongContextReorder()\n",
    ">     reordered_documents = reordering.transform_documents(documents)\n",
    ">     documents_joined = '\\n'.join([document.page_content for document in docs])\n",
    "> \n",
    ">     return documents_joined\n",
    "> \n",
    "> template = '''\n",
    "> 주어진 context를 활용하라:\n",
    "> {context}\n",
    "> \n",
    "> 다음 질문에 답하라:\n",
    "> {question}\n",
    "> \n",
    "> 주어지는 언어로 답변하라: {language}\n",
    "> '''\n",
    "> \n",
    "> prompt = ChatPromptTemplate.from_template(template)\n",
    "> model = ChatOpenAI(model='gpt-4o-mini')\n",
    "> parser = StrOutputParser()\n",
    "> \n",
    "> chain = (\n",
    ">     {\n",
    ">         'context': itemgetter('question')\n",
    ">         | retriever\n",
    ">         | RunnableLambda(reorder_documents),\n",
    ">         'question': itemgetter('question'),\n",
    ">         'language': itemgetter('language'),\n",
    ">     }\n",
    ">     | prompt\n",
    ">     | model\n",
    ">     | parser\n",
    "> )\n",
    "> \n",
    "> answer = chain.invoke(\n",
    ">     {'question': 'ChatGPT에 대해 무엇을 말해줄 수 있나요?', 'language': 'KOREAN'}\n",
    "> )\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"영화는 다양한 이야기를 시각적으로 표현하는 매체입니다.\",\n",
    "    \"좋은 영화는 관객의 감정을 깊이 있게 자극합니다.\",\n",
    "    \"영화의 배경 음악은 이야기의 분위기를 한층 더 풍부하게 만듭니다.\",\n",
    "    \"고전 영화는 오늘날에도 여전히 많은 사랑을 받고 있습니다.\",\n",
    "    \"상상력이 풍부한 영화는 관객을 새로운 세계로 안내합니다.\",\n",
    "    \"여행은 새로운 경험과 추억을 만들어 줍니다.\",\n",
    "    \"커피 한 잔과 좋은 책은 완벽한 조합입니다.\",\n",
    "    \"친구와의 대화는 언제나 즐거운 시간이 됩니다.\",\n",
    "    \"가을의 바람은 특별한 감성을 불러일으킵니다.\",\n",
    "    \"정원에서 꽃을 가꾸는 것은 마음을 편안하게 합니다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma를 사용하여 텍스트 데이터로부터 임베딩 데이터베이스 생성\n",
    "retriever_movie = Chroma.from_texts(\n",
    "    texts,  # 사용할 텍스트 데이터 (문서 목록)\n",
    "    embedding=OpenAIEmbeddings(model='text-embedding-3-small'),  # 사용할 임베딩 모델 지정\n",
    ").as_retriever(search_kwargs={'k': 10})  # 검색할 결과의 개수를 10으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['좋은 영화는 관객의 감정을 깊이 있게 자극합니다.',\n",
       " '고전 영화는 오늘날에도 여전히 많은 사랑을 받고 있습니다.',\n",
       " '여행은 새로운 경험과 추억을 만들어 줍니다.',\n",
       " '친구와의 대화는 언제나 즐거운 시간이 됩니다.',\n",
       " '정원에서 꽃을 가꾸는 것은 마음을 편안하게 합니다.',\n",
       " '가을의 바람은 특별한 감성을 불러일으킵니다.',\n",
       " '커피 한 잔과 좋은 책은 완벽한 조합입니다.',\n",
       " '상상력이 풍부한 영화는 관객을 새로운 세계로 안내합니다.',\n",
       " '영화의 배경 음악은 이야기의 분위기를 한층 더 풍부하게 만듭니다.',\n",
       " '영화는 다양한 이야기를 시각적으로 표현하는 매체입니다.']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LongContextReorder 객체 생성: 긴 문맥을 재정렬하는 데 사용\n",
    "context_reorder = LongContextReorder()\n",
    "\n",
    "# 원본 텍스트 문서들을 재정렬\n",
    "texts_reordered = context_reorder.transform_documents(texts)\n",
    "\n",
    "# 재정렬된 텍스트 출력\n",
    "texts_reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_documents(documents):\n",
    "    # LongContextReorder 객체 생성: 긴 문맥을 재정렬하는 기능\n",
    "    context_reorder = LongContextReorder()\n",
    "    \n",
    "    # 입력된 문서들을 재정렬\n",
    "    documents_reordered = context_reorder.transform_documents(documents)\n",
    "    \n",
    "    # 재정렬된 문서의 내용을 줄바꿈으로 구분하여 하나의 문자열로 결합\n",
    "    documents_joined = '\\n'.join([document.page_content for document in documents_reordered])\n",
    "\n",
    "    return documents_joined  # 재정렬된 문서의 내용을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿 정의: reference, question, language를 포함\n",
    "template = '''\n",
    "    주어진 reference를 최대한 활용하라:\n",
    "    {reference}\n",
    "\n",
    "    다음 질문에 답하라:\n",
    "    {question}\n",
    "\n",
    "주어지는 언어로 답하라: {language}\n",
    "'''\n",
    "\n",
    "# 템플릿으로부터 프롬프트 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# OpenAI의 Chat 모델 초기화 (gpt-4o-mini 모델 사용)\n",
    "model = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "\n",
    "# 출력 파서를 초기화 (문자열 출력을 처리)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 체인 구성: 데이터 흐름을 정의\n",
    "chain = (\n",
    "    {\n",
    "        # 'reference' 키에 대해 여러 처리를 정의\n",
    "        'reference': itemgetter('question')  # 질문에서 reference를 추출\n",
    "        | retriever_chroma  # Chroma 리트리버로부터 데이터를 검색\n",
    "        | RunnableLambda(reorder_documents),  # 문서를 재정렬\n",
    "        'question': itemgetter('question'),  # 질문을 그대로 가져오기\n",
    "        'language': itemgetter('language'),  # 언어 정보를 가져오기\n",
    "    }\n",
    "    | prompt  # 프롬프트 템플릿에 데이터 결합\n",
    "    | model  # 모델에 프롬프트 전달하여 응답 생성\n",
    "    | parser  # 모델의 응답을 파싱\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"삼성전자는 최근 다양한 이슈에 직면해 있습니다. 이재용 삼성전자 회장이 취임 2주년을 맞이한 가운데, 고 이건희 선대 회장의 4주기를 맞이하여 삼성에서 어떤 공개 메시지가 나올지 관심이 집중되고 있습니다. 또한, 삼성전자는 '위기론'에 대한 우려가 커지고 있으며, 이는 기업의 실적 부진과 관련이 깊습니다. \\n\\n특히, SK하이닉스가 어닝서프라이즈를 기록하며 주가가 반등하고 있는 반면, 삼성전자는 지속적인 주가 하락으로 52주 신저가를 기록하고 있어 시장에서의 우려가 커지고 있습니다. 이러한 상황 속에서 삼성전자의 향후 대응과 전략이 주목받고 있으며, 기업 실적과 글로벌 경제 상황에 대한 경계감이 고조되고 있습니다.\""
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인을 사용하여 질문을 실행하고 응답을 받음\n",
    "response = chain.invoke({\n",
    "    'question': '삼성전자의 최근 이슈에 대해서 알려줄래?',  # 질문: 삼성전자의 최근 이슈\n",
    "    'language': '한국어'  # 언어: 한국어로 응답 요청\n",
    "})\n",
    "\n",
    "# 응답 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp_keywords -> retriever 구축\n",
    "# 텍스트 파일 로더 생성: 지정된 경로에서 텍스트 파일을 로드\n",
    "loader = TextLoader('./data/nlp_keywords.txt')\n",
    "\n",
    "# 텍스트 분할기 생성: 각 청크의 크기와 중첩 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=250,  # 각 청크의 최대 크기 (250자)\n",
    "    chunk_overlap=50,  # 각 청크 간의 중첩 (50자)\n",
    ")\n",
    "\n",
    "# 텍스트를 로드하고 분할하여 문서 리스트 생성\n",
    "documents = loader.load_and_split(text_splitter)\n",
    "\n",
    "# Chroma 데이터베이스 생성: 문서들을 임베딩하여 저장\n",
    "db_nlp = Chroma.from_documents(\n",
    "    documents,  # 사용될 문서 리스트\n",
    "    embedding=OpenAIEmbeddings(model='text-embedding-3-small'),  # 사용할 임베딩 모델 지정\n",
    ")\n",
    "\n",
    "# Chroma 데이터베이스를 리트리버로 변환하고 검색할 결과의 개수를 10으로 설정\n",
    "retriever_nlp = db_nlp.as_retriever(search_kwargs={'k': 10})\n",
    "\n",
    "# 문서 재정렬 함수 정의\n",
    "def reorder_documents(documents):\n",
    "    # LongContextReorder 객체 생성: 긴 문맥을 재정렬하는 기능\n",
    "    context_reorder = LongContextReorder()\n",
    "    \n",
    "    # 입력된 문서들을 재정렬\n",
    "    documents_reordered = context_reorder.transform_documents(documents)\n",
    "    \n",
    "    # 재정렬된 문서의 내용을 줄바꿈으로 구분하여 하나의 문자열로 결합\n",
    "    documents_joined = '\\n'.join([document.page_content for document in documents_reordered])\n",
    "\n",
    "    return documents_joined  # 재정렬된 문서의 내용을 반환\n",
    "\n",
    "# 프롬프트 템플릿 정의: reference, question, language를 포함\n",
    "template = '''\n",
    "주어진 reference를 최대한 활용하라:\n",
    "{reference}\n",
    "\n",
    "다음 질문에 답하라:\n",
    "{question}\n",
    "\n",
    "주어지는 언어로 답하라: {language}\n",
    "'''\n",
    "\n",
    "## question과 연관된 reference를 retriever를 통해 획득\n",
    "## 획득한 reference를 prompt에 주입\n",
    "## prompt를 llm에 입력하여 결과 return\n",
    "# 프롬프트 템플릿을 사용하여 PromptTemplate 객체 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# OpenAI의 Chat 모델 초기화 (gpt-4o-mini 모델 사용)\n",
    "model = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "\n",
    "# 문자열 출력을 처리하기 위한 출력 파서 초기화\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 데이터 흐름을 정의하는 체인 구성\n",
    "chain = (\n",
    "    {\n",
    "        # 'reference' 키에 대한 처리 흐름 정의\n",
    "        'reference': itemgetter('question')  # 질문에서 reference를 추출\n",
    "        | retriever_nlp  # NLP 리트리버를 사용하여 데이터를 검색\n",
    "        | RunnableLambda(reorder_documents),  # 검색된 문서를 재정렬\n",
    "        'question': itemgetter('question'),  # 질문을 그대로 가져오기\n",
    "        'language': itemgetter('language'),  # 언어 정보를 가져오기\n",
    "    }\n",
    "    | prompt  # 프롬프트 템플릿에 데이터 결합\n",
    "    | model  # 모델에 프롬프트를 전달하여 응답 생성\n",
    "    | parser  # 모델의 응답을 파싱\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HuggingFace에서는 딥러닝을 다양한 방식으로 사용할 수 있습니다. 주로 자연어 처리(NLP) 작업을 위한 사전 훈련된 모델과 도구를 제공하여, 사용자가 쉽게 딥러닝 모델을 활용할 수 있도록 돕습니다. \\n\\n예를 들어, HuggingFace의 Transformers 라이브러리를 사용하면 텍스트 분류, 감정 분석, 번역, 텍스트 생성 등 여러 NLP 작업을 간편하게 수행할 수 있습니다. 이러한 모델들은 대규모 데이터셋으로 사전 훈련되어 있어, 특정 작업에 맞게 추가 훈련(fine-tuning)하여 높은 성능을 발휘할 수 있습니다.\\n\\n또한, HuggingFace는 사용자 친화적인 API를 제공하여, 복잡한 딥러닝 모델을 손쉽게 사용할 수 있도록 해줍니다. 이를 통해 데이터 분석가나 개발자는 딥러닝의 복잡성을 최소화하면서도 효과적인 솔루션을 구축할 수 있습니다.'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인을 사용하여 질문을 실행하고 응답을 받음\n",
    "response = chain.invoke({\n",
    "    'question': 'huggingface에서 deep learning을 어떻게 사용할 수 있어?',\n",
    "    'language': '한국어'\n",
    "})\n",
    "\n",
    "# 응답 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='HuggingFace\\n\\n정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nTransformer'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Deep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nDataFrame'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\\n\\nDeep Learning'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='LLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nHuggingFace'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Word2Vec\\n\\n정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\n\\nFAISS (Facebook AI Similarity Search)'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='FAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content=\"Attention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\"),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='Transformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nSQL'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='DataFrame\\n\\n정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nLLM (Large Language Model)'),\n",
       " Document(metadata={'source': './data/nlp_keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nAttention 메커니즘')]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP 리트리버를 사용하여 질문에 대한 응답을 검색\n",
    "response = retriever_nlp.invoke('huggingface에서 deep learning을 어떻게 사용할 수 있어?')  # 질문: Hugging Face에서 딥 러닝 사용 방법\n",
    "\n",
    "# 응답 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ParentDocumentRetriever\n",
    "\n",
    "문서 검색 과정에서 문서를 적절한 크기의 chunk로 나누는 것은 다음의 상충되는 두 가지 중요한 요소를 고려해야 함.\n",
    "\n",
    "1. 작은 문서를 원하는 경우: 문서의 임베딩이 그 의미를 가장 정확하게 반영. <br>\n",
    "문서가 너무 길면 임베딩이 의미를 잃어버릴 수 있음. <br>\n",
    "2. 각 청크의 맥락이 유지되도록 충분히 긴 문서를 원하는 경우.\n",
    "\n",
    "위의 두 경우에서 균형을 맞추기 위해 ParentDocumentRetriever라는 도구가 사용. <br> \n",
    "문서를 작은 chunk으로 나누고, 이 chunk를 관리. <br>\n",
    "검색을 진행할 때는, 먼저 이 작은 chunk들을 찾아낸 다음, 이 chunk들이 속한 원본 문서의 ID를 통해 전체적인 맥락을 파악 가능. <br>\n",
    "\n",
    "parent document: 원본 문서. 전체 문서일 수도 있고, 비교적 큰 다른 chunk일 수도 있음. <br>\n",
    "이 방식을 통해 문서의 의미를 정확하게 파악하면서도, 전체적인 맥락을 유지할 수 있음 <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "> ```python\n",
    "> retriever = ParentDocumentRetriever(\n",
    ">     vectorstore=vectorstore,\n",
    ">     docstore=store,\n",
    ">     child_splitter=child_splitter,\n",
    "> )\n",
    "> \n",
    "> parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "> child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
    "> vectorstore = Chroma(\n",
    ">     collection_name='split_parents',\n",
    ">     embedding_function=OpenAIEmbeddings(),\n",
    "> )\n",
    "> store = InMemoryStore()\n",
    "> \n",
    "> retriever = ParentDocumentRetriever(\n",
    ">     vectorstore=vectorstore,\n",
    ">     docstore=store,\n",
    ">     child_splitter=child_splitter,\n",
    ">     parent_splitter=parent_splitter,\n",
    "> )\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 파일 로더 생성: 지정된 경로에서 텍스트 파일을 로드\n",
    "loader = TextLoader('./data/finance_keywords.txt')\n",
    "\n",
    "# 텍스트 분할기 생성: 각 청크의 크기 설정\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200  # 각 청크의 최대 크기 (200자)\n",
    ")\n",
    "\n",
    "# Chroma 데이터베이스 생성: 금융 관련 문서 저장\n",
    "db_finance = Chroma(\n",
    "    collection_name='full_documents',  # 컬렉션 이름 설정\n",
    "    embedding_function=OpenAIEmbeddings(model='text-embedding-3-small')  # 사용할 임베딩 모델 지정\n",
    ")\n",
    "\n",
    "# 인메모리 스토어 생성: 문서 저장을 위한 임시 스토리지\n",
    "store = InMemoryStore()\n",
    "\n",
    "# 부모 문서 리트리버 생성: Chroma 데이터베이스와 스토어를 연결\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=db_finance,  # 벡터 스토어 설정\n",
    "    docstore=store,  # 문서 스토어 설정\n",
    "    child_splitter=child_splitter,  # 자식 문서 분할기 설정\n",
    ")\n",
    "\n",
    "# 로드한 문서를 리트리버에 추가\n",
    "retriever.add_documents(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "환율 (Exchange Rate)\n",
      "\n",
      "정의: 환율은 두 통화 간의 교환 비율을 의미합니다.\n",
      "예시: 1달러가 1,200원일 경우, 달러와 원화의 환율이 1,200입니다.\n",
      "연관키워드: 외환, 금융, 경제\n",
      "\n",
      "신용 (Credit)\n"
     ]
    }
   ],
   "source": [
    "# '비트코인'과 관련된 문서를 Chroma 데이터베이스에서 검색하고, 첫 번째 결과의 내용을 출력\n",
    "result = db_finance.similarity_search('비트코인')  # '비트코인'에 대한 유사도 검색 수행\n",
    "print(result[0].page_content)  # 검색 결과 중 첫 번째 문서의 내용을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부모 문서와 자식 문서를 위한 텍스트 분할기 생성\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)  # 부모 문서의 청크 크기를 1000자로 설정\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)  # 자식 문서의 청크 크기를 200자로 설정\n",
    "\n",
    "# Chroma 데이터베이스 생성: 부모 문서를 저장하기 위한 데이터베이스\n",
    "db_finance_with_parent = Chroma(\n",
    "    collection_name='parent_documents',  # 데이터베이스의 컬렉션 이름을 'parent_documents'로 설정\n",
    "    embedding_function=OpenAIEmbeddings(model='text-embedding-3-small')  # 사용할 임베딩 모델 지정\n",
    ")\n",
    "\n",
    "# 인메모리 스토어 생성: 문서를 저장할 인메모리 스토어\n",
    "store = InMemoryStore()\n",
    "\n",
    "# 부모 문서 리트리버 생성: 부모 문서와 자식 문서를 검색할 리트리버\n",
    "retriever_parent = ParentDocumentRetriever(\n",
    "    vectorstore=db_finance_with_parent,  # 벡터 스토어로 부모 문서를 저장한 Chroma 데이터베이스 지정\n",
    "    docstore=store,  # 문서 저장소로 인메모리 스토어 지정\n",
    "    child_splitter=child_splitter,  # 자식 문서 분할기를 지정\n",
    "    parent_splitter=parent_splitter,  # 부모 문서 분할기를 지정\n",
    ")\n",
    "\n",
    "# 로드한 문서를 리트리버에 추가\n",
    "retriever_parent.add_documents(loader.load())  # 로더를 통해 로드한 문서들을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인메모리 스토어에 저장된 키의 개수를 세어 출력\n",
    "num_keys = len(list(store.yield_keys()))  # yield_keys()를 호출하여 저장된 키 목록을 생성하고, 그 길이를 계산\n",
    "print(num_keys)  # 저장된 키의 개수를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "채권 (Bond)\n",
      "\n",
      "정의: 채권은 발행자가 일정 기간 후에 원금과 이자를 지급하겠다고 약속하는 부채 증서입니다.\n",
      "예시: 정부가 인프라 프로젝트를 위해 채권을 발행할 수 있습니다.\n",
      "연관키워드: 고정 수익, 투자, 자금 조달\n",
      "\n",
      "유동성 (Liquidity)\n"
     ]
    }
   ],
   "source": [
    "# '채권'과 관련된 문서를 Chroma 데이터베이스에서 검색하고, 첫 번째 결과의 내용을 출력\n",
    "result = db_finance_with_parent.similarity_search('채권')  # '채권'에 대한 유사도 검색 수행\n",
    "print(result[0].page_content)  # 검색 결과 중 첫 번째 문서의 내용을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자본 (Capital)\n",
      "\n",
      "정의: 자본은 기업이 사업을 운영하기 위해 사용하는 자원의 총액을 의미합니다.\n",
      "예시: 기업은 자본을 통해 새로운 프로젝트에 투자하거나 운영 비용을 충당할 수 있습니다.\n",
      "연관키워드: 재무, 투자, 자산\n",
      "\n",
      "주식 (Stock)\n",
      "\n",
      "정의: 주식은 기업의 소유권을 나타내는 증권으로, 주식을 소유한 사람은 해당 기업의 일부를 소유하게 됩니다.\n",
      "예시: 주식을 구매하면 기업의 이익 배당금을 받을 수 있습니다.\n",
      "연관키워드: 증권, 투자, 자본 시장\n",
      "\n",
      "채권 (Bond)\n",
      "\n",
      "정의: 채권은 발행자가 일정 기간 후에 원금과 이자를 지급하겠다고 약속하는 부채 증서입니다.\n",
      "예시: 정부가 인프라 프로젝트를 위해 채권을 발행할 수 있습니다.\n",
      "연관키워드: 고정 수익, 투자, 자금 조달\n",
      "\n",
      "유동성 (Liquidity)\n",
      "\n",
      "정의: 유동성은 자산을 현금으로 전환하는 용이성을 의미합니다.\n",
      "예시: 주식은 상대적으로 높은 유동성을 가지지만, 부동산은 낮은 유동성을 가질 수 있습니다.\n",
      "연관키워드: 자산, 금융, 시장\n",
      "\n",
      "금리 (Interest Rate)\n",
      "\n",
      "정의: 금리는 대출이나 투자에 대한 이자의 비율을 나타내며, 경제에 큰 영향을 미칩니다.\n",
      "예시: 중앙은행이 금리를 인상하면 대출이 줄어들 수 있습니다.\n",
      "연관키워드: 금융 정책, 대출, 투자\n",
      "\n",
      "포트폴리오 (Portfolio)\n",
      "\n",
      "정의: 포트폴리오는 투자자가 보유한 다양한 자산의 집합을 의미합니다.\n",
      "예시: 주식, 채권, 부동산 등으로 구성된 포트폴리오가 있을 수 있습니다.\n",
      "연관키워드: 투자, 위험 관리, 자산 배분\n",
      "\n",
      "리스크 (Risk)\n",
      "\n",
      "정의: 리스크는 투자에서 예상치 못한 손실이 발생할 가능성을 의미합니다.\n",
      "예시: 주식 시장의 변동성은 높은 리스크를 동반할 수 있습니다.\n",
      "연관키워드: 투자, 손실, 위험 관리\n",
      "\n",
      "배당금 (Dividend)\n",
      "\n",
      "정의: 배당금은 기업이 이익의 일부를 주주에게 분배하는 금액을 의미합니다.\n",
      "예시: 정기적으로 배당금을 지급하는 안정적인 기업들이 많습니다.\n",
      "연관키워드: 주식, 투자, 수익\n"
     ]
    }
   ],
   "source": [
    "# 부모 문서 리트리버를 사용하여 '채권'에 대한 응답을 검색하고, 첫 번째 결과의 내용을 출력\n",
    "response = retriever_parent.invoke('채권')  # '채권'에 대한 질문으로 리트리버에 요청\n",
    "print(response[0].page_content)  # 검색 결과 중 첫 번째 문서의 내용을 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "\n",
    "1\\. 조선, 중앙, 동아일보 전체페이지 크롤링 <br>\n",
    "2\\. 데이터 db에 적재 (chroma) <br>\n",
    "3\\. retriever 생성 <br>\n",
    "4\\. chain 생성 <br>\n",
    "5\\. 조회 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_urls(url):\n",
    "    # 주어진 URL에 GET 요청을 보냅니다.\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # 응답의 HTML 내용을 lxml 파서를 사용하여 BeautifulSoup 객체로 변환합니다.\n",
    "    bs_response = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    # 'a.nclicks(cnt_flashart)' 선택자로 링크를 찾아 href 속성을 추출합니다.\n",
    "    urls = [\n",
    "        item.get('href')\n",
    "        for item in bs_response.select('a.nclicks\\(cnt_flashart\\)')\n",
    "    ]\n",
    "\n",
    "    # 추출한 URL 리스트를 반환합니다.\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:13<00:00,  4.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# 빈 리스트를 초기화하여 URL을 저장할 준비를 합니다.\n",
    "urls = []\n",
    "\n",
    "# tqdm을 사용하여 진행 상황을 시각적으로 보여줍니다.\n",
    "for oid in tqdm(('023', '025', '020')):\n",
    "    # 각 oid에 대해 1페이지부터 19페이지까지 반복합니다.\n",
    "    for page in range(1, 20):\n",
    "        # 각 페이지의 URL을 생성합니다.\n",
    "        url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid={oid}&date=20241025&page={page}'\n",
    "        \n",
    "        # 생성된 URL에서 페이지 URL을 추출하고 urls 리스트에 추가합니다.\n",
    "        urls.extend(get_page_urls(url))\n",
    "\n",
    "# 중복된 URL을 제거하여 고유한 URL 리스트로 만듭니다.\n",
    "urls = list(set(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages:   0%|          | 0/641 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 641/641 [00:28<00:00, 22.40it/s]\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "news = naver_news_crawler(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부모 문서와 자식 문서를 위한 텍스트 분할기 생성\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)  # 부모 문서의 청크 크기를 1000자로 설정\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)  # 자식 문서의 청크 크기를 200자로 설정\n",
    "\n",
    "# Chroma 데이터베이스 생성: 부모 문서를 저장하기 위한 데이터베이스\n",
    "db_finance_with_parent = FAISS(\n",
    "    embedding_function=OpenAIEmbeddings(model='text-embedding-3-small'),  # 사용할 임베딩 모델 지정\n",
    "    index=faiss.IndexFlatL2(1536),\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "# 인메모리 스토어 생성: 문서를 저장할 인메모리 스토어\n",
    "store = InMemoryStore()\n",
    "\n",
    "# 부모 문서 리트리버 생성: 부모 문서와 자식 문서를 검색할 리트리버\n",
    "retriever_parent = ParentDocumentRetriever(\n",
    "    vectorstore=db_finance_with_parent,  # 벡터 스토어로 부모 문서를 저장한 Chroma 데이터베이스 지정\n",
    "    docstore=store,  # 문서 저장소로 인메모리 스토어 지정\n",
    "    child_splitter=child_splitter,  # 자식 문서 분할기를 지정\n",
    "    parent_splitter=parent_splitter,  # 부모 문서 분할기를 지정\n",
    ")\n",
    "\n",
    "# 로드한 문서를 리트리버에 추가\n",
    "retriever_parent.add_documents(news)  # 로더를 통해 로드한 문서들을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 재정렬 함수 정의\n",
    "def reorder_documents(documents):\n",
    "    # LongContextReorder 객체 생성: 긴 문맥을 재정렬하는 기능\n",
    "    context_reorder = LongContextReorder()\n",
    "    \n",
    "    # 입력된 문서들을 재정렬\n",
    "    documents_reordered = context_reorder.transform_documents(documents)\n",
    "    \n",
    "    # 재정렬된 문서의 내용을 줄바꿈으로 구분하여 하나의 문자열로 결합\n",
    "    documents_joined = '\\n'.join([document.page_content for document in documents_reordered])\n",
    "\n",
    "    return documents_joined  # 재정렬된 문서의 내용을 반환\n",
    "\n",
    "# 프롬프트 템플릿 정의: reference, question, language를 포함\n",
    "template = '''\n",
    "주어진 reference를 최대한 활용하여 아래의 질문에 답하라:\n",
    "{reference}\n",
    "\n",
    "다음 질문에 답하라. reference에서 답을 찾을 수 없으면 찾을 수 없다고 답하라:\n",
    "{question}\n",
    "\n",
    "주어지는 언어로 답하라:\n",
    "{language}\n",
    "'''\n",
    "\n",
    "## question과 연관된 reference를 retriever를 통해 획득\n",
    "## 획득한 reference를 prompt에 주입\n",
    "## prompt를 llm에 입력하여 결과 return\n",
    "# 프롬프트 템플릿을 사용하여 PromptTemplate 객체 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# OpenAI의 Chat 모델 초기화 (gpt-4o-mini 모델 사용)\n",
    "model = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "\n",
    "# 문자열 출력을 처리하기 위한 출력 파서 초기화\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 데이터 흐름을 정의하는 체인 구성\n",
    "chain = (\n",
    "    {\n",
    "        # 'reference' 키에 대한 처리 흐름 정의\n",
    "        'reference': itemgetter('question')  # 질문에서 reference를 추출\n",
    "        | retriever_parent  # NLP 리트리버를 사용하여 데이터를 검색\n",
    "        | RunnableLambda(reorder_documents),  # 검색된 문서를 재정렬\n",
    "        'question': itemgetter('question'),  # 질문을 그대로 가져오기\n",
    "        'language': itemgetter('language'),  # 언어 정보를 가져오기\n",
    "    }\n",
    "    | prompt  # 프롬프트 템플릿에 데이터 결합\n",
    "    | model  # 모델에 프롬프트를 전달하여 응답 생성\n",
    "    | parser  # 모델의 응답을 파싱\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'삼성전자는 최근 3분기 실적이 부진한 상황으로 보입니다. 증권가는 삼성전자의 반도체 부문 3분기 영업이익을 5조원 안팎으로 추산하고 있으며, SK하이닉스가 분기 영업이익 기준으로 처음으로 삼성 반도체를 제친 것으로 나타났습니다. 삼성전자의 반도체 부문장이 \"걱정을 끼쳐 송구하다\"는 사과문을 발표한 것으로 보아, 현재 삼성전자는 어려운 상황에 처해 있는 것으로 판단됩니다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question': '삼성전자 근황이 어떻게 돼?', 'language': 'korean'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
